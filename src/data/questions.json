[
  {
    "id": 1,
    "question": "An upstream system has been configured to pass the date for a given batch of data to the Databricks Jobs API as a parameter. The notebook to be scheduled will use this parameter to load data with the following code: df = spark.read.format(\"parquet\").load(f\"/mnt/source/(date)\") Which code block should be used to create the date Python variable used in the above code block?",
    "choices": [
      {
        "id": "A",
        "text": "date = spark.conf.get(\"date\")"
      },
      {
        "id": "B",
        "text": "input_dict = input() date= input_dict[\"date\"]"
      },
      {
        "id": "C",
        "text": "import sys date = sys.argv[1]"
      },
      {
        "id": "D",
        "text": "date = dbutils.notebooks.getParam(\"date\")"
      },
      {
        "id": "E",
        "text": "dbutils.widgets.text(\"date\", \"null\") date = dbutils.widgets.get(\"date\")"
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: The date is passed to the notebook through the Databricks Jobs API as a job parameter and must become a Python variable used in the f-string path.\n- Mechanism tested: Databricks job parameters are typically surfaced to notebooks via widgets; dbutils.widgets.get(...) retrieves the parameter value at runtime.\n- Option E first defines the widget (so the parameter can be provided) and then reads it with dbutils.widgets.get(\"date\"), creating the Python variable date used in the load path.\n\nWhy the other options are incorrect\n- A: spark.conf.get(\"date\") reads Spark configuration, not a Jobs API notebook parameter.\n- B: input() expects interactive stdin; Jobs runs are non-interactive.\n- C: sys.argv is not how Databricks Jobs notebook parameters are passed to notebook code.\n- D: dbutils.notebooks.getParam(...) is not the standard/expected mechanism for Jobs API parameters in notebooks; the question’s pattern matches widgets.\n\nKey takeaway\n- For Databricks Jobs notebook parameters, use notebook widgets (dbutils.widgets.get) to retrieve the value inside the notebook.",
    "images": [
      "/questions/q001.webp"
    ],
    "docs": [
      {
        "title": "Databricks notebook widgets (dbutils.widgets)",
        "query": "dbutils.widgets notebook parameters"
      },
      {
        "title": "Databricks Jobs task parameters",
        "query": "Databricks Jobs notebook parameters"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      }
    ]
  },
  {
    "id": 2,
    "question": "The Databricks workspace administrator has configured interactive clusters for each of the data engineering groups. To control costs, clusters are set to terminate after 30 minutes of inactivity. Each user should be able to execute workloads against their assigned clusters at any time of the day. Assuming users have been added to a workspace but not granted any permissions, which of the following describes the minimal permissions a user would need to start and attach to an already configured cluster.",
    "choices": [
      {
        "id": "A",
        "text": "\"Can Manage\" privileges on the required cluster"
      },
      {
        "id": "B",
        "text": "Workspace Admin privileges, cluster creation allowed, \"Can Attach To\" privileges on the required cluster"
      },
      {
        "id": "C",
        "text": "Cluster creation allowed, \"Can Attach To\" privileges on the required cluster"
      },
      {
        "id": "D",
        "text": "\"Can Restart\" privileges on the required cluster"
      },
      {
        "id": "E",
        "text": "Cluster creation allowed, \"Can Restart\" privileges on the required cluster"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Users must be able to start a pre-configured cluster that may have auto-terminated and then attach to it to run workloads.\n- Mechanism tested: Databricks cluster permissions; “Can Restart” grants the ability to start/stop/restart a cluster and (by enabling use of the cluster) attach to it.\n- Therefore, “Can Restart” on the required cluster is the minimal permission that satisfies “start and attach”.\n\nWhy the other options are incorrect\n- A: “Can Manage” is broader than needed (includes management actions); it is not minimal.\n- B: Workspace Admin + cluster creation is unnecessary for starting/attaching to an existing configured cluster.\n- C: “Can Attach To” alone doesn’t allow starting a terminated cluster, which is required due to auto-termination.\n- E: Cluster creation is still unnecessary; only restart/attach on the existing cluster is required.\n\nKey takeaway\n- If a user must start an auto-terminated existing cluster, they need “Can Restart” on that cluster; cluster creation/admin is not required.",
    "images": [
      "/questions/q002.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 3,
    "question": "When scheduling Structured Streaming jobs for production, which configuration automatically recovers from query failures and keeps costs low?",
    "choices": [
      {
        "id": "A",
        "text": "Cluster: New Job Cluster; Retries: Unlimited; Maximum Concurrent Runs: Unlimited"
      },
      {
        "id": "B",
        "text": "Cluster: New Job Cluster; Retries: None; Maximum Concurrent Runs: 1"
      },
      {
        "id": "C",
        "text": "Cluster: Existing All-Purpose Cluster; Retries: Unlimited; Maximum Concurrent Runs: 1"
      },
      {
        "id": "D",
        "text": "Cluster: New Job Cluster; Retries: Unlimited; Maximum Concurrent Runs: 1"
      },
      {
        "id": "E",
        "text": "Cluster: Existing All-Purpose Cluster; Retries: None; Maximum Concurrent Runs: 1"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: “Automatically recovers from query failures” and “keeps costs low” for a production Structured Streaming job.\n- Mechanism tested: Databricks Jobs settings for streaming reliability and cost control.\n- A New Job Cluster keeps costs low by spinning up only for the run, Unlimited retries enables automatic recovery from failures, and Maximum Concurrent Runs = 1 prevents overlapping streaming runs that would waste compute and potentially duplicate work.\n\nWhy the other options are incorrect\n- A: Unlimited concurrent runs can create overlapping stream instances, increasing cost and risk.\n- B: No retries means failures won’t be automatically recovered.\n- C: An existing all-purpose cluster is typically higher-cost for production jobs and less isolated; also not the “keep costs low” choice.\n- E: No retries means no automatic recovery.\n\nKey takeaway\n- For production streaming, combine a job cluster + unlimited retries + a single concurrent run to recover from failures without runaway cost.",
    "images": [
      "/questions/q003.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 4,
    "question": "The data engineering team has configured a Databricks SQL query and alert to monitor the values in a Delta Lake table. The recent_sensor_recordings table contains an identifying sensor_id alongside the timestamp and temperature for the most recent 5 minutes of recordings. The below query is used to create the alert: The query is set to refresh each minute and always completes in less than 10 seconds. The alert is set to trigger when mean (temperature) > 120. Notifications are triggered to be sent at most every 1 minute. If this alert raises notifications for 3 consecutive minutes and then stops, which statement must be true?",
    "choices": [
      {
        "id": "A",
        "text": "The total average temperature across all sensors exceeded 120 on three consecutive executions of the query"
      },
      {
        "id": "B",
        "text": "The recent_sensor_recordings table was unresponsive for three consecutive runs of the query"
      },
      {
        "id": "C",
        "text": "The source query failed to update properly for three consecutive minutes and then restarted"
      },
      {
        "id": "D",
        "text": "The maximum temperature recording for at least one sensor exceeded 120 on three consecutive executions of the query"
      },
      {
        "id": "E",
        "text": "The average temperature recordings for at least one sensor exceeded 120 on three consecutive executions of the query"
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: The alert triggers when mean(temperature) > 120, and notifications were raised for 3 consecutive minutes (query refreshes every minute).\n- Mechanism tested: How Databricks SQL alerts evaluate the query result against a threshold.\n- The condition “mean(temperature) > 120” must have evaluated to true on each of those three executions. If the query returns per-sensor averages (implied by including sensor_id in the table and monitoring “values”), then at least one sensor’s average temperature must have exceeded 120 on three consecutive runs.\n\nWhy the other options are incorrect\n- A: “Total average across all sensors” is not guaranteed unless the query computes a single global mean; the alert condition can be satisfied by a per-sensor result.\n- B: Table unresponsiveness is not implied; the query is stated to complete in <10 seconds.\n- C: Query failure/restart is not implied; again, it completes successfully and triggers based on a value condition.\n- D: The alert is on mean(temperature), not max(temperature); a single high reading doesn’t necessarily push the mean over 120.\n\nKey takeaway\n- SQL alerts trigger only when the query’s returned metric(s) satisfy the threshold; if the alert is on a mean, the mean must exceed the threshold on each triggering run.",
    "images": [
      "/questions/q004.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 5,
    "question": "A junior developer complains that the code in their notebook isn't producing the correct results in the development environment. A shared screenshot reveals that while they're using a notebook versioned with Databricks Repos, they're using a personal branch that contains old logic. The desired branch named dev-2.3.9 is not available from the branch selection dropdown. Which approach will allow this developer to review the current logic for this notebook?",
    "choices": [
      {
        "id": "A",
        "text": "Use Repos to make a pull request use the Databricks REST API to update the current branch to dev-2.3.9"
      },
      {
        "id": "B",
        "text": "Use Repos to pull changes from the remote Git repository and select the dev-2.3.9 branch."
      },
      {
        "id": "C",
        "text": "Use Repos to checkout the dev-2.3.9 branch and auto-resolve conflicts with the current branch"
      },
      {
        "id": "D",
        "text": "Merge all changes back to the main branch in the remote Git repository and clone the repo again"
      },
      {
        "id": "E",
        "text": "Use Repos to merge the current branch and the dev-2.3.9 branch, then make a pull request to sync with the remote repository"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The desired branch (dev-2.3.9) is not in the Repos branch dropdown, and the developer needs to review the current logic from that branch.\n- Mechanism tested: Databricks Repos Git synchronization behavior.\n- Pulling from the remote updates the local repo’s knowledge of remote branches; once fetched, the developer can select dev-2.3.9 from the branch selector.\n\nWhy the other options are incorrect\n- A: Creating a PR and using the REST API is unnecessary just to view a branch; the issue is that the branch isn’t fetched locally.\n- C: Checking out can’t happen if the branch isn’t available locally yet; the missing step is pulling/fetching remote refs.\n- D: Merging into main and recloning is unrelated and destructive to the goal of simply reviewing a specific branch.\n- E: Merging branches and making a PR changes history and is not required to access the branch’s contents.\n\nKey takeaway\n- If a Git branch isn’t visible in Databricks Repos, pull (fetch) from the remote first, then switch to the branch.",
    "images": [
      "/questions/q005.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 6,
    "question": "The security team is exploring whether or not the Databricks secrets module can be leveraged for connecting to an external database. After testing the code with all Python variables being defined with strings, they upload the password to the secrets module and configure the correct permissions for the currently active user. They then modify their code to the following (leaving all other variables unchanged).Which statement describes what will happen when the above code is executed?",
    "choices": [
      {
        "id": "A",
        "text": "The connection to the external table will fail; the string \"REDACTED\" will be printed."
      },
      {
        "id": "B",
        "text": "An interactive input box will appear in the notebook; if the right password is provided, the connection will succeed and the encoded password will be saved to DBFS."
      },
      {
        "id": "C",
        "text": "An interactive input box will appear in the notebook; if the right password is provided, the connection will succeed and the password will be printed in plain text."
      },
      {
        "id": "D",
        "text": "The connection to the external table will succeed; the string value of password will be printed in plain text."
      },
      {
        "id": "E",
        "text": "The connection to the external table will succeed; the string \"REDACTED\" will be printed."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Replace a plaintext password variable with a Databricks secret and execute code that both uses the password and prints it.\n- Mechanism tested: Databricks secret redaction in notebook outputs.\n- Secrets retrieved via dbutils.secrets are usable as strings for authentication, but notebook output redacts them when displayed. So the connection can succeed, and printing the value shows “REDACTED”.\n\nWhy the other options are incorrect\n- A: Using a secret does not inherently break the connection; it’s still a valid string value for authentication.\n- B: Secrets do not prompt an interactive input box; they are retrieved programmatically.\n- C: No interactive prompt occurs, and the secret will not be printed in plain text.\n- D: The secret will not be printed in plain text due to automatic redaction.\n\nKey takeaway\n- Databricks secrets can be used in code, but displayed outputs are redacted (e.g., “REDACTED”).",
    "images": [
      "/questions/q006.webp"
    ],
    "docs": [
      {
        "title": "Databricks secrets (dbutils.secrets) and redaction",
        "query": "Databricks secrets redacted output"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 7,
    "question": "The data science team has created and logged a production model using MLflow. The following code correctly imports and applies the production model to output the predictions as a new DataFrame named preds with the schema \"customer_id LONG, predictions DOUBLE, date DATE\". The data science team would like predictions saved to a Delta Lake table with the ability to compare all predictions across time. Churn predictions will be made at most once per day. Which code block accomplishes this task while minimizing potential compute costs?",
    "choices": [
      {
        "id": "A",
        "text": "preds.write.mode(\"append\").saveAsTable(\"churn_preds\")"
      },
      {
        "id": "B",
        "text": "preds.write.format(\"delta\").save(\"/preds/churn_preds\")"
      },
      {
        "id": "C",
        "text": ""
      },
      {
        "id": "D",
        "text": ""
      },
      {
        "id": "E",
        "text": ""
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: Persist daily churn predictions to a Delta table so predictions can be compared across time, while minimizing compute cost.\n- Mechanism tested: Writing predictions to a managed Delta table with append semantics.\n- Option A appends each day’s preds DataFrame to a table (churn_preds). This preserves historical daily prediction rows for time-based comparison without rewriting prior data.\n\nWhy the other options are incorrect\n- B: Writing to a path with save(...) doesn’t create a managed table for easy querying/time comparisons, and (as written) doesn’t express an append-to-table pattern.\n- C: No option text provided, so it cannot be evaluated as a valid implementation.\n- D: No option text provided, so it cannot be evaluated as a valid implementation.\n- E: No option text provided, so it cannot be evaluated as a valid implementation.\n\nKey takeaway\n- To retain prediction history, append predictions to a Delta table rather than rewriting or writing to an unmanaged path.",
    "images": [
      "/questions/q007.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 8,
    "question": "An upstream source writes Parquet data as hourly batches to directories named with the current date. A nightly batch job runs the following code to ingest all data from the previous day as indicated by the date variable: Assume that the fields customer_id and order_id serve as a composite key to uniquely identify each order. If the upstream system is known to occasionally produce duplicate entries for a single order hours apart, which statement is correct?",
    "choices": [
      {
        "id": "A",
        "text": "Each write to the orders table will only contain unique records, and only those records without duplicates in the target table will be written."
      },
      {
        "id": "B",
        "text": "Each write to the orders table will only contain unique records, but newly written records may have duplicates already present in the target table."
      },
      {
        "id": "C",
        "text": "Each write to the orders table will only contain unique records; if existing records with the same key are present in the target table, these records will be overwritten."
      },
      {
        "id": "D",
        "text": "Each write to the orders table will only contain unique records; if existing records with the same key are present in the target table, the operation will fail."
      },
      {
        "id": "E",
        "text": "Each write to the orders table will run deduplication over the union of new and existing records, ensuring no duplicate records are present."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The upstream may output duplicate records for the same (customer_id, order_id) within the day being ingested; the job ingests “all data from the previous day”.\n- Mechanism tested: Deduplication scope in the ingestion code (batch-only vs. target-table-wide).\n- The correct statement is that the write for that day can be deduplicated within the incoming batch (so that day’s write has unique rows), but unless the code performs a key-based upsert/merge against the existing Delta table, duplicates that already exist in the target table can still remain.\n\nWhy the other options are incorrect\n- A: This claims duplicates in the target are prevented (“only those records without duplicates in the target table”); that would require an upsert/merge against the target, not just batch ingest.\n- C: Overwriting existing records with the same key requires an explicit merge/upsert or overwrite-by-key pattern, not a simple append ingest.\n- D: Failure on duplicate keys is not Delta’s default behavior for appends; it would require constraints/enforcement not stated in the question.\n- E: Deduplicating across the union of new + existing data would require reading the target and rewriting/merging; that’s not implied by a nightly ingest of yesterday’s files.\n\nKey takeaway\n- Batch deduplication only guarantees uniqueness within the incoming batch; preventing duplicates across history requires a key-based MERGE/UPSERT or a full-table rewrite strategy.",
    "images": [
      "/questions/q008.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 9,
    "question": "A junior member of the data engineering team is exploring the language interoperability of Databricks notebooks. The intended outcome of the below code is to register a view of all sales that occurred in countries on the continent of Africa that appear in the geo_lookup table. Before executing the code, running SHOW TABLES on the current database indicates the database contains only two tables: geo_lookup and sales. Which statement correctly describes the outcome of executing these command cells in order in an interactive notebook?",
    "choices": [
      {
        "id": "A",
        "text": "Both commands will succeed. Executing show tables will show that countries_af and sales_af have been registered as views."
      },
      {
        "id": "B",
        "text": "Cmd 1 will succeed. Cmd 2 will search all accessible databases for a table or view named countries_af: if this entity exists, Cmd 2 will succeed."
      },
      {
        "id": "C",
        "text": "Cmd 1 will succeed and Cmd 2 will fail. countries_af will be a Python variable representing a PySpark DataFrame."
      },
      {
        "id": "D",
        "text": "Both commands will fail. No new variables, tables, or views will be created."
      },
      {
        "id": "E",
        "text": "Cmd 1 will succeed and Cmd 2 will fail. countries_af will be a Python variable containing a list of strings."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Execute two notebook command cells in order, intending to register a view based on countries in geo_lookup and sales.\n- Mechanism tested: Databricks notebook language interoperability—Python variables are not directly resolvable inside a separate SQL command cell unless explicitly passed via supported mechanisms.\n- Cmd 1 (Python) can successfully create countries_af as an in-memory Python object representing a list of values. Cmd 2 (SQL) then fails because it cannot resolve the Python variable countries_af as a SQL table/view or inline list automatically.\n\nWhy the other options are incorrect\n- A: Cmd 2 would not succeed just because Cmd 1 ran; Python variables don’t automatically become SQL views.\n- B: Cmd 2 does not search “all accessible databases” for a Python variable; it only resolves SQL objects (tables/views/functions).\n- C: The answer describes countries_af as a DataFrame; the intended “countries” collection for an IN filter is more consistent with a list of strings than a DataFrame.\n- D: Cmd 1 does execute valid Python and can create a variable; it is not guaranteed to fail.\n- E is correct for the outcome: Cmd 1 succeeds, Cmd 2 fails, and countries_af is a Python list of strings.\n\nKey takeaway\n- Python variables created in one cell don’t automatically become SQL objects usable in a later SQL cell; you must explicitly create a view/table or pass values via supported interfaces.",
    "images": [
      "/questions/q009.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 10,
    "question": "A Delta table of weather records is partitioned by date and has the below schema: date DATE, device_id INT, temp FLOAT, latitude FLOAT, longitude FLOAT To find all the records from within the Arctic Circle, you execute a query with the below filter: latitude > 66.3 Which statement describes how the Delta engine identifies which files to load?",
    "choices": [
      {
        "id": "A",
        "text": "All records are cached to an operational database and then the filter is applied"
      },
      {
        "id": "B",
        "text": "The Parquet file footers are scanned for min and max statistics for the latitude column"
      },
      {
        "id": "C",
        "text": "All records are cached to attached storage and then the filter is applied"
      },
      {
        "id": "D",
        "text": "The Delta log is scanned for min and max statistics for the latitude column"
      },
      {
        "id": "E",
        "text": "The Hive metastore is scanned for min and max statistics for the latitude column"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: The table is partitioned by date, but the filter is on latitude (> 66.3). The engine must decide which files to read.\n- Mechanism tested: Delta Lake data skipping using file-level statistics stored in the Delta transaction log.\n- Delta stores min/max stats per column per file in the Delta log; the engine scans those stats to skip files that cannot satisfy latitude > 66.3.\n\nWhy the other options are incorrect\n- A/C: Delta does not “cache all records” to apply a filter; it prunes files before reading whenever possible.\n- B: Scanning Parquet footers is not the primary mechanism described for Delta tables; Delta uses the transaction log’s stored stats to decide file reads.\n- E: The Hive metastore does not store per-file min/max stats for Delta data skipping.\n\nKey takeaway\n- Delta uses transaction log file statistics (min/max) for data skipping, even when the filter column is not the partition column.",
    "images": [
      "/questions/q010.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 11,
    "question": "The data engineering team has configured a job to process customer requests to be forgotten (have their data deleted). All user data that needs to be deleted is stored in Delta Lake tables using default table settings. The team has decided to process all deletions from the previous week as a batch job at 1am each Sunday. The total duration of this job is less than one hour. Every Monday at 3am, a batch job executes a series of VACUUM commands on all Delta Lake tables throughout the organization. The compliance officer has recently learned about Delta Lake's time travel functionality. They are concerned that this might allow continued access to deleted data. Assuming all delete logic is correctly implemented, which statement correctly addresses this concern?",
    "choices": [
      {
        "id": "A",
        "text": "Because the VACUUM command permanently deletes all files containing deleted records, deleted records may be accessible with time travel for around 24 hours."
      },
      {
        "id": "B",
        "text": "Because the default data retention threshold is 24 hours, data files containing deleted records will be retained until the VACUUM job is run the following day."
      },
      {
        "id": "C",
        "text": "Because Delta Lake time travel provides full access to the entire history of a table, deleted records can always be recreated by users with full admin privileges."
      },
      {
        "id": "D",
        "text": "Because Delta Lake's delete statements have ACID guarantees, deleted records will be permanently purged from all storage systems as soon as a delete job completes."
      },
      {
        "id": "E",
        "text": "Because the default data retention threshold is 7 days, data files containing deleted records will be retained until the VACUUM job is run 8 days later."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Deleted data should not remain accessible via time travel; tables use default settings; VACUUM runs weekly deletions Sunday 1am and VACUUMs run every Monday 3am.\n- Mechanism tested: Delta Lake time travel + VACUUM retention window.\n- With default settings, Delta retains old files for 7 days. Even if deletes run correctly, the physical files containing deleted records are retained until they fall outside the 7‑day retention and are then removed by a subsequent VACUUM. Given the schedule, the VACUUM that can actually purge those files would occur after the retention window has passed—effectively around 8 days later in this weekly cadence.\n\nWhy the other options are incorrect\n- A: 24 hours is not the default retention window implied by the question’s “default table settings”.\n- B: 24 hours is not the default; also the concern is about time travel across the retention window, not just “until tomorrow”.\n- C: Time travel is constrained by retention and VACUUM; it is not “always possible” indefinitely by admins under default retention policies.\n- D: ACID guarantees correctness of the delete operation, not immediate physical purge of underlying files.\n\nKey takeaway\n- Deletes remove records logically, but time travel can still access prior versions until VACUUM removes old files after the retention period (default 7 days).",
    "images": [
      "/questions/q011.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 12,
    "question": "A junior data engineer has configured a workload that posts the following JSON to the Databricks REST API endpoint 2.0/jobs/create. Assuming that all configurations and referenced resources are available, which statement describes the result of executing this workload three times?",
    "choices": [
      {
        "id": "A",
        "text": "Three new jobs named \"Ingest new data\" will be defined in the workspace, and they will each run once daily."
      },
      {
        "id": "B",
        "text": "The logic defined in the referenced notebook will be executed three times on new clusters with the configurations of the provided cluster ID."
      },
      {
        "id": "C",
        "text": "Three new jobs named \"Ingest new data\" will be defined in the workspace, but no jobs will be executed."
      },
      {
        "id": "D",
        "text": "One new job named \"Ingest new data\" will be defined in the workspace, but it will not be executed."
      },
      {
        "id": "E",
        "text": "The logic defined in the referenced notebook will be executed three times on the referenced existing all purpose cluster."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: The workload calls the REST API endpoint 2.0/jobs/create three times.\n- Mechanism tested: Databricks Jobs API semantics—/jobs/create defines a job; it does not run it.\n- Therefore, each call creates a new job definition. Executing the request three times defines three jobs with the same name, but none of them execute just from creation.\n\nWhy the other options are incorrect\n- A: Creation alone does not execute runs; “will each run once daily” is not implied by calling /jobs/create.\n- B/E: These describe running the notebook three times; that would require a run endpoint (e.g., /jobs/run-now) or an immediate run trigger.\n- D: A single job would be created only if the API call updated an existing job; /jobs/create creates a new job per call.\n\nKey takeaway\n- /jobs/create creates job definitions; running jobs requires a separate run trigger.",
    "images": [
      "/questions/q012.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 13,
    "question": "An upstream system is emitting change data capture (CDC) logs that are being written to a cloud object storage    directory. Each record in the log indicates the change type (insert, update, or delete) and the values for each field after the change. The source table has a primary key identified by the field pk_id. For auditing purposes, the data governance team wishes to maintain a full record of all values that have ever been valid in the source system. For analytical purposes, only the most recent value for each record needs to be recorded. The Databricks job to ingest these records occurs once per hour, but each individual record may have changed multiple times over the course of an hour. Which solution meets these requirements?",
    "choices": [
      {
        "id": "A",
        "text": "Create a separate history table for each pk_id resolve the current state of the table by running a union all filtering the history tables for the most recent state."
      },
      {
        "id": "B",
        "text": "Use MERGE INTO to insert, update, or delete the most recent entry for each pk_id into a bronze table, then propagate all changes throughout the system."
      },
      {
        "id": "C",
        "text": "Iterate through an ordered set of changes to the table, applying each in turn; rely on Delta Lake's versioning ability to create an audit log."
      },
      {
        "id": "D",
        "text": "Use Delta Lake's change data feed to automatically process CDC data from an external system, propagating all changes to all dependent tables in the Lakehouse."
      },
      {
        "id": "E",
        "text": "Ingest all log information into a bronze table; use MERGE INTO to insert, update, or delete the most recent entry for each pk_id into a silver table to recreate the current table state."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Keep a full audit record of all values ever valid (history), but also maintain a current “most recent value per pk_id” view for analytics, even when a pk_id changes multiple times within an hour.\n- Mechanism tested: Using Delta Lake change tracking to propagate incremental changes and support both history and current-state tables.\n- Delta Lake’s Change Data Feed (CDF) provides a reliable, ordered stream of row-level changes (inserts/updates/deletes) between versions. Using CDF to drive downstream processing allows maintaining (1) a history/audit dataset of changes and (2) a Type 1 “current state” dataset by applying only the latest change per pk_id.\n\nWhy the other options are incorrect\n- A: Creating a separate table per pk_id is not scalable (millions of keys) and doesn’t match the requirement.\n- B: Merging only into a single bronze table does not address the requirement to preserve full historical validity values for auditing unless changes are retained separately.\n- C: Relying on table version history alone does not give a simple row-level audit trail without additional change extraction logic.\n- E: While a bronze+silver approach can build current state, it does not, by itself, provide a standardized change feed mechanism to drive dependent tables; the question’s requirement emphasizes maintaining “all values ever valid” reliably as changes occur, which is directly what CDF provides.\n\nKey takeaway\n- Use a row-level change stream (Delta Change Data Feed) to power both an audit/history view and an up-to-date current-state (Type 1) table.",
    "images": [
      "/questions/q013.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 14,
    "question": "An hourly batch job is configured to ingest data files from a cloud object storage container where each batch represent all records produced by the source system in a given hour. The batch job to process these records into the Lakehouse is sufficiently delayed to ensure no late-arriving data is missed. The user_id field represents a unique key for the data, which has the following schema: user_id BIGINT, username STRING, user_utc STRING, user_region STRING, last_login BIGINT, auto_pay BOOLEAN, last_updated BIGINT New records are all ingested into a table named account_history which maintains a full record of all data in the same schema as the source. The next table in the system is named account_current and is implemented as a Type 1 table representing the most recent value for each unique user_id. Assuming there are millions of user accounts and tens of thousands of records processed hourly, which implementation can be used to efficiently update the described account_current table as part of each hourly batch job?",
    "choices": [
      {
        "id": "A",
        "text": "Use Auto Loader to subscribe to new files in the account_history directory; configure a Structured Streaming trigger once job to batch update newly detected files into the account_current table."
      },
      {
        "id": "B",
        "text": "Overwrite the account_current table with each batch using the results of a query against the account_history table grouping by user_id and filtering for the max value of last_updated."
      },
      {
        "id": "C",
        "text": "Filter records in account_history using the last_updated field and the most recent hour processed, as well as the max last_iogin by user_id write a merge statement to update or insert the most recent value for each user_id."
      },
      {
        "id": "D",
        "text": "Use Delta Lake version history to get the difference between the latest version of account_history and one version prior, then write these records to account_current."
      },
      {
        "id": "E",
        "text": "Filter records in account_history using the last_updated field and the most recent hour processed, making sure to deduplicate on username; write a merge statement to update or insert the most recent value for each username."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Efficiently maintain account_current as a Type 1 table (latest row per user_id) given millions of users and hourly batches.\n- Mechanism tested: Incremental processing + MERGE INTO for Type 1 upserts.\n- Option C filters to only recently changed records (the hour being processed), resolves the latest record per user_id (using last_updated/last_login as needed), and MERGEs into account_current keyed by user_id—avoiding expensive full-table recomputation.\n\nWhy the other options are incorrect\n- A: Converting an hourly batch into a streaming trigger-once pipeline is unnecessary overhead for a described batch ingestion scenario.\n- B: Overwriting account_current each hour requires scanning and aggregating the full account_history (very expensive at this scale).\n- D: Delta version history alone doesn’t provide the needed per-user “latest record” logic; it also doesn’t directly yield a clean incremental update set without additional processing.\n- E: The unique key is user_id, not username; deduplicating/merging on username can produce incorrect results.\n\nKey takeaway\n- For large Type 1 tables, filter to the new/changed batch and MERGE by the true key (user_id) to update only what changed.",
    "images": [
      "/questions/q014.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 15,
    "question": "A table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information about customers derived from a number of upstream sources. Currently, the data engineering team populates this table nightly by overwriting the table with the current valid values derived from upstream data sources.   The churn prediction model used by the ML team is fairly stable in production. The team is only interested in making predictions on records that have changed in the past 24 hours. Which approach would simplify the identification of these changed records?",
    "choices": [
      {
        "id": "A",
        "text": "Apply the churn model to all rows in the customer_churn_params table, but implement logic to perform an upsert into the predictions table that ignores rows where predictions have not changed."
      },
      {
        "id": "B",
        "text": "Convert the batch job to a Structured Streaming job using the complete output mode; configure a Structured Streaming job to read from the customer_churn_params table and incrementally predict against the churn model."
      },
      {
        "id": "C",
        "text": "Calculate the difference between the previous model predictions and the current customer_churn_params on a key identifying unique customers before making new predictions; only make predictions on those customers not in the previous predictions."
      },
      {
        "id": "D",
        "text": "Modify the overwrite logic to include a field populated by calling spark.sql.functions.current_timestamp() as data are being written; use this field to identify records written on a particular date."
      },
      {
        "id": "E",
        "text": "Replace the current overwrite logic with a merge statement to modify only those records that have changed; write logic to make predictions on the changed records identified by the change data feed."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Only make predictions for records that changed in the past 24 hours; current pipeline overwrites the entire table nightly.\n- Mechanism tested: Delta Change Data Feed (CDF) + MERGE-based updates.\n- Replacing overwrite with MERGE updates only changed rows, which then makes it straightforward to identify those changes via CDF and run the churn model only for changed records—minimizing unnecessary compute.\n\nWhy the other options are incorrect\n- A: Still applies the model to all rows (high compute) and adds extra logic later.\n- B: Complete output mode repeatedly outputs full aggregations/state; it doesn’t directly solve “only changed rows” and can increase compute.\n- C: Comparing predictions to inputs adds an extra join step and still doesn’t directly identify which inputs changed without additional tracking.\n- D: Adding a current_timestamp during an overwrite marks all rows as “newly written” each run, which defeats identifying only truly changed records.\n\nKey takeaway\n- If you need “only changed rows,” avoid full overwrites and use MERGE + Change Data Feed to extract just the incremental changes.",
    "images": [
      "/questions/q015.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 16,
    "question": "A table is registered with the following code: Both users and orders are Delta Lake tables. Which statement describes the results of querying recent_orders?",
    "choices": [
      {
        "id": "A",
        "text": "All logic will execute at query time and return the result of joining the valid versions of the source tables at the time the query finishes."
      },
      {
        "id": "B",
        "text": "All logic will execute when the table is defined and store the result of joining tables to the DBFS; this stored data will be returned when the table is queried."
      },
      {
        "id": "C",
        "text": "Results will be computed and cached when the table is defined; these cached results will incrementally update as new records are inserted into source tables."
      },
      {
        "id": "D",
        "text": "All logic will execute at query time and return the result of joining the valid versions of the source tables at the time the query began."
      },
      {
        "id": "E",
        "text": "The versions of each source table will be stored in the table transaction log; query results will be saved to DBFS with each query."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A table is registered from a query joining two Delta tables (users and orders), then recent_orders is queried.\n- Mechanism tested: Logical vs. materialized results and Delta’s snapshot isolation.\n- A registered view/table definition like this is evaluated at query time; when the query begins, Delta chooses a consistent snapshot (a “valid version”) of each source table. The join runs against those versions for the duration of the query, so results reflect the state as of query start.\n\nWhy the other options are incorrect\n- A: Delta does not switch snapshots mid-query based on when the query finishes; consistency is based on the snapshot at query start.\n- B: Defining the object does not materialize and store joined results to DBFS unless explicitly written/materialized.\n- C: There is no guarantee of an automatically maintained incremental cache of join results.\n- E: Source table versions are recorded in their own transaction logs; queries do not “save results to DBFS with each query” as part of versioning.\n\nKey takeaway\n- Delta provides snapshot isolation: a query reads consistent versions of tables as of the time the query starts.",
    "images": [
      "/questions/q016.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 17,
    "question": "A production workload incrementally applies updates from an external Change Data Capture feed to a Delta Lake table as an always-on Structured Stream job. When data was initially migrated for this table, OPTIMIZE was executed and most data files were resized to 1 GB. Auto Optimize and Auto Compaction were both turned on for the streaming production job. Recent review of data files shows that most data files are under 64 MB, although each partition in the table contains at least 1 GB of data and the total table size is over 10 TB. Which of the following likely explains these smaller file sizes?",
    "choices": [
      {
        "id": "A",
        "text": "Databricks has autotuned to a smaller target file size to reduce duration of MERGE operations"
      },
      {
        "id": "B",
        "text": "Z-order indices calculated on the table are preventing file compaction"
      },
      {
        "id": "C",
        "text": "Bloom filter indices calculated on the table are preventing file compaction"
      },
      {
        "id": "D",
        "text": "Databricks has autotuned to a smaller target file size based on the overall size of data in the table"
      },
      {
        "id": "E",
        "text": "Databricks has autotuned to a smaller target file size based on the amount of data in each partition"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: Streaming job with MERGE-like updates results in many small (<64 MB) files despite Auto Optimize + Auto Compaction and plenty of data per partition.\n- Mechanism tested: Databricks auto-tuning of file sizes for write patterns (especially MERGE/upserts).\n- For workloads dominated by frequent MERGE/upsert operations, Databricks may target smaller files to reduce the amount of data rewritten per operation, improving MERGE performance—leading to many small files.\n\nWhy the other options are incorrect\n- B/C: Z-order or Bloom filters do not “prevent” compaction; they don’t explain persistent small-file creation in this scenario.\n- D/E: The observation is small files despite large partitions/table; the more direct explanation is tuning for MERGE characteristics rather than overall table/partition size alone.\n\nKey takeaway\n- With frequent incremental updates (e.g., MERGE), Databricks can prefer smaller target files to improve update performance, which can increase small-file counts.",
    "images": [
      "/questions/q017.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 18,
    "question": "Which statement regarding stream-static joins and static Delta tables is correct?",
    "choices": [
      {
        "id": "A",
        "text": "Each microbatch of a stream-static join will use the most recent version of the static Delta table as of each microbatch."
      },
      {
        "id": "B",
        "text": "Each microbatch of a stream-static join will use the most recent version of the static Delta table as of the job's initialization."
      },
      {
        "id": "C",
        "text": "The checkpoint directory will be used to track state information for the unique keys present in the join."
      },
      {
        "id": "D",
        "text": "Stream-static joins cannot use static Delta tables because of consistency issues."
      },
      {
        "id": "E",
        "text": "The checkpoint directory will be used to track updates to the static Delta table."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Understand how a stream-static join behaves when the static side is a Delta table.\n- Mechanism tested: Structured Streaming initialization snapshot behavior for static inputs.\n- In a stream-static join, the “static” Delta table is loaded as a snapshot when the streaming query starts. Each microbatch joins against that same snapshot unless the query is restarted.\n\nWhy the other options are incorrect\n- A: Using “most recent version as of each microbatch” would imply the static table is reloaded every microbatch, which is not the default behavior.\n- C/E: The checkpoint tracks streaming progress/state; it does not track updates to the static table.\n- D: Stream-static joins can use static Delta tables; consistency is handled via snapshotting.\n\nKey takeaway\n- In stream-static joins, the static Delta table is effectively a fixed snapshot from query start; refresh it by restarting the stream.",
    "images": [
      "/questions/q018.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 19,
    "question": "A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity and average temperature for each non- overlapping five-minute interval. Events are recorded once per minute per device. Streaming DataFrame df has the following schema: \"device_id INT, event_time TIMESTAMP, temp FLOAT, humidity FLOAT\" Code block:    Choose the response that correctly fills in the blank within the code block to complete this task.",
    "choices": [
      {
        "id": "A",
        "text": "to_interval(\"event_time\", \"5 minutes\").alias(\"time\")"
      },
      {
        "id": "B",
        "text": "window(\"event_time\", \"5 minutes\").alias(\"time\")"
      },
      {
        "id": "C",
        "text": "\"event_time\""
      },
      {
        "id": "D",
        "text": "window(\"event_time\", \"10 minutes\").alias(\"time\")"
      },
      {
        "id": "E",
        "text": "lag(\"event_time\", \"10 minutes\").alias(\"time\")"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Grouped aggregation over non-overlapping 5-minute intervals using event_time in a streaming DataFrame.\n- Mechanism tested: Structured Streaming windowing with tumbling windows.\n- window(\"event_time\", \"5 minutes\") creates 5-minute time windows suitable for grouping and aggregating (avg humidity/temp) per device per interval.\n\nWhy the other options are incorrect\n- A: to_interval(...) is not the standard windowing function used for streaming time windows in this pattern.\n- C: Grouping by raw event_time would aggregate per timestamp, not per 5-minute interval.\n- D: 10-minute windows do not meet the 5-minute requirement.\n- E: lag(...) is a window function for offsetting rows, not creating time buckets for grouped aggregation.\n\nKey takeaway\n- Use window(timestamp_col, \"duration\") to build time-bucketed aggregations in Structured Streaming.",
    "images": [
      "/questions/q019.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 20,
    "question": "A data architect has designed a system in which two Structured Streaming jobs will concurrently write to a single bronze Delta table. Each job is subscribing to a different topic from an Apache Kafka source, but they will write data with the same schema. To keep the directory structure simple, a data engineer has decided to nest a checkpoint directory to be shared by both streams. The proposed directory structure is displayed below: Which statement describes whether this checkpoint directory structure is valid for the given scenario and why?",
    "choices": [
      {
        "id": "A",
        "text": "No; Delta Lake manages streaming checkpoints in the transaction log."
      },
      {
        "id": "B",
        "text": "Yes; both of the streams can share a single checkpoint directory."
      },
      {
        "id": "C",
        "text": "No; only one stream can write to a Delta Lake table."
      },
      {
        "id": "D",
        "text": "Yes; Delta Lake supports infinite concurrent writers."
      },
      {
        "id": "E",
        "text": "No; each of the streams needs to have its own checkpoint directory."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Two separate Structured Streaming queries will concurrently write to the same Delta table; proposal is to share/nest a checkpoint directory.\n- Mechanism tested: Structured Streaming checkpoint isolation.\n- Each streaming query needs its own checkpoint directory because the checkpoint stores query-specific progress and state. Sharing a checkpoint risks corrupting offsets/state and is not supported.\n\nWhy the other options are incorrect\n- A: Delta’s transaction log is not a replacement for streaming checkpoints; checkpoints are still required for streaming progress/state.\n- B: Two streams cannot share one checkpoint directory safely because their offsets and state are different.\n- C: Multiple streams can write to the same Delta table; the issue is checkpoint sharing, not “only one stream can write”.\n- D: “Infinite concurrent writers” is not the relevant concept; correctness depends on independent checkpoints.\n\nKey takeaway\n- One checkpoint directory per streaming query; never share checkpoints across different streams.",
    "images": [
      "/questions/q020.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 21,
    "question": "A Structured Streaming job deployed to production has been experiencing delays during peak hours of the day. At   present, during normal execution, each microbatch of data is processed in less than 3 seconds. During peak hours of the day, execution time for each microbatch becomes very inconsistent, sometimes exceeding 30 seconds. The streaming write is currently configured with a trigger interval of 10 seconds. Holding all other variables constant and assuming records need to be processed in less than 10 seconds, which adjustment will meet the requirement?",
    "choices": [
      {
        "id": "A",
        "text": "Decrease the trigger interval to 5 seconds; triggering batches more frequently allows idle executors to begin processing the next batch while longer running tasks from previous batches finish."
      },
      {
        "id": "B",
        "text": "Increase the trigger interval to 30 seconds; setting the trigger interval near the maximum execution time observed for each batch is always best practice to ensure no records are dropped."
      },
      {
        "id": "C",
        "text": "The trigger interval cannot be modified without modifying the checkpoint directory; to maintain the current stream state, increase the number of shuffle partitions to maximize parallelism."
      },
      {
        "id": "D",
        "text": "Use the trigger once option and configure a Databricks job to execute the query every 10 seconds; this ensures all backlogged records are processed with each batch."
      },
      {
        "id": "E",
        "text": "Decrease the trigger interval to 5 seconds; triggering batches more frequently may prevent records from backing up and large batches from causing spill."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Records must be processed in <10 seconds; current trigger is 10s, but peak hours cause some microbatches to take up to 30s, creating backlogs.\n- Mechanism tested: Trigger interval vs. batch size/backpressure behavior in micro-batch streaming.\n- Decreasing the trigger interval to 5 seconds can reduce how many records accumulate between triggers, which helps prevent large, spill-prone microbatches and reduces the chance of falling behind the latency requirement.\n\nWhy the other options are incorrect\n- A: Spark does not process overlapping microbatches concurrently by simply lowering the trigger; long tasks from a prior batch don’t enable parallel processing of the next batch in that way.\n- B: Increasing the trigger to 30 seconds violates the requirement that records be processed in <10 seconds.\n- C: Changing trigger interval does not require changing the checkpoint; the proposed dependency is incorrect.\n- D: Trigger once executed every 10 seconds via jobs is not equivalent to continuous streaming with state/progress; it also doesn’t address the backlog/latency requirement reliably.\n\nKey takeaway\n- If you’re missing latency SLOs due to variable batch times, reducing trigger interval can reduce per-batch input size and help prevent backlogs.",
    "images": [
      "/questions/q021.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 22,
    "question": "Which statement describes Delta Lake Auto Compaction?",
    "choices": [
      {
        "id": "A",
        "text": "An asynchronous job runs after the write completes to detect if files could be further compacted; if yes, an OPTIMIZE job is executed toward a default of 1 GB."
      },
      {
        "id": "B",
        "text": "Before a Jobs cluster terminates, OPTIMIZE is executed on all tables modified during the most recent job."
      },
      {
        "id": "C",
        "text": "Optimized writes use logical partitions instead of directory partitions; because partition boundaries are only represented in metadata, fewer small files are written."
      },
      {
        "id": "D",
        "text": "Data is queued in a messaging bus instead of committing data directly to memory; all data is committed from the messaging bus in one batch once the job is complete."
      },
      {
        "id": "E",
        "text": "An asynchronous job runs after the write completes to detect if files could be further compacted; if yes, an OPTIMIZE job is executed toward a default of 128 MB."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Identify what “Delta Lake Auto Compaction” does.\n- Mechanism tested: Auto Compaction behavior and target file size.\n- Auto Compaction runs asynchronously after writes to detect and compact small files, effectively executing an OPTIMIZE-like compaction toward a smaller default target (commonly ~128 MB) to reduce small-file problems.\n\nWhy the other options are incorrect\n- A: Auto Compaction targets smaller files than 1 GB; 1 GB is more aligned with manual OPTIMIZE defaults, not auto compaction’s typical target.\n- B: There is no rule that OPTIMIZE runs before a job cluster terminates on all modified tables.\n- C: Partitioning is still directory-based for Delta; this is not what “optimized writes” means.\n- D: Auto Compaction is not a messaging bus or deferred commit mechanism.\n\nKey takeaway\n- Auto Compaction is an asynchronous small-file compaction step after writes, typically compacting toward ~128 MB files.",
    "images": [
      "/questions/q022.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 23,
    "question": "Which statement characterizes the general programming model used by Spark Structured Streaming?",
    "choices": [
      {
        "id": "A",
        "text": "Structured Streaming leverages the parallel processing of GPUs to achieve highly parallel data throughput."
      },
      {
        "id": "B",
        "text": "Structured Streaming is implemented as a messaging bus and is derived from Apache Kafka."
      },
      {
        "id": "C",
        "text": "Structured Streaming uses specialized hardware and I/O streams to achieve sub-second latency for data transfer."
      },
      {
        "id": "D",
        "text": "Structured Streaming models new data arriving in a data stream as new rows appended to an unbounded table."
      },
      {
        "id": "E",
        "text": "Structured Streaming relies on a distributed network of nodes that hold incremental state values for cached stages."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Describe the general programming model of Spark Structured Streaming.\n- Mechanism tested: Structured Streaming’s unbounded table abstraction.\n- Structured Streaming treats a stream as an unbounded table where new events arrive as new rows; users write queries as if over tables, and Spark runs them incrementally.\n\nWhy the other options are incorrect\n- A: Structured Streaming is not GPU-based by definition.\n- B: It is not derived from Kafka; Kafka is just one possible source.\n- C: It does not require specialized hardware or imply sub-second transfer by hardware design.\n- E: While state can be maintained for some queries, “cached stages” and that description do not define the programming model.\n\nKey takeaway\n- Think “stream = unbounded table”; Structured Streaming incrementally updates query results as new rows arrive.",
    "images": [
      "/questions/q023.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 24,
    "question": "Which configuration parameter directly affects the size of a spark-partition upon ingestion of data into Spark?",
    "choices": [
      {
        "id": "A",
        "text": "spark.sql.files.maxPartitionBytes"
      },
      {
        "id": "B",
        "text": "spark.sql.autoBroadcastJoinThreshold"
      },
      {
        "id": "C",
        "text": "spark.sql.files.openCostInBytes"
      },
      {
        "id": "D",
        "text": "spark.sql.adaptive.coalescePartitions.minPartitionNum"
      },
      {
        "id": "E",
        "text": "spark.sql.adaptive.advisoryPartitionSizeInBytes"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: Which config directly affects the size of a Spark partition when ingesting files.\n- Mechanism tested: File source partition sizing.\n- spark.sql.files.maxPartitionBytes sets the maximum number of bytes per partition when Spark reads file-based data sources, directly controlling initial partition sizes.\n\nWhy the other options are incorrect\n- B: autoBroadcastJoinThreshold controls broadcast join behavior, not file ingestion partition sizing.\n- C: openCostInBytes is a heuristic used along with maxPartitionBytes; it influences planning but does not directly set the partition size limit.\n- D/E: Adaptive coalescing/advisory sizes apply during AQE shuffle partition coalescing, not initial ingestion partition sizing.\n\nKey takeaway\n- For file reads, spark.sql.files.maxPartitionBytes is the primary knob for input partition sizing.",
    "images": [
      "/questions/q024.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 25,
    "question": "A Spark job is taking longer than expected. Using the Spark UI, a data engineer notes that the Min, Median, and Max Durations for tasks in a particular stage show the minimum and median time to complete a task as roughly the same, but the max duration for a task to be roughly 100 times as long as the minimum. Which situation is causing increased duration of the overall job?",
    "choices": [
      {
        "id": "A",
        "text": "Task queueing resulting from improper thread pool assignment."
      },
      {
        "id": "B",
        "text": "Spill resulting from attached volume storage being too small."
      },
      {
        "id": "C",
        "text": "Network latency due to some cluster nodes being in different regions from the source data"
      },
      {
        "id": "D",
        "text": "Skew caused by more data being assigned to a subset of spark-partitions."
      },
      {
        "id": "E",
        "text": "Credential validation errors while pulling data from an external system."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Explain why a stage has similar min/median task durations but a max duration ~100x longer.\n- Mechanism tested: Data skew in partitions.\n- This pattern indicates most tasks process similar amounts of data, but a few tasks handle disproportionately large partitions, taking far longer and extending the stage’s completion time—classic skew.\n\nWhy the other options are incorrect\n- A: Task queueing/thread pool issues would affect many tasks broadly, not create a small number of extreme outliers.\n- B: Spill can slow tasks, but the described “few extremely slow tasks” pattern is more directly explained by skewed partition sizes.\n- C: Cross-region node placement is not implied by the question and would generally degrade many tasks, not just a few outliers.\n- E: Credential validation errors would usually fail tasks rather than produce a few very slow tasks.\n\nKey takeaway\n- A small number of very slow tasks relative to the median is a strong indicator of partition/data skew.",
    "images": [
      "/questions/q025.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 26,
    "question": "Each configuration below is identical to the extent that each cluster has 400 GB total of RAM, 160 total cores and only one Executor per VM. Given a job with at least one wide transformation, which of the following cluster configurations will result in maximum performance?",
    "choices": [
      {
        "id": "A",
        "text": "• Total VMs; 1 • 400 GB per Executor • 160 Cores / Executor"
      },
      {
        "id": "B",
        "text": "• Total VMs: 8 • 50 GB per Executor • 20 Cores / Executor"
      },
      {
        "id": "C",
        "text": "• Total VMs: 16 • 25 GB per Executor • 10 Cores/Executor"
      },
      {
        "id": "D",
        "text": "• Total VMs: 4 • 100 GB per Executor • 40 Cores/Executor"
      },
      {
        "id": "E",
        "text": "• Total VMs:2 • 200 GB per Executor • 80 Cores / Executor"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the cluster layout (same total cores/RAM) that maximizes performance for a job with at least one wide transformation (shuffle).\n- Mechanism tested: Shuffle overhead vs. distribution across executors/nodes.\n- With a single VM/executor (option A), shuffle does not require exchanging data across multiple executors/nodes, minimizing network and coordination overhead under the constraint that total compute resources are the same.\n\nWhy the other options are incorrect\n- B/C/D/E: Spreading the same total cores/RAM across more VMs introduces shuffle network transfer, more remote reads/writes, and more coordination overhead for wide transformations, which can reduce performance when total resources are fixed.\n\nKey takeaway\n- With fixed total resources, wide transformations pay shuffle overhead; fewer nodes can reduce network shuffle overhead (though in practice there are other tradeoffs).",
    "images": [
      "/questions/q026.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 27,
    "question": "A junior data engineer on your team has implemented the following code block. The view new_events contains a batch of records with the same schema as the events Delta table. The event_id field serves as a unique key for this table. When this query is executed, what will happen with new records that have the same event_id as an existing record?",
    "choices": [
      {
        "id": "A",
        "text": "They are merged."
      },
      {
        "id": "B",
        "text": "They are ignored."
      },
      {
        "id": "C",
        "text": "They are updated."
      },
      {
        "id": "D",
        "text": "They are inserted."
      },
      {
        "id": "E",
        "text": "They are deleted."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Determine what happens to incoming rows whose event_id already exists in the target Delta table when executing the shown code block.\n- Mechanism tested: MERGE INTO semantics when no matched-action is specified (common pattern: WHEN NOT MATCHED THEN INSERT).\n- If the statement only inserts non-matching keys (and does not include a WHEN MATCHED UPDATE/DELETE), then rows with event_id already present are not changed—i.e., they are ignored.\n\nWhy the other options are incorrect\n- A/C/D/E: Merging, updating, inserting-on-match, or deleting would require explicit WHEN MATCHED clauses; the provided correct outcome indicates those clauses are not present for matched keys.\n\nKey takeaway\n- In a MERGE, existing-key behavior depends on the WHEN MATCHED clauses; with only “insert when not matched,” matching keys are ignored.",
    "images": [
      "/questions/q027.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 28,
    "question": "A junior data engineer seeks to leverage Delta Lake's Change Data Feed functionality to create a Type 1 table representing all of the values that have ever been valid for all rows in a bronze table created with the property delta.enableChangeDataFeed = true. They plan to execute the following code as a daily job: Which statement describes the execution and results of running the above query multiple times?",
    "choices": [
      {
        "id": "A",
        "text": "Each time the job is executed, newly updated records will be merged into the target table, overwriting previous values with the same primary keys."
      },
      {
        "id": "B",
        "text": "Each time the job is executed, the entire available history of inserted or updated records will be appended to the target table, resulting in many duplicate entries."
      },
      {
        "id": "C",
        "text": "Each time the job is executed, the target table will be overwritten using the entire history of inserted or updated records, giving the desired result."
      },
      {
        "id": "D",
        "text": "Each time the job is executed, the differences between the original and current versions are calculated; this may result in duplicate entries for some records."
      },
      {
        "id": "E",
        "text": "Each time the job is executed, only those records that have been inserted or updated since the last execution will be appended to the target table, giving the desired result."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Run a daily job reading Delta Change Data Feed to build a table of “all values that have ever been valid,” and understand what happens if the job is run multiple times.\n- Mechanism tested: Change Data Feed read range control (startingVersion/startingTimestamp) and idempotency.\n- If the query reads the entire available CDF history each time (i.e., no “start from last processed version” logic) and appends results, then every run re-appends historical changes, producing many duplicates.\n\nWhy the other options are incorrect\n- A: MERGE/upsert behavior would require a merge into the target keyed on primary keys; pure append doesn’t overwrite prior duplicates.\n- C: Overwriting the target each run is not what an append-based CDF history build does (and would also discard prior appended history unless recomputed).\n- D: “Differences between original and current versions” is not the same as reading CDF changes, and doesn’t explain repeated full-history appends.\n- E: Appending only since the last execution requires tracking and setting the startingVersion/startingTimestamp to the last processed point; that’s not implied in the described repeated-run behavior.\n\nKey takeaway\n- CDF reads are not automatically incremental across runs; you must explicitly bound the read range (start from last processed version) to avoid duplicates.",
    "images": [
      "/questions/q028.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 29,
    "question": "A new data engineer notices that a critical field was omitted from an application that writes its Kafka source to Delta Lake. This happened even though the critical field was in the Kafka source. That field was further missing from data written to dependent, long-term storage. The retention threshold on the Kafka service is seven days. The pipeline has been in production for three months. Which describes how Delta Lake can help to avoid data loss of this nature in the future?",
    "choices": [
      {
        "id": "A",
        "text": "The Delta log and Structured Streaming checkpoints record the full history of the Kafka producer."
      },
      {
        "id": "B",
        "text": "Delta Lake schema evolution can retroactively calculate the correct value for newly added fields, as long as the data was in the original source."
      },
      {
        "id": "C",
        "text": "Delta Lake automatically checks that all fields present in the source data are included in the ingestion layer."
      },
      {
        "id": "D",
        "text": "Data can never be permanently dropped or deleted from Delta Lake, so data loss is not possible under any circumstance."
      },
      {
        "id": "E",
        "text": "Ingesting all raw data and metadata from Kafka to a bronze Delta table creates a permanent, replayable history of the data state."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Avoid future data loss when a downstream pipeline accidentally omits a field, given Kafka retention is only 7 days and the pipeline has been running for months.\n- Mechanism tested: Bronze-layer design for replayability in the lakehouse.\n- Writing all raw Kafka data (and metadata) into a bronze Delta table creates a durable, long-term, replayable record beyond Kafka’s retention. If a field is later added/fixed, downstream tables can be rebuilt/replayed from bronze without relying on Kafka still having old messages.\n\nWhy the other options are incorrect\n- A: Checkpoints/logs do not preserve the full producer history required to reconstruct months-old missing fields once Kafka has expired messages.\n- B: Schema evolution can add columns going forward; it cannot retroactively “calculate” missing historical values if the pipeline never stored them in durable storage.\n- C: Delta does not automatically guarantee all source fields were written; it writes what the ingestion logic selects.\n- D: Data can be deleted from Delta (e.g., delete + vacuum); “data loss is not possible” is false.\n\nKey takeaway\n- Persist raw source data in a bronze Delta table so you can replay and rebuild downstream datasets even when the source system’s retention is limited.",
    "images": [
      "/questions/q029.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 30,
    "question": "A nightly job ingests data into a Delta Lake table using the following code: The next step in the pipeline requires a function that returns an object that can be used to manipulate new records that have not yet been processed to the next table in the pipeline. Which code snippet completes this function definition? def new_records():",
    "choices": [
      {
        "id": "A",
        "text": "return spark.readStream.table(\"bronze\")"
      },
      {
        "id": "B",
        "text": "return spark.readStream.load(\"bronze\")"
      },
      {
        "id": "C",
        "text": ""
      },
      {
        "id": "D",
        "text": "return spark.read.option(\"readChangeFeed\", \"true\").table (\"bronze\")"
      },
      {
        "id": "E",
        "text": ""
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: After a nightly ingest to a bronze Delta table, the next step needs a function returning an object usable to manipulate “new records not yet processed” downstream.\n- Mechanism tested: Delta Change Data Feed read API to retrieve incremental changes from a Delta table.\n- Option D reads the bronze Delta table using readChangeFeed, returning a DataFrame of changes (new/updated/deleted rows) that can be filtered and processed as “new records” since prior versions.\n\nWhy the other options are incorrect\n- A: readStream.table(\"bronze\") creates a streaming source; the requirement describes a nightly batch step needing a manipulable object for the newly ingested records, not an always-on stream.\n- B: readStream.load(\"bronze\") is not the correct pattern for reading a registered table named “bronze,” and it still implies streaming rather than an incremental batch of new changes.\n- C: No option text provided, so it cannot be evaluated as a valid implementation.\n- E: No option text provided, so it cannot be evaluated as a valid implementation.\n\nKey takeaway\n- Use Delta Change Data Feed (readChangeFeed=true) to obtain incremental changes from a Delta table for downstream processing.",
    "images": [
      "/questions/q030.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 31,
    "question": "A junior data engineer is working to implement logic for a Lakehouse table named silver_device_recordings. The source data contains 100 unique fields in a highly nested JSON structure. The silver_device_recordings table will be used downstream to power several production monitoring dashboards and a production model. At present, 45 of the 100 fields are being used in at least one of these applications. The data engineer is trying to determine the best approach for dealing with schema declaration given the highly- nested structure of the data and the numerous fields. Which of the following accurately presents information about Delta Lake and Databricks that may impact their decision-making process?",
    "choices": [
      {
        "id": "A",
        "text": "The Tungsten encoding used by Databricks is optimized for storing string data; newly-added native support for querying JSON strings means that string types are always most efficient."
      },
      {
        "id": "B",
        "text": "Because Delta Lake uses Parquet for data storage, data types can be easily evolved by just modifying file footer information in place."
      },
      {
        "id": "C",
        "text": "Human labor in writing code is the largest cost associated with data engineering workloads; as such, automating table declaration logic should be a priority in all migration workloads."
      },
      {
        "id": "D",
        "text": "Because Databricks will infer schema using types that allow all observed data to be processed, setting types manually provides greater assurance of data quality enforcement."
      },
      {
        "id": "E",
        "text": "Schema inference and evolution on Databricks ensure that inferred types will always accurately match the data types used by downstream systems."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A junior data engineer is working to implement logic for a Lakehouse table named silver_device_recordings. The source data contains 100 unique fields in a highly nested JSON str...\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why D is correct: Because Databricks will infer schema using types that allow all observed data to be processed, setting types manually provides greater assurance of data quality enforcement. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The Tungsten encoding used by Databricks is optimized for storing string data; newly-added native support for querying JSON strings means that string types are always most efficient. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n- B: Because Delta Lake uses Parquet for data storage, data types can be easily evolved by just modifying file footer information in place. is wrong because Parquet files are immutable; schema changes require writing new files/metadata rather than editing footers in place.\n- C: Human labor in writing code is the largest cost associated with data engineering workloads; as such, automating table declaration logic should be a priority in all migration workloads. is wrong because it’s a cost/priority claim, not a Databricks/Delta mechanism that answers the schema decision in the question.\n- E: Schema inference and evolution on Databricks ensure that inferred types will always accurately match the data types used by downstream systems. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q031.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 32,
    "question": "The data engineering team maintains the following code:   Assuming that this code produces logically correct results and the data in the source tables has been de- duplicated and validated, which statement describes what will occur when this code is executed?",
    "choices": [
      {
        "id": "A",
        "text": "A batch job will update the enriched_itemized_orders_by_account table, replacing only those rows that have different values than the current version of the table, using accountID as the primary key."
      },
      {
        "id": "B",
        "text": "The enriched_itemized_orders_by_account table will be overwritten using the current valid version of data in each of the three tables referenced in the join logic."
      },
      {
        "id": "C",
        "text": "An incremental job will leverage information in the state store to identify unjoined rows in the source tables and write these rows to the enriched_iteinized_orders_by_account table."
      },
      {
        "id": "D",
        "text": "An incremental job will detect if new rows have been written to any of the source tables; if new rows are detected, all results will be recalculated and used to overwrite the enriched_itemized_orders_by_account table."
      },
      {
        "id": "E",
        "text": "No computation will occur until enriched_itemized_orders_by_account is queried; upon query materialization, results will be calculated using the current valid version of data in each of the three tables referenced in the join logic."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source tables has been de- duplicated and...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: The enriched_itemized_orders_by_account table will be overwritten using the current valid version of data in each of the three tables referenced in the join logic. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: A batch job will update the enriched_itemized_orders_by_account table, replacing only those rows that have different values than the current version of the table, using accountID as the primary key. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source tables has been de- duplicated and...) as stated.\n- C: An incremental job will leverage information in the state store to identify unjoined rows in the source tables and write these rows to the enriched_iteinized_orders_by_account table. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source tables has been de- duplicated and...) as stated.\n- D: An incremental job will detect if new rows have been written to any of the source tables; if new rows are detected, all results will be recalculated and used to overwrite the enriched_itemized_orders_by_account table. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source tables has been de- duplicated and...) as stated.\n- E: No computation will occur until enriched_itemized_orders_by_account is queried; upon query materialization, results will be calculated using the current valid version of data in each of the three tables referenced in the join logic. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source tables has been de- duplicated and...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q032.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 33,
    "question": "The data engineering team is migrating an enterprise system with thousands of tables and views into the Lakehouse. They plan to implement the target architecture using a series of bronze, silver, and gold tables. Bronze tables will almost exclusively be used by production data engineering workloads, while silver tables will be used to support both data engineering and machine learning workloads. Gold tables will largely serve business intelligence and reporting purposes. While personal identifying information (PII) exists in all tiers of data, pseudonymization and anonymization rules are in place for all data at the silver and gold levels. The organization is interested in reducing security concerns while maximizing the ability to collaborate across diverse teams. Which statement exemplifies best practices for implementing this system?",
    "choices": [
      {
        "id": "A",
        "text": "Isolating tables in separate databases based on data quality tiers allows for easy permissions management through database ACLs and allows physical separation of default storage locations for managed tables."
      },
      {
        "id": "B",
        "text": "Because databases on Databricks are merely a logical construct, choices around database organization do not impact security or discoverability in the Lakehouse."
      },
      {
        "id": "C",
        "text": "Storing all production tables in a single database provides a unified view of all data assets available throughout the Lakehouse, simplifying discoverability by granting all users view privileges on this database."
      },
      {
        "id": "D",
        "text": "Working in the default Databricks database provides the greatest security when working with managed tables, as these will be created in the DBFS root."
      },
      {
        "id": "E",
        "text": "Because all tables must live in the same storage containers used for the database they're created in, organizations should be prepared to create between dozens and thousands of databases depending on their data isolation requirements."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: The data engineering team is migrating an enterprise system with thousands of tables and views into the Lakehouse. They plan to implement the target architecture using a series...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: Isolating tables in separate databases based on data quality tiers allows for easy permissions management through database ACLs and allows physical separation of default storage locations for managed tables. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Because databases on Databricks are merely a logical construct, choices around database organization do not impact security or discoverability in the Lakehouse. is wrong because it does not satisfy the requirement in the question (The data engineering team is migrating an enterprise system with thousands of tables and views into the Lakehouse. They plan to implement the target architecture using a series...) as stated.\n- C: Storing all production tables in a single database provides a unified view of all data assets available throughout the Lakehouse, simplifying discoverability by granting all users view privileges on this database. is wrong because it does not satisfy the requirement in the question (The data engineering team is migrating an enterprise system with thousands of tables and views into the Lakehouse. They plan to implement the target architecture using a series...) as stated.\n- D: Working in the default Databricks database provides the greatest security when working with managed tables, as these will be created in the DBFS root. is wrong because it does not satisfy the requirement in the question (The data engineering team is migrating an enterprise system with thousands of tables and views into the Lakehouse. They plan to implement the target architecture using a series...) as stated.\n- E: Because all tables must live in the same storage containers used for the database they're created in, organizations should be prepared to create between dozens and thousands of databases depending on their data isolation requirements. is wrong because it does not satisfy the requirement in the question (The data engineering team is migrating an enterprise system with thousands of tables and views into the Lakehouse. They plan to implement the target architecture using a series...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q033.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 34,
    "question": "The data architect has mandated that all tables in the Lakehouse should be configured as external Delta Lake tables. Which approach will ensure that this requirement is met?",
    "choices": [
      {
        "id": "A",
        "text": "Whenever a database is being created, make sure that the LOCATION keyword is used"
      },
      {
        "id": "B",
        "text": "When configuring an external data warehouse for all table storage, leverage Databricks for all ELT."
      },
      {
        "id": "C",
        "text": "Whenever a table is being created, make sure that the LOCATION keyword is used."
      },
      {
        "id": "D",
        "text": "When tables are created, make sure that the EXTERNAL keyword is used in the CREATE TABLE statement."
      },
      {
        "id": "E",
        "text": "When the workspace is being configured, make sure that external cloud object storage has been mounted."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: The data architect has mandated that all tables in the Lakehouse should be configured as external Delta Lake tables.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: Whenever a table is being created, make sure that the LOCATION keyword is used. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Whenever a database is being created, make sure that the LOCATION keyword is used is wrong because it does not satisfy the requirement in the question (The data architect has mandated that all tables in the Lakehouse should be configured as external Delta Lake tables.) as stated.\n- B: When configuring an external data warehouse for all table storage, leverage Databricks for all ELT. is wrong because it does not satisfy the requirement in the question (The data architect has mandated that all tables in the Lakehouse should be configured as external Delta Lake tables.) as stated.\n- D: When tables are created, make sure that the EXTERNAL keyword is used in the CREATE TABLE statement. is wrong because it does not satisfy the requirement in the question (The data architect has mandated that all tables in the Lakehouse should be configured as external Delta Lake tables.) as stated.\n- E: When the workspace is being configured, make sure that external cloud object storage has been mounted. is wrong because it does not satisfy the requirement in the question (The data architect has mandated that all tables in the Lakehouse should be configured as external Delta Lake tables.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q034.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 35,
    "question": "To reduce storage and compute costs, the data engineering team has been tasked with curating a series of aggregate tables leveraged by business intelligence dashboards, customer-facing applications, production machine learning models, and ad hoc analytical queries. The data engineering team has been made aware of new requirements from a customer-facing application, which is the only downstream workload they manage entirely. As a result, an aggregate table used by numerous teams across the organization will need to have a number of fields renamed, and additional fields will also be added. Which of the solutions addresses the situation while minimally interrupting other teams in the organization without increasing the number of tables that need to be managed?",
    "choices": [
      {
        "id": "A",
        "text": "Send all users notice that the schema for the table will be changing; include in the communication the logic necessary to revert the new table schema to match historic queries."
      },
      {
        "id": "B",
        "text": "Configure a new table with all the requisite fields and new names and use this as the source for the customer- facing application; create a view that maintains the original data schema and table name by aliasing select fields from the new table."
      },
      {
        "id": "C",
        "text": "Create a new table with the required schema and new fields and use Delta Lake's deep clone functionality to   sync up changes committed to one table to the corresponding table."
      },
      {
        "id": "D",
        "text": "Replace the current table definition with a logical view defined with the query logic currently writing the aggregate table; create a new table to power the customer-facing application."
      },
      {
        "id": "E",
        "text": "Add a table comment warning all users that the table schema and field names will be changing on a given date; overwrite the table in place to the specifications of the customer-facing application."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: To reduce storage and compute costs, the data engineering team has been tasked with curating a series of aggregate tables leveraged by business intelligence dashboards, customer...\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why B is correct: Configure a new table with all the requisite fields and new names and use this as the source for the customer- facing application; create a view that maintains the original data schema and table name by aliasing select fields from the new table. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Send all users notice that the schema for the table will be changing; include in the communication the logic necessary to revert the new table schema to match historic queries. is wrong because it does not satisfy the requirement in the question (To reduce storage and compute costs, the data engineering team has been tasked with curating a series of aggregate tables leveraged by business intelligence dashboards, customer...) as stated.\n- C: Create a new table with the required schema and new fields and use Delta Lake's deep clone functionality to   sync up changes committed to one table to the corresponding table. is wrong because it does not satisfy the requirement in the question (To reduce storage and compute costs, the data engineering team has been tasked with curating a series of aggregate tables leveraged by business intelligence dashboards, customer...) as stated.\n- D: Replace the current table definition with a logical view defined with the query logic currently writing the aggregate table; create a new table to power the customer-facing application. is wrong because it does not satisfy the requirement in the question (To reduce storage and compute costs, the data engineering team has been tasked with curating a series of aggregate tables leveraged by business intelligence dashboards, customer...) as stated.\n- E: Add a table comment warning all users that the table schema and field names will be changing on a given date; overwrite the table in place to the specifications of the customer-facing application. is wrong because it does not satisfy the requirement in the question (To reduce storage and compute costs, the data engineering team has been tasked with curating a series of aggregate tables leveraged by business intelligence dashboards, customer...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q035.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 36,
    "question": "A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT, post_time TIMESTAMP, date DATE This table is partitioned by the date column. A query is run with the following filter: longitude < 20 & longitude > -20 Which statement describes how data will be filtered?",
    "choices": [
      {
        "id": "A",
        "text": "Statistics in the Delta Log will be used to identify partitions that might Include files in the filtered range."
      },
      {
        "id": "B",
        "text": "No file skipping will occur because the optimizer does not know the relationship between the partition column and the longitude."
      },
      {
        "id": "C",
        "text": "The Delta Engine will use row-level statistics in the transaction log to identify the flies that meet the filter criteria."
      },
      {
        "id": "D",
        "text": "Statistics in the Delta Log will be used to identify data files that might include records in the filtered range."
      },
      {
        "id": "E",
        "text": "The Delta Engine will scan the parquet file footers to identify each row that meets the filter criteria."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...\n- Tested mechanism/concept: Databricks Repos (Git integration, branch/commit/pull).\n- Why D is correct: Statistics in the Delta Log will be used to identify data files that might include records in the filtered range. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Statistics in the Delta Log will be used to identify partitions that might Include files in the filtered range. is wrong because it does not satisfy the requirement in the question (A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...) as stated.\n- B: No file skipping will occur because the optimizer does not know the relationship between the partition column and the longitude. is wrong because it does not satisfy the requirement in the question (A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...) as stated.\n- C: The Delta Engine will use row-level statistics in the transaction log to identify the flies that meet the filter criteria. is wrong because it does not satisfy the requirement in the question (A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...) as stated.\n- E: The Delta Engine will scan the parquet file footers to identify each row that meets the filter criteria. is wrong because it does not satisfy the requirement in the question (A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q036.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 37,
    "question": "A small company based in the United States has recently contracted a consulting firm in India to implement several new data engineering pipelines to power artificial intelligence applications. All the company's data is stored in regional cloud storage in the United States. The workspace administrator at the company is uncertain about where the Databricks workspace used by the contractors should be deployed. Assuming that all data governance considerations are accounted for, which statement accurately informs this decision?",
    "choices": [
      {
        "id": "A",
        "text": "Databricks runs HDFS on cloud volume storage; as such, cloud virtual machines must be deployed in the region where the data is stored."
      },
      {
        "id": "B",
        "text": "Databricks workspaces do not rely on any regional infrastructure; as such, the decision should be made based upon what is most convenient for the workspace administrator."
      },
      {
        "id": "C",
        "text": "Cross-region reads and writes can incur significant costs and latency; whenever possible, compute should be deployed in the same region the data is stored."
      },
      {
        "id": "D",
        "text": "Databricks leverages user workstations as the driver during interactive development; as such, users should always use a workspace deployed in a region they are physically near."
      },
      {
        "id": "E",
        "text": "Databricks notebooks send all executable code from the user’s browser to virtual machines over the open internet; whenever possible, choosing a workspace region near the end users is the most secure."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A small company based in the United States has recently contracted a consulting firm in India to implement several new data engineering pipelines to power artificial intelligenc...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: Cross-region reads and writes can incur significant costs and latency; whenever possible, compute should be deployed in the same region the data is stored. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Databricks runs HDFS on cloud volume storage; as such, cloud virtual machines must be deployed in the region where the data is stored. is wrong because it does not satisfy the requirement in the question (A small company based in the United States has recently contracted a consulting firm in India to implement several new data engineering pipelines to power artificial intelligenc...) as stated.\n- B: Databricks workspaces do not rely on any regional infrastructure; as such, the decision should be made based upon what is most convenient for the workspace administrator. is wrong because it does not satisfy the requirement in the question (A small company based in the United States has recently contracted a consulting firm in India to implement several new data engineering pipelines to power artificial intelligenc...) as stated.\n- D: Databricks leverages user workstations as the driver during interactive development; as such, users should always use a workspace deployed in a region they are physically near. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n- E: Databricks notebooks send all executable code from the user’s browser to virtual machines over the open internet; whenever possible, choosing a workspace region near the end users is the most secure. is wrong because it does not satisfy the requirement in the question (A small company based in the United States has recently contracted a consulting firm in India to implement several new data engineering pipelines to power artificial intelligenc...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q037.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 38,
    "question": "The downstream consumers of a Delta Lake table have been complaining about data quality issues impacting    performance in their applications. Specifically, they have complained that invalid latitude and longitude values in the activity_details table have been breaking their ability to use other geolocation processes. A junior engineer has written the following code to add CHECK constraints to the Delta Lake table: A senior engineer has confirmed the above logic is correct and the valid ranges for latitude and longitude are provided, but the code fails when executed. Which statement explains the cause of this failure?",
    "choices": [
      {
        "id": "A",
        "text": "Because another team uses this table to support a frequently running application, two-phase locking is preventing the operation from committing."
      },
      {
        "id": "B",
        "text": "The activity_details table already exists; CHECK constraints can only be added during initial table creation."
      },
      {
        "id": "C",
        "text": "The activity_details table already contains records that violate the constraints; all existing data must pass CHECK constraints in order to add them to an existing table."
      },
      {
        "id": "D",
        "text": "The activity_details table already contains records; CHECK constraints can only be added prior to inserting values into a table."
      },
      {
        "id": "E",
        "text": "The current table schema does not contain the field valid_coordinates; schema evolution will need to be enabled before altering the table to add a constraint."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: The downstream consumers of a Delta Lake table have been complaining about data quality issues impacting performance in their applications. Specifically, they have complained th...\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why C is correct: The activity_details table already contains records that violate the constraints; all existing data must pass CHECK constraints in order to add them to an existing table. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Because another team uses this table to support a frequently running application, two-phase locking is preventing the operation from committing. is wrong because it does not satisfy the requirement in the question (The downstream consumers of a Delta Lake table have been complaining about data quality issues impacting performance in their applications. Specifically, they have complained th...) as stated.\n- B: The activity_details table already exists; CHECK constraints can only be added during initial table creation. is wrong because it does not satisfy the requirement in the question (The downstream consumers of a Delta Lake table have been complaining about data quality issues impacting performance in their applications. Specifically, they have complained th...) as stated.\n- D: The activity_details table already contains records; CHECK constraints can only be added prior to inserting values into a table. is wrong because it does not satisfy the requirement in the question (The downstream consumers of a Delta Lake table have been complaining about data quality issues impacting performance in their applications. Specifically, they have complained th...) as stated.\n- E: The current table schema does not contain the field valid_coordinates; schema evolution will need to be enabled before altering the table to add a constraint. is wrong because it does not satisfy the requirement in the question (The downstream consumers of a Delta Lake table have been complaining about data quality issues impacting performance in their applications. Specifically, they have complained th...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q038.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 39,
    "question": "Which of the following is true of Delta Lake and the Lakehouse?",
    "choices": [
      {
        "id": "A",
        "text": "Because Parquet compresses data row by row. strings will only be compressed when a character is repeated multiple times."
      },
      {
        "id": "B",
        "text": "Delta Lake automatically collects statistics on the first 32 columns of each table which are leveraged in data skipping based on query filters."
      },
      {
        "id": "C",
        "text": "Views in the Lakehouse maintain a valid cache of the most recent versions of source tables at all times."
      },
      {
        "id": "D",
        "text": "Primary and foreign key constraints can be leveraged to ensure duplicate values are never entered into a dimension table."
      },
      {
        "id": "E",
        "text": "Z-order can only be applied to numeric values stored in Delta Lake tables."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: Delta Lake automatically collects statistics on the first 32 columns of each table which are leveraged in data skipping based on query filters. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Because Parquet compresses data row by row. strings will only be compressed when a character is repeated multiple times. is wrong because it does not satisfy the requirement in the question () as stated.\n- C: Views in the Lakehouse maintain a valid cache of the most recent versions of source tables at all times. is wrong because it does not satisfy the requirement in the question () as stated.\n- D: Primary and foreign key constraints can be leveraged to ensure duplicate values are never entered into a dimension table. is wrong because it does not satisfy the requirement in the question () as stated.\n- E: Z-order can only be applied to numeric values stored in Delta Lake tables. is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q039.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 40,
    "question": "The view updates represents an incremental batch of all newly ingested data to be inserted or updated in the customers table. The following logic is used to process these records.   Which statement describes this implementation?",
    "choices": [
      {
        "id": "A",
        "text": "The customers table is implemented as a Type 3 table; old values are maintained as a new column alongside the current value."
      },
      {
        "id": "B",
        "text": "The customers table is implemented as a Type 2 table; old values are maintained but marked as no longer current and new values are inserted."
      },
      {
        "id": "C",
        "text": "The customers table is implemented as a Type 0 table; all writes are append only with no changes to existing values."
      },
      {
        "id": "D",
        "text": "The customers table is implemented as a Type 1 table; old values are overwritten by new values and no history is maintained."
      },
      {
        "id": "E",
        "text": "The customers table is implemented as a Type 2 table; old values are overwritten and new customers are appended."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The view updates represents an incremental batch of all newly ingested data to be inserted or updated in the customers table. The following logic is used to process these records.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: The customers table is implemented as a Type 2 table; old values are maintained but marked as no longer current and new values are inserted. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The customers table is implemented as a Type 3 table; old values are maintained as a new column alongside the current value. is wrong because it does not satisfy the requirement in the question (The view updates represents an incremental batch of all newly ingested data to be inserted or updated in the customers table. The following logic is used to process these records.) as stated.\n- C: The customers table is implemented as a Type 0 table; all writes are append only with no changes to existing values. is wrong because it does not satisfy the requirement in the question (The view updates represents an incremental batch of all newly ingested data to be inserted or updated in the customers table. The following logic is used to process these records.) as stated.\n- D: The customers table is implemented as a Type 1 table; old values are overwritten by new values and no history is maintained. is wrong because it does not satisfy the requirement in the question (The view updates represents an incremental batch of all newly ingested data to be inserted or updated in the customers table. The following logic is used to process these records.) as stated.\n- E: The customers table is implemented as a Type 2 table; old values are overwritten and new customers are appended. is wrong because it does not satisfy the requirement in the question (The view updates represents an incremental batch of all newly ingested data to be inserted or updated in the customers table. The following logic is used to process these records.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q040.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 41,
    "question": "The DevOps team has configured a production workload as a collection of notebooks scheduled to run daily using the Jobs UI. A new data engineering hire is onboarding to the team and has requested access to one of these notebooks to review the production logic. What are the maximum notebook permissions that can be granted to the user without allowing accidental changes to production code or data?",
    "choices": [
      {
        "id": "A",
        "text": "Can Manage"
      },
      {
        "id": "B",
        "text": "Can Edit"
      },
      {
        "id": "C",
        "text": "No permissions"
      },
      {
        "id": "D",
        "text": "Can Read"
      },
      {
        "id": "E",
        "text": "Can Run"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: The DevOps team has configured a production workload as a collection of notebooks scheduled to run daily using the Jobs UI. A new data engineering hire is onboarding to the team...\n- Tested mechanism/concept: Databricks Jobs scheduling/execution model (task types, parameters, retries).\n- Why D is correct: Can Read directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Can Manage is wrong because it does not satisfy the requirement in the question (The DevOps team has configured a production workload as a collection of notebooks scheduled to run daily using the Jobs UI. A new data engineering hire is onboarding to the team...) as stated.\n- B: Can Edit is wrong because it does not satisfy the requirement in the question (The DevOps team has configured a production workload as a collection of notebooks scheduled to run daily using the Jobs UI. A new data engineering hire is onboarding to the team...) as stated.\n- C: No permissions is wrong because it does not satisfy the requirement in the question (The DevOps team has configured a production workload as a collection of notebooks scheduled to run daily using the Jobs UI. A new data engineering hire is onboarding to the team...) as stated.\n- E: Can Run is wrong because it does not satisfy the requirement in the question (The DevOps team has configured a production workload as a collection of notebooks scheduled to run daily using the Jobs UI. A new data engineering hire is onboarding to the team...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q041.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 42,
    "question": "A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups, which are used for setting up data access using ACLs. The user_ltv table has the following schema:   email STRING, age INT, ltv INT The following view definition is executed: An analyst who is not a member of the marketing group executes the following query: SELECT * FROM email_ltv - Which statement describes the results returned by this query?",
    "choices": [
      {
        "id": "A",
        "text": "Three columns will be returned, but one column will be named \"REDACTED\" and contain only null values."
      },
      {
        "id": "B",
        "text": "Only the email and ltv columns will be returned; the email column will contain all null values."
      },
      {
        "id": "C",
        "text": "The email and ltv columns will be returned with the values in user_ltv."
      },
      {
        "id": "D",
        "text": "The email.age, and ltv columns will be returned with the values in user_ltv."
      },
      {
        "id": "E",
        "text": "Only the email and ltv columns will be returned; the email column will contain the string \"REDACTED\" in each row."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why E is correct: Only the email and ltv columns will be returned; the email column will contain the string \"REDACTED\" in each row. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Three columns will be returned, but one column will be named \"REDACTED\" and contain only null values. is wrong because it does not satisfy the requirement in the question (A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,) as stated.\n- B: Only the email and ltv columns will be returned; the email column will contain all null values. is wrong because it does not satisfy the requirement in the question (A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,) as stated.\n- C: The email and ltv columns will be returned with the values in user_ltv. is wrong because it does not satisfy the requirement in the question (A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,) as stated.\n- D: The email.age, and ltv columns will be returned with the values in user_ltv. is wrong because it does not satisfy the requirement in the question (A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q042.webp"
    ],
    "docs": [
      {
        "title": "Databricks secrets (dbutils.secrets) and redaction",
        "query": "Databricks secrets redacted output"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 43,
    "question": "The data governance team has instituted a requirement that all tables containing Personal Identifiable Information (PH) must be clearly annotated. This includes adding column comments, table comments, and setting the custom table property \"contains_pii\" = true. The following SQL DDL statement is executed to create a new table: Which command allows manual confirmation that these three requirements have been met?",
    "choices": [
      {
        "id": "A",
        "text": "DESCRIBE EXTENDED dev.pii_test"
      },
      {
        "id": "B",
        "text": "DESCRIBE DETAIL dev.pii_test"
      },
      {
        "id": "C",
        "text": "SHOW TBLPROPERTIES dev.pii_test"
      },
      {
        "id": "D",
        "text": "DESCRIBE HISTORY dev.pii_test"
      },
      {
        "id": "E",
        "text": "SHOW TABLES dev"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: The data governance team has instituted a requirement that all tables containing Personal Identifiable Information (PH) must be clearly annotated. This includes adding column co...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: DESCRIBE EXTENDED dev.pii_test directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: DESCRIBE DETAIL dev.pii_test is wrong because it does not satisfy the requirement in the question (The data governance team has instituted a requirement that all tables containing Personal Identifiable Information (PH) must be clearly annotated. This includes adding column co...) as stated.\n- C: SHOW TBLPROPERTIES dev.pii_test is wrong because it does not satisfy the requirement in the question (The data governance team has instituted a requirement that all tables containing Personal Identifiable Information (PH) must be clearly annotated. This includes adding column co...) as stated.\n- D: DESCRIBE HISTORY dev.pii_test is wrong because it does not satisfy the requirement in the question (The data governance team has instituted a requirement that all tables containing Personal Identifiable Information (PH) must be clearly annotated. This includes adding column co...) as stated.\n- E: SHOW TABLES dev is wrong because it does not satisfy the requirement in the question (The data governance team has instituted a requirement that all tables containing Personal Identifiable Information (PH) must be clearly annotated. This includes adding column co...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q043.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 44,
    "question": "The data governance team is reviewing code used for deleting records for compliance with GDPR. They note the following logic is used to delete records from the Delta Lake table named users. Assuming that user_id is a unique identifying key and that delete_requests contains all users that have requested deletion, which statement describes whether successfully executing the above logic guarantees that the records to be deleted are no longer accessible and why?",
    "choices": [
      {
        "id": "A",
        "text": "Yes; Delta Lake ACID guarantees provide assurance that the DELETE command succeeded fully and permanently purged these records."
      },
      {
        "id": "B",
        "text": "No; the Delta cache may return records from previous versions of the table until the cluster is restarted."
      },
      {
        "id": "C",
        "text": "Yes; the Delta cache immediately updates to reflect the latest data files recorded to disk."
      },
      {
        "id": "D",
        "text": "No; the Delta Lake DELETE command only provides ACID guarantees when combined with the MERGE INTO command."
      },
      {
        "id": "E",
        "text": "No; files containing deleted records may still be accessible with time travel until a VACUUM command is used to remove invalidated data files."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: The data governance team is reviewing code used for deleting records for compliance with GDPR. They note the following logic is used to delete records from the Delta Lake table...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why E is correct: No; files containing deleted records may still be accessible with time travel until a VACUUM command is used to remove invalidated data files. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Yes; Delta Lake ACID guarantees provide assurance that the DELETE command succeeded fully and permanently purged these records. is wrong because it does not satisfy the requirement in the question (The data governance team is reviewing code used for deleting records for compliance with GDPR. They note the following logic is used to delete records from the Delta Lake table...) as stated.\n- B: No; the Delta cache may return records from previous versions of the table until the cluster is restarted. is wrong because it does not satisfy the requirement in the question (The data governance team is reviewing code used for deleting records for compliance with GDPR. They note the following logic is used to delete records from the Delta Lake table...) as stated.\n- C: Yes; the Delta cache immediately updates to reflect the latest data files recorded to disk. is wrong because it does not satisfy the requirement in the question (The data governance team is reviewing code used for deleting records for compliance with GDPR. They note the following logic is used to delete records from the Delta Lake table...) as stated.\n- D: No; the Delta Lake DELETE command only provides ACID guarantees when combined with the MERGE INTO command. is wrong because it does not satisfy the requirement in the question (The data governance team is reviewing code used for deleting records for compliance with GDPR. They note the following logic is used to delete records from the Delta Lake table...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q044.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 45,
    "question": "An external object storage container has been mounted to the location /mnt/finance_eda_bucket. The following logic was executed to create a database for the finance team: After the database was successfully created and permissions configured, a member of the finance team runs the following code: If all users on the finance team are members of the finance group, which statement describes how the tx_sales table will be created?",
    "choices": [
      {
        "id": "A",
        "text": "A logical table will persist the query plan to the Hive Metastore in the Databricks control plane."
      },
      {
        "id": "B",
        "text": "An external table will be created in the storage container mounted to /mnt/finance_eda_bucket."
      },
      {
        "id": "C",
        "text": "A logical table will persist the physical plan to the Hive Metastore in the Databricks control plane."
      },
      {
        "id": "D",
        "text": "An managed table will be created in the storage container mounted to /mnt/finance_eda_bucket."
      },
      {
        "id": "E",
        "text": "A managed table will be created in the DBFS root storage container."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: An external object storage container has been mounted to the location /mnt/finance_eda_bucket. The following logic was executed to create a database for the finance team: After...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: An managed table will be created in the storage container mounted to /mnt/finance_eda_bucket. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: A logical table will persist the query plan to the Hive Metastore in the Databricks control plane. is wrong because it does not satisfy the requirement in the question (An external object storage container has been mounted to the location /mnt/finance_eda_bucket. The following logic was executed to create a database for the finance team: After...) as stated.\n- B: An external table will be created in the storage container mounted to /mnt/finance_eda_bucket. is wrong because it does not satisfy the requirement in the question (An external object storage container has been mounted to the location /mnt/finance_eda_bucket. The following logic was executed to create a database for the finance team: After...) as stated.\n- C: A logical table will persist the physical plan to the Hive Metastore in the Databricks control plane. is wrong because it does not satisfy the requirement in the question (An external object storage container has been mounted to the location /mnt/finance_eda_bucket. The following logic was executed to create a database for the finance team: After...) as stated.\n- E: A managed table will be created in the DBFS root storage container. is wrong because it does not satisfy the requirement in the question (An external object storage container has been mounted to the location /mnt/finance_eda_bucket. The following logic was executed to create a database for the finance team: After...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q045.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 46,
    "question": "Although the Databricks Utilities Secrets module provides tools to store sensitive credentials and avoid accidentally displaying them in plain text users should still be careful with which credentials are stored here and which users have access to using these secrets. Which statement describes a limitation of Databricks Secrets?",
    "choices": [
      {
        "id": "A",
        "text": "Because the SHA256 hash is used to obfuscate stored secrets, reversing this hash will display the value in plain text."
      },
      {
        "id": "B",
        "text": "Account administrators can see all secrets in plain text by logging on to the Databricks Accounts console."
      },
      {
        "id": "C",
        "text": "Secrets are stored in an administrators-only table within the Hive Metastore; database administrators have permission to query this table by default."
      },
      {
        "id": "D",
        "text": "Iterating through a stored secret and printing each character will display secret contents in plain text."
      },
      {
        "id": "E",
        "text": "The Databricks REST API can be used to list secrets in plain text if the personal access token has proper credentials."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Although the Databricks Utilities Secrets module provides tools to store sensitive credentials and avoid accidentally displaying them in plain text users should still be careful...\n- Tested mechanism/concept: Databricks secrets (scopes, ACLs) and safe credential handling.\n- Why B is correct: Account administrators can see all secrets in plain text by logging on to the Databricks Accounts console. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Because the SHA256 hash is used to obfuscate stored secrets, reversing this hash will display the value in plain text. is wrong because it does not satisfy the requirement in the question (Although the Databricks Utilities Secrets module provides tools to store sensitive credentials and avoid accidentally displaying them in plain text users should still be careful...) as stated.\n- C: Secrets are stored in an administrators-only table within the Hive Metastore; database administrators have permission to query this table by default. is wrong because it does not satisfy the requirement in the question (Although the Databricks Utilities Secrets module provides tools to store sensitive credentials and avoid accidentally displaying them in plain text users should still be careful...) as stated.\n- D: Iterating through a stored secret and printing each character will display secret contents in plain text. is wrong because it does not satisfy the requirement in the question (Although the Databricks Utilities Secrets module provides tools to store sensitive credentials and avoid accidentally displaying them in plain text users should still be careful...) as stated.\n- E: The Databricks REST API can be used to list secrets in plain text if the personal access token has proper credentials. is wrong because it does not satisfy the requirement in the question (Although the Databricks Utilities Secrets module provides tools to store sensitive credentials and avoid accidentally displaying them in plain text users should still be careful...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q046.webp"
    ],
    "docs": [
      {
        "title": "Databricks secrets (dbutils.secrets) and redaction",
        "query": "Databricks secrets redacted output"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 47,
    "question": "What statement is true regarding the retention of job run history?",
    "choices": [
      {
        "id": "A",
        "text": "It is retained until you export or delete job run logs"
      },
      {
        "id": "B",
        "text": "It is retained for 30 days, during which time you can deliver job run logs to DBFS or S3"
      },
      {
        "id": "C",
        "text": "It is retained for 60 days, during which you can export notebook run results to HTML"
      },
      {
        "id": "D",
        "text": "It is retained for 60 days, after which logs are archived"
      },
      {
        "id": "E",
        "text": "It is retained for 90 days or until the run-id is re-used through custom run configuration"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: It is retained for 60 days, during which you can export notebook run results to HTML directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: It is retained until you export or delete job run logs is wrong because it does not satisfy the requirement in the question () as stated.\n- B: It is retained for 30 days, during which time you can deliver job run logs to DBFS or S3 is wrong because it does not satisfy the requirement in the question () as stated.\n- D: It is retained for 60 days, after which logs are archived is wrong because it does not satisfy the requirement in the question () as stated.\n- E: It is retained for 90 days or until the run-id is re-used through custom run configuration is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q047.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 48,
    "question": "A data engineer, User A, has promoted a new pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an external orchestration tool to trigger job runs through the REST API. Both users authorized the REST API calls using their personal access tokens. Which statement describes the contents of the workspace audit logs concerning these events?",
    "choices": [
      {
        "id": "A",
        "text": "Because the REST API was used for job creation and triggering runs, a Service Principal will be automatically used to identify these events."
      },
      {
        "id": "B",
        "text": "Because User B last configured the jobs, their identity will be associated with both the job creation events and the job run events."
      },
      {
        "id": "C",
        "text": "Because these events are managed separately, User A will have their identity associated with the job creation events and User B will have their identity associated with the job run events."
      },
      {
        "id": "D",
        "text": "Because the REST API was used for job creation and triggering runs, user identity will not be captured in the audit logs."
      },
      {
        "id": "E",
        "text": "Because User A created the jobs, their identity will be associated with both the job creation events and the job run events."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A data engineer, User A, has promoted a new pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an ex...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: Because these events are managed separately, User A will have their identity associated with the job creation events and User B will have their identity associated with the job run events. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Because the REST API was used for job creation and triggering runs, a Service Principal will be automatically used to identify these events. is wrong because it does not satisfy the requirement in the question (A data engineer, User A, has promoted a new pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an ex...) as stated.\n- B: Because User B last configured the jobs, their identity will be associated with both the job creation events and the job run events. is wrong because it does not satisfy the requirement in the question (A data engineer, User A, has promoted a new pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an ex...) as stated.\n- D: Because the REST API was used for job creation and triggering runs, user identity will not be captured in the audit logs. is wrong because it does not satisfy the requirement in the question (A data engineer, User A, has promoted a new pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an ex...) as stated.\n- E: Because User A created the jobs, their identity will be associated with both the job creation events and the job run events. is wrong because it does not satisfy the requirement in the question (A data engineer, User A, has promoted a new pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an ex...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q048.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 49,
    "question": "A user new to Databricks is trying to troubleshoot long execution times for some pipeline logic they are working on. Presently, the user is executing code cell-by-cell, using display() calls to confirm code is producing the logically correct results as new transformations are added to an operation. To get a measure of average time to execute, the user is running each cell multiple times interactively. Which of the following adjustments will get a more accurate measure of how code is likely to perform in production?",
    "choices": [
      {
        "id": "A",
        "text": "Scala is the only language that can be accurately tested using interactive notebooks; because the best performance is achieved by using Scala code compiled to JARs, all PySpark and Spark SQL logic should be refactored."
      },
      {
        "id": "B",
        "text": "The only way to meaningfully troubleshoot code execution times in development notebooks Is to use production-sized data and production-sized clusters with Run All execution."
      },
      {
        "id": "C",
        "text": "Production code development should only be done using an IDE; executing code against a local build of open source Spark and Delta Lake will provide the most accurate benchmarks for how code will perform in production."
      },
      {
        "id": "D",
        "text": "Calling display() forces a job to trigger, while many transformations will only add to the logical query plan; because of caching, repeated execution of the same logic does not provide meaningful results."
      },
      {
        "id": "E",
        "text": "The Jobs UI should be leveraged to occasionally run the notebook as a job and track execution time during incremental code development because Photon can only be enabled on clusters launched for scheduled jobs."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: A user new to Databricks is trying to troubleshoot long execution times for some pipeline logic they are working on. Presently, the user is executing code cell-by-cell, using di...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: The only way to meaningfully troubleshoot code execution times in development notebooks Is to use production-sized data and production-sized clusters with Run All execution. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Scala is the only language that can be accurately tested using interactive notebooks; because the best performance is achieved by using Scala code compiled to JARs, all PySpark and Spark SQL logic should be refactored. is wrong because it does not satisfy the requirement in the question (A user new to Databricks is trying to troubleshoot long execution times for some pipeline logic they are working on. Presently, the user is executing code cell-by-cell, using di...) as stated.\n- C: Production code development should only be done using an IDE; executing code against a local build of open source Spark and Delta Lake will provide the most accurate benchmarks for how code will perform in production. is wrong because it does not satisfy the requirement in the question (A user new to Databricks is trying to troubleshoot long execution times for some pipeline logic they are working on. Presently, the user is executing code cell-by-cell, using di...) as stated.\n- D: Calling display() forces a job to trigger, while many transformations will only add to the logical query plan; because of caching, repeated execution of the same logic does not provide meaningful results. is wrong because it does not satisfy the requirement in the question (A user new to Databricks is trying to troubleshoot long execution times for some pipeline logic they are working on. Presently, the user is executing code cell-by-cell, using di...) as stated.\n- E: The Jobs UI should be leveraged to occasionally run the notebook as a job and track execution time during incremental code development because Photon can only be enabled on clusters launched for scheduled jobs. is wrong because it does not satisfy the requirement in the question (A user new to Databricks is trying to troubleshoot long execution times for some pipeline logic they are working on. Presently, the user is executing code cell-by-cell, using di...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q049.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 50,
    "question": "A production cluster has 3 executor nodes and uses the same virtual machine type for the driver and executor. When evaluating the Ganglia Metrics for this cluster, which indicator would signal a bottleneck caused by code executing on the driver?",
    "choices": [
      {
        "id": "A",
        "text": "The five Minute Load Average remains consistent/flat"
      },
      {
        "id": "B",
        "text": "Bytes Received never exceeds 80 million bytes per second"
      },
      {
        "id": "C",
        "text": "Total Disk Space remains constant"
      },
      {
        "id": "D",
        "text": "Network I/O never spikes"
      },
      {
        "id": "E",
        "text": "Overall cluster CPU utilization is around 25%"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A production cluster has 3 executor nodes and uses the same virtual machine type for the driver and executor.\n- Tested mechanism/concept: Databricks compute configuration (clusters, jobs compute, pools).\n- Why D is correct: Network I/O never spikes directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The five Minute Load Average remains consistent/flat is wrong because it does not satisfy the requirement in the question (A production cluster has 3 executor nodes and uses the same virtual machine type for the driver and executor.) as stated.\n- B: Bytes Received never exceeds 80 million bytes per second is wrong because it does not satisfy the requirement in the question (A production cluster has 3 executor nodes and uses the same virtual machine type for the driver and executor.) as stated.\n- C: Total Disk Space remains constant is wrong because it does not satisfy the requirement in the question (A production cluster has 3 executor nodes and uses the same virtual machine type for the driver and executor.) as stated.\n- E: Overall cluster CPU utilization is around 25% is wrong because it does not satisfy the requirement in the question (A production cluster has 3 executor nodes and uses the same virtual machine type for the driver and executor.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q050.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 51,
    "question": "Where in the Spark UI can one diagnose a performance problem induced by not leveraging predicate push-down?",
    "choices": [
      {
        "id": "A",
        "text": "In the Executor’s log file, by grepping for \"predicate push-down\""
      },
      {
        "id": "B",
        "text": "In the Stage’s Detail screen, in the Completed Stages table, by noting the size of data read from the Input column"
      },
      {
        "id": "C",
        "text": "In the Storage Detail screen, by noting which RDDs are not stored on disk"
      },
      {
        "id": "D",
        "text": "In the Delta Lake transaction log. by noting the column statistics"
      },
      {
        "id": "E",
        "text": "In the Query Detail screen, by interpreting the Physical Plan"
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: Spark UI Query Details / Physical Plan (shows pushed filters, scans, joins).\n- Why E is correct: In the Query Detail screen, by interpreting the Physical Plan directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: In the Executor’s log file, by grepping for \"predicate push-down\" is wrong because the question asks where in the Spark UI to diagnose this; grepping executor logs is not the Spark UI diagnostic path.\n- B: In the Stage’s Detail screen, in the Completed Stages table, by noting the size of data read from the Input column is wrong because it does not satisfy the requirement in the question () as stated.\n- C: In the Storage Detail screen, by noting which RDDs are not stored on disk is wrong because predicate push-down is a data source scan/plan optimization visible in the query plan, not an RDD storage detail.\n- D: In the Delta Lake transaction log. by noting the column statistics is wrong because the Delta transaction log tracks table versions, not the query execution plan shown in the Spark UI.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q051.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 52,
    "question": "Review the following error traceback: Which statement describes the error being raised?",
    "choices": [
      {
        "id": "A",
        "text": "The code executed was PySpark but was executed in a Scala notebook."
      },
      {
        "id": "B",
        "text": "There is no column in the table named heartrateheartrateheartrate"
      },
      {
        "id": "C",
        "text": "There is a type error because a column object cannot be multiplied."
      },
      {
        "id": "D",
        "text": "There is a type error because a DataFrame object cannot be multiplied."
      },
      {
        "id": "E",
        "text": "There is a syntax error because the heartrate column is not correctly identified as a column."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Review the following error traceback:\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: There is no column in the table named heartrateheartrateheartrate directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The code executed was PySpark but was executed in a Scala notebook. is wrong because it does not satisfy the requirement in the question (Review the following error traceback:) as stated.\n- C: There is a type error because a column object cannot be multiplied. is wrong because it does not satisfy the requirement in the question (Review the following error traceback:) as stated.\n- D: There is a type error because a DataFrame object cannot be multiplied. is wrong because it does not satisfy the requirement in the question (Review the following error traceback:) as stated.\n- E: There is a syntax error because the heartrate column is not correctly identified as a column. is wrong because it does not satisfy the requirement in the question (Review the following error traceback:) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q052.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 53,
    "question": "Which distribution does Databricks support for installing custom Python code packages?",
    "choices": [
      {
        "id": "A",
        "text": "sbt"
      },
      {
        "id": "B",
        "text": "CRANC. npm"
      },
      {
        "id": "D",
        "text": "Wheels"
      },
      {
        "id": "E",
        "text": "jars"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: Wheels directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: sbt is wrong because it does not satisfy the requirement in the question () as stated.\n- B: CRANC. npm is wrong because it does not satisfy the requirement in the question () as stated.\n- E: jars is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q053.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 54,
    "question": "Which Python variable contains a list of directories to be searched when trying to locate required modules?",
    "choices": [
      {
        "id": "A",
        "text": "importlib.resource_path"
      },
      {
        "id": "B",
        "text": "sys.path"
      },
      {
        "id": "C",
        "text": "os.path"
      },
      {
        "id": "D",
        "text": "pypi.path"
      },
      {
        "id": "E",
        "text": "pylib.source"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: sys.path directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: importlib.resource_path is wrong because it does not satisfy the requirement in the question () as stated.\n- C: os.path is wrong because it does not satisfy the requirement in the question () as stated.\n- D: pypi.path is wrong because it does not satisfy the requirement in the question () as stated.\n- E: pylib.source is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q054.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 55,
    "question": "Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code. Which statement describes a main benefit that offset this additional effort?",
    "choices": [
      {
        "id": "A",
        "text": "Improves the quality of your data"
      },
      {
        "id": "B",
        "text": "Validates a complete use case of your application"
      },
      {
        "id": "C",
        "text": "Troubleshooting is easier since all steps are isolated and tested individually"
      },
      {
        "id": "D",
        "text": "Yields faster deployment and execution times"
      },
      {
        "id": "E",
        "text": "Ensures that all steps interact correctly to achieve the desired end result"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: Troubleshooting is easier since all steps are isolated and tested individually directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Improves the quality of your data is wrong because it does not satisfy the requirement in the question (Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.) as stated.\n- B: Validates a complete use case of your application is wrong because it does not satisfy the requirement in the question (Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.) as stated.\n- D: Yields faster deployment and execution times is wrong because it does not satisfy the requirement in the question (Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.) as stated.\n- E: Ensures that all steps interact correctly to achieve the desired end result is wrong because it does not satisfy the requirement in the question (Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q055.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 56,
    "question": "Which statement describes integration testing?",
    "choices": [
      {
        "id": "A",
        "text": "Validates interactions between subsystems of your application"
      },
      {
        "id": "B",
        "text": "Requires an automated testing framework"
      },
      {
        "id": "C",
        "text": "Requires manual intervention"
      },
      {
        "id": "D",
        "text": "Validates an application use case"
      },
      {
        "id": "E",
        "text": "Validates behavior of individual elements of your application"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: Validates interactions between subsystems of your application directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Requires an automated testing framework is wrong because it does not satisfy the requirement in the question () as stated.\n- C: Requires manual intervention is wrong because it does not satisfy the requirement in the question () as stated.\n- D: Validates an application use case is wrong because it does not satisfy the requirement in the question () as stated.\n- E: Validates behavior of individual elements of your application is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q056.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 57,
    "question": "Which REST API call can be used to review the notebooks configured to run as tasks in a multi-task job?",
    "choices": [
      {
        "id": "A",
        "text": "/jobs/runs/list"
      },
      {
        "id": "B",
        "text": "/jobs/runs/get-output"
      },
      {
        "id": "C",
        "text": "/jobs/runs/get"
      },
      {
        "id": "D",
        "text": "/jobs/get"
      },
      {
        "id": "E",
        "text": "/jobs/list"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: /jobs/get directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: /jobs/runs/list is wrong because it does not satisfy the requirement in the question () as stated.\n- B: /jobs/runs/get-output is wrong because it does not satisfy the requirement in the question () as stated.\n- C: /jobs/runs/get is wrong because it does not satisfy the requirement in the question () as stated.\n- E: /jobs/list is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q057.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 58,
    "question": "A Databricks job has been configured with 3 tasks, each of which is a Databricks notebook. Task A does not depend on other tasks. Tasks B and C run in parallel, with each having a serial dependency on task A. If tasks A and B complete successfully but task C fails during a scheduled run, which statement describes the resulting state?",
    "choices": [
      {
        "id": "A",
        "text": "All logic expressed in the notebook associated with tasks A and B will have been successfully completed; some operations in task C may have completed successfully."
      },
      {
        "id": "B",
        "text": "All logic expressed in the notebook associated with tasks A and B will have been successfully completed; any changes made in task C will be rolled back due to task failure."
      },
      {
        "id": "C",
        "text": "All logic expressed in the notebook associated with task A will have been successfully completed; tasks B and C will not commit any changes because of stage failure."
      },
      {
        "id": "D",
        "text": "Because all tasks are managed as a dependency graph, no changes will be committed to the Lakehouse until ail tasks have successfully been completed."
      },
      {
        "id": "E",
        "text": "Unless all tasks complete successfully, no changes will be committed to the Lakehouse; because task C failed, all commits will be rolled back automatically."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A Databricks job has been configured with 3 tasks, each of\n- Tested mechanism/concept: Databricks Jobs scheduling/execution model (task types, parameters, retries).\n- Why A is correct: All logic expressed in the notebook associated with tasks A and B will have been successfully completed; some operations in task C may have completed successfully. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: All logic expressed in the notebook associated with tasks A and B will have been successfully completed; any changes made in task C will be rolled back due to task failure. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with 3 tasks, each of) as stated.\n- C: All logic expressed in the notebook associated with task A will have been successfully completed; tasks B and C will not commit any changes because of stage failure. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with 3 tasks, each of) as stated.\n- D: Because all tasks are managed as a dependency graph, no changes will be committed to the Lakehouse until ail tasks have successfully been completed. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with 3 tasks, each of) as stated.\n- E: Unless all tasks complete successfully, no changes will be committed to the Lakehouse; because task C failed, all commits will be rolled back automatically. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with 3 tasks, each of) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q058.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 59,
    "question": "A Delta Lake table was created with the below query: Realizing that the original query had a typographical error, the below code was executed: ALTER TABLE prod.sales_by_stor RENAME TO prod.sales_by_store Which result will occur after running the second command?",
    "choices": [
      {
        "id": "A",
        "text": "The table reference in the metastore is updated and no data is changed."
      },
      {
        "id": "B",
        "text": "The table name change is recorded in the Delta transaction log."
      },
      {
        "id": "C",
        "text": "All related files and metadata are dropped and recreated in a single ACID transaction."
      },
      {
        "id": "D",
        "text": "The table reference in the metastore is updated and all data files are moved."
      },
      {
        "id": "E",
        "text": "A new Delta transaction log Is created for the renamed table."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A Delta Lake table was created with the below query: Realizing that the original query had a typographical error, the below code was executed: ALTER TABLE prod.sales_by_stor REN...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: The table reference in the metastore is updated and no data is changed. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: The table name change is recorded in the Delta transaction log. is wrong because it does not satisfy the requirement in the question (A Delta Lake table was created with the below query: Realizing that the original query had a typographical error, the below code was executed: ALTER TABLE prod.sales_by_stor REN...) as stated.\n- C: All related files and metadata are dropped and recreated in a single ACID transaction. is wrong because it does not satisfy the requirement in the question (A Delta Lake table was created with the below query: Realizing that the original query had a typographical error, the below code was executed: ALTER TABLE prod.sales_by_stor REN...) as stated.\n- D: The table reference in the metastore is updated and all data files are moved. is wrong because it does not satisfy the requirement in the question (A Delta Lake table was created with the below query: Realizing that the original query had a typographical error, the below code was executed: ALTER TABLE prod.sales_by_stor REN...) as stated.\n- E: A new Delta transaction log Is created for the renamed table. is wrong because it does not satisfy the requirement in the question (A Delta Lake table was created with the below query: Realizing that the original query had a typographical error, the below code was executed: ALTER TABLE prod.sales_by_stor REN...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q059.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 60,
    "question": "The data engineering team maintains a table of aggregate statistics through batch nightly updates. This includes total sales for the previous day alongside totals and averages for a variety of time periods including the 7 previous days, year-to-date, and quarter-to-date. This table is named store_saies_summary and the schema is as follows: The table daily_store_sales contains all the information needed to update store_sales_summary. The schema for this table is: store_id INT, sales_date DATE, total_sales FLOAT    If daily_store_sales is implemented as a Type 1 table and the total_sales column might be adjusted after manual data auditing, which approach is the safest to generate accurate reports in the store_sales_summary table?",
    "choices": [
      {
        "id": "A",
        "text": "Implement the appropriate aggregate logic as a batch read against the daily_store_sales table and overwrite the store_sales_summary table with each Update."
      },
      {
        "id": "B",
        "text": "Implement the appropriate aggregate logic as a batch read against the daily_store_sales table and append new rows nightly to the store_sales_summary table."
      },
      {
        "id": "C",
        "text": "Implement the appropriate aggregate logic as a batch read against the daily_store_sales table and use upsert logic to update results in the store_sales_summary table."
      },
      {
        "id": "D",
        "text": "Implement the appropriate aggregate logic as a Structured Streaming read against the daily_store_sales table and use upsert logic to update results in the store_sales_summary table."
      },
      {
        "id": "E",
        "text": "Use Structured Streaming to subscribe to the change data feed for daily_store_sales and apply changes to the aggregates in the store_sales_summary table with each update."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: The data engineering team maintains a table of aggregate statistics through batch nightly updates. This includes total sales for the previous day alongside totals and averages f...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why E is correct: Use Structured Streaming to subscribe to the change data feed for daily_store_sales and apply changes to the aggregates in the store_sales_summary table with each update. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Implement the appropriate aggregate logic as a batch read against the daily_store_sales table and overwrite the store_sales_summary table with each Update. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains a table of aggregate statistics through batch nightly updates. This includes total sales for the previous day alongside totals and averages f...) as stated.\n- B: Implement the appropriate aggregate logic as a batch read against the daily_store_sales table and append new rows nightly to the store_sales_summary table. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains a table of aggregate statistics through batch nightly updates. This includes total sales for the previous day alongside totals and averages f...) as stated.\n- C: Implement the appropriate aggregate logic as a batch read against the daily_store_sales table and use upsert logic to update results in the store_sales_summary table. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains a table of aggregate statistics through batch nightly updates. This includes total sales for the previous day alongside totals and averages f...) as stated.\n- D: Implement the appropriate aggregate logic as a Structured Streaming read against the daily_store_sales table and use upsert logic to update results in the store_sales_summary table. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains a table of aggregate statistics through batch nightly updates. This includes total sales for the previous day alongside totals and averages f...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q060.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 61,
    "question": "A member of the data engineering team has submitted a short notebook that they wish to schedule as part of a larger data pipeline. Assume that the commands provided below produce the logically correct results when run as presented.  Which command should be removed from the notebook before scheduling it as a job?",
    "choices": [
      {
        "id": "A",
        "text": "Cmd 2"
      },
      {
        "id": "B",
        "text": "Cmd 3"
      },
      {
        "id": "C",
        "text": "Cmd 4"
      },
      {
        "id": "D",
        "text": "Cmd 5"
      },
      {
        "id": "E",
        "text": "Cmd 6"
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: A member of the data engineering team has submitted a short notebook that they wish to schedule as part of a larger data pipeline. Assume that the commands provided below produc...\n- Tested mechanism/concept: Databricks Jobs scheduling/execution model (task types, parameters, retries).\n- Why E is correct: Cmd 6 directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Cmd 2 is wrong because it does not satisfy the requirement in the question (A member of the data engineering team has submitted a short notebook that they wish to schedule as part of a larger data pipeline. Assume that the commands provided below produc...) as stated.\n- B: Cmd 3 is wrong because it does not satisfy the requirement in the question (A member of the data engineering team has submitted a short notebook that they wish to schedule as part of a larger data pipeline. Assume that the commands provided below produc...) as stated.\n- C: Cmd 4 is wrong because it does not satisfy the requirement in the question (A member of the data engineering team has submitted a short notebook that they wish to schedule as part of a larger data pipeline. Assume that the commands provided below produc...) as stated.\n- D: Cmd 5 is wrong because it does not satisfy the requirement in the question (A member of the data engineering team has submitted a short notebook that they wish to schedule as part of a larger data pipeline. Assume that the commands provided below produc...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q061.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 62,
    "question": "The business reporting team requires that data for their dashboards be updated every hour. The total processing time for the pipeline that extracts transforms, and loads the data for their pipeline runs in 10 minutes.  Assuming normal operating conditions, which configuration will meet their service-level agreement requirements with the lowest cost?",
    "choices": [
      {
        "id": "A",
        "text": "Manually trigger a job anytime the business reporting team refreshes their dashboards"
      },
      {
        "id": "B",
        "text": "Schedule a job to execute the pipeline once an hour on a new job cluster"
      },
      {
        "id": "C",
        "text": "Schedule a Structured Streaming job with a trigger interval of 60 minutes"
      },
      {
        "id": "D",
        "text": "Schedule a job to execute the pipeline once an hour on a dedicated interactive cluster"
      },
      {
        "id": "E",
        "text": "Configure a job that executes every time new data lands in a given directory"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The business reporting team requires that data for their dashboards be updated every hour. The total processing time for the pipeline that extracts transforms, and loads the dat...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: Schedule a job to execute the pipeline once an hour on a new job cluster directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Manually trigger a job anytime the business reporting team refreshes their dashboards is wrong because it does not satisfy the requirement in the question (The business reporting team requires that data for their dashboards be updated every hour. The total processing time for the pipeline that extracts transforms, and loads the dat...) as stated.\n- C: Schedule a Structured Streaming job with a trigger interval of 60 minutes is wrong because it does not satisfy the requirement in the question (The business reporting team requires that data for their dashboards be updated every hour. The total processing time for the pipeline that extracts transforms, and loads the dat...) as stated.\n- D: Schedule a job to execute the pipeline once an hour on a dedicated interactive cluster is wrong because it does not satisfy the requirement in the question (The business reporting team requires that data for their dashboards be updated every hour. The total processing time for the pipeline that extracts transforms, and loads the dat...) as stated.\n- E: Configure a job that executes every time new data lands in a given directory is wrong because it does not satisfy the requirement in the question (The business reporting team requires that data for their dashboards be updated every hour. The total processing time for the pipeline that extracts transforms, and loads the dat...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q062.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 63,
    "question": "A Databricks SQL dashboard has been configured to monitor the total number of records present in a collection of Delta Lake tables using the following query pattern: SELECT COUNT (*) FROM table - Which of the following describes how results are generated each time the dashboard is updated?",
    "choices": [
      {
        "id": "A",
        "text": "The total count of rows is calculated by scanning all data files"
      },
      {
        "id": "B",
        "text": "The total count of rows will be returned from cached results unless REFRESH is run"
      },
      {
        "id": "C",
        "text": "The total count of records is calculated from the Delta transaction logs"
      },
      {
        "id": "D",
        "text": "The total count of records is calculated from the parquet file metadata"
      },
      {
        "id": "E",
        "text": "The total count of records is calculated from the Hive metastore"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A Databricks SQL dashboard has been configured to monitor the total number of records present in a collection of Delta Lake tables using the following query pattern: SELECT COUN...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: The total count of records is calculated from the Delta transaction logs directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The total count of rows is calculated by scanning all data files is wrong because it does not satisfy the requirement in the question (A Databricks SQL dashboard has been configured to monitor the total number of records present in a collection of Delta Lake tables using the following query pattern: SELECT COUN...) as stated.\n- B: The total count of rows will be returned from cached results unless REFRESH is run is wrong because it does not satisfy the requirement in the question (A Databricks SQL dashboard has been configured to monitor the total number of records present in a collection of Delta Lake tables using the following query pattern: SELECT COUN...) as stated.\n- D: The total count of records is calculated from the parquet file metadata is wrong because it does not satisfy the requirement in the question (A Databricks SQL dashboard has been configured to monitor the total number of records present in a collection of Delta Lake tables using the following query pattern: SELECT COUN...) as stated.\n- E: The total count of records is calculated from the Hive metastore is wrong because it does not satisfy the requirement in the question (A Databricks SQL dashboard has been configured to monitor the total number of records present in a collection of Delta Lake tables using the following query pattern: SELECT COUN...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q063.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 64,
    "question": "A Delta Lake table was created with the below query: Consider the following query: DROP TABLE prod.sales_by_store -   If this statement is executed by a workspace admin, which result will occur?",
    "choices": [
      {
        "id": "A",
        "text": "Nothing will occur until a COMMIT command is executed."
      },
      {
        "id": "B",
        "text": "The table will be removed from the catalog but the data will remain in storage."
      },
      {
        "id": "C",
        "text": "The table will be removed from the catalog and the data will be deleted."
      },
      {
        "id": "D",
        "text": "An error will occur because Delta Lake prevents the deletion of production data."
      },
      {
        "id": "E",
        "text": "Data will be marked as deleted but still recoverable with Time Travel."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A Delta Lake table was created with the below query: Consider the following query: DROP TABLE prod.sales_by_store - If this statement is executed by a workspace admin,\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: The table will be removed from the catalog and the data will be deleted. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Nothing will occur until a COMMIT command is executed. is wrong because it does not satisfy the requirement in the question (A Delta Lake table was created with the below query: Consider the following query: DROP TABLE prod.sales_by_store - If this statement is executed by a workspace admin,) as stated.\n- B: The table will be removed from the catalog but the data will remain in storage. is wrong because it does not satisfy the requirement in the question (A Delta Lake table was created with the below query: Consider the following query: DROP TABLE prod.sales_by_store - If this statement is executed by a workspace admin,) as stated.\n- D: An error will occur because Delta Lake prevents the deletion of production data. is wrong because it does not satisfy the requirement in the question (A Delta Lake table was created with the below query: Consider the following query: DROP TABLE prod.sales_by_store - If this statement is executed by a workspace admin,) as stated.\n- E: Data will be marked as deleted but still recoverable with Time Travel. is wrong because it does not satisfy the requirement in the question (A Delta Lake table was created with the below query: Consider the following query: DROP TABLE prod.sales_by_store - If this statement is executed by a workspace admin,) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q064.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 65,
    "question": "Two of the most common data locations on Databricks are the DBFS root storage and external object storage mounted with dbutils.fs.mount(). Which of the following statements is correct?",
    "choices": [
      {
        "id": "A",
        "text": "DBFS is a file system protocol that allows users to interact with files stored in object storage using syntax and guarantees similar to Unix file systems."
      },
      {
        "id": "B",
        "text": "By default, both the DBFS root and mounted data sources are only accessible to workspace administrators."
      },
      {
        "id": "C",
        "text": "The DBFS root is the most secure location to store data, because mounted storage volumes must have full public read and write permissions."
      },
      {
        "id": "D",
        "text": "Neither the DBFS root nor mounted storage can be accessed when using %sh in a Databricks notebook."
      },
      {
        "id": "E",
        "text": "The DBFS root stores files in ephemeral block volumes attached to the driver, while mounted directories will always persist saved data to external storage between sessions."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: Two of the most common data locations on Databricks are the DBFS root storage and external object storage mounted with dbutils.fs.mount().\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: DBFS is a file system protocol that allows users to interact with files stored in object storage using syntax and guarantees similar to Unix file systems. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: By default, both the DBFS root and mounted data sources are only accessible to workspace administrators. is wrong because it does not satisfy the requirement in the question (Two of the most common data locations on Databricks are the DBFS root storage and external object storage mounted with dbutils.fs.mount().) as stated.\n- C: The DBFS root is the most secure location to store data, because mounted storage volumes must have full public read and write permissions. is wrong because it does not satisfy the requirement in the question (Two of the most common data locations on Databricks are the DBFS root storage and external object storage mounted with dbutils.fs.mount().) as stated.\n- D: Neither the DBFS root nor mounted storage can be accessed when using %sh in a Databricks notebook. is wrong because it does not satisfy the requirement in the question (Two of the most common data locations on Databricks are the DBFS root storage and external object storage mounted with dbutils.fs.mount().) as stated.\n- E: The DBFS root stores files in ephemeral block volumes attached to the driver, while mounted directories will always persist saved data to external storage between sessions. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q065.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 66,
    "question": "The following code has been migrated to a Databricks notebook from a legacy workload: The code executes successfully and provides the logically correct results, however, it takes over 20 minutes to extract and load around 1 GB of data. Which statement is a possible explanation for this behavior?",
    "choices": [
      {
        "id": "A",
        "text": "%sh triggers a cluster restart to collect and install Git. Most of the latency is related to cluster startup time."
      },
      {
        "id": "B",
        "text": "Instead of cloning, the code should use %sh pip install so that the Python code can get executed in parallel across all nodes in a cluster."
      },
      {
        "id": "C",
        "text": "%sh does not distribute file moving operations; the final line of code should be updated to use %fs instead."
      },
      {
        "id": "D",
        "text": "Python will always execute slower than Scala on Databricks. The run.py script should be refactored to Scala."
      },
      {
        "id": "E",
        "text": "%sh executes shell code on the driver node. The code does not take advantage of the worker nodes or Databricks optimized Spark."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: The following code has been migrated to a Databricks notebook from a legacy workload: The code executes successfully and provides the logically correct results, however, it take...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why E is correct: %sh executes shell code on the driver node. The code does not take advantage of the worker nodes or Databricks optimized Spark. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: %sh triggers a cluster restart to collect and install Git. Most of the latency is related to cluster startup time. is wrong because it does not satisfy the requirement in the question (The following code has been migrated to a Databricks notebook from a legacy workload: The code executes successfully and provides the logically correct results, however, it take...) as stated.\n- B: Instead of cloning, the code should use %sh pip install so that the Python code can get executed in parallel across all nodes in a cluster. is wrong because it does not satisfy the requirement in the question (The following code has been migrated to a Databricks notebook from a legacy workload: The code executes successfully and provides the logically correct results, however, it take...) as stated.\n- C: %sh does not distribute file moving operations; the final line of code should be updated to use %fs instead. is wrong because it does not satisfy the requirement in the question (The following code has been migrated to a Databricks notebook from a legacy workload: The code executes successfully and provides the logically correct results, however, it take...) as stated.\n- D: Python will always execute slower than Scala on Databricks. The run.py script should be refactored to Scala. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q066.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 67,
    "question": "The data science team has requested assistance in accelerating queries on free form text from user reviews. The data is currently stored in Parquet with the below schema: item_id INT, user_id INT, review_id INT, rating FLOAT, review STRING The review column contains the full text of the review left by the user. Specifically, the data science team is looking to identify if any of 30 key words exist in this field. A junior data engineer suggests converting this data to Delta Lake will improve query performance. Which response to the junior data engineer s suggestion is correct?",
    "choices": [
      {
        "id": "A",
        "text": "Delta Lake statistics are not optimized for free text fields with high cardinality."
      },
      {
        "id": "B",
        "text": "Text data cannot be stored with Delta Lake."
      },
      {
        "id": "C",
        "text": "ZORDER ON review will need to be run to see performance gains."
      },
      {
        "id": "D",
        "text": "The Delta log creates a term matrix for free text fields to support selective filtering."
      },
      {
        "id": "E",
        "text": "Delta Lake statistics are only collected on the first 4 columns in a table."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: The data science team has requested assistance in accelerating queries on free form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...\n- Tested mechanism/concept: Parquet/Delta schema enforcement & evolution.\n- Why A is correct: Delta Lake statistics are not optimized for free text fields with high cardinality. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Text data cannot be stored with Delta Lake. is wrong because it does not satisfy the requirement in the question (The data science team has requested assistance in accelerating queries on free form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...) as stated.\n- C: ZORDER ON review will need to be run to see performance gains. is wrong because it does not satisfy the requirement in the question (The data science team has requested assistance in accelerating queries on free form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...) as stated.\n- D: The Delta log creates a term matrix for free text fields to support selective filtering. is wrong because it does not satisfy the requirement in the question (The data science team has requested assistance in accelerating queries on free form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...) as stated.\n- E: Delta Lake statistics are only collected on the first 4 columns in a table. is wrong because it does not satisfy the requirement in the question (The data science team has requested assistance in accelerating queries on free form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q067.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 68,
    "question": "Assuming that the Databricks CLI has been installed and configured correctly, which Databricks CLI command can be used to upload a custom Python Wheel to object storage mounted with the DBFS for use with a production job?",
    "choices": [
      {
        "id": "A",
        "text": "configure"
      },
      {
        "id": "B",
        "text": "fs"
      },
      {
        "id": "C",
        "text": "jobs"
      },
      {
        "id": "D",
        "text": "libraries"
      },
      {
        "id": "E",
        "text": "workspace"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Assuming that the Databricks CLI has been installed and configured correctly,\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: libraries directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: configure is wrong because it does not satisfy the requirement in the question (Assuming that the Databricks CLI has been installed and configured correctly,) as stated.\n- B: fs is wrong because it does not satisfy the requirement in the question (Assuming that the Databricks CLI has been installed and configured correctly,) as stated.\n- C: jobs is wrong because it does not satisfy the requirement in the question (Assuming that the Databricks CLI has been installed and configured correctly,) as stated.\n- E: workspace is wrong because it does not satisfy the requirement in the question (Assuming that the Databricks CLI has been installed and configured correctly,) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q068.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 69,
    "question": "The business intelligence team has a dashboard configured to track various summary metrics for retail stores. This includes total sales for the previous day alongside totals and averages for a variety of time periods. The fields required to populate this dashboard have the following schema: For demand forecasting, the Lakehouse contains a validated table of all itemized sales updated incrementally in near real-time. This table, named products_per_order, includes the following fields:    Because reporting on long-term sales trends is less volatile, analysts using the new dashboard only require data to be refreshed once daily. Because the dashboard will be queried interactively by many users throughout a normal business day, it should return results quickly and reduce total compute associated with each materialization. Which solution meets the expectations of the end users while controlling and limiting possible costs?",
    "choices": [
      {
        "id": "A",
        "text": "Populate the dashboard by configuring a nightly batch job to save the required values as a table overwritten with each update."
      },
      {
        "id": "B",
        "text": "Use Structured Streaming to configure a live dashboard against the products_per_order table within a Databricks notebook."
      },
      {
        "id": "C",
        "text": "Configure a webhook to execute an incremental read against products_per_order each time the dashboard is refreshed."
      },
      {
        "id": "D",
        "text": "Use the Delta Cache to persist the products_per_order table in memory to quickly update the dashboard with each query."
      },
      {
        "id": "E",
        "text": "Define a view against the products_per_order table and define the dashboard against this view."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: The business intelligence team has a dashboard configured to track various summary metrics for retail stores. This includes total sales for the previous day alongside totals and...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: Populate the dashboard by configuring a nightly batch job to save the required values as a table overwritten with each update. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Use Structured Streaming to configure a live dashboard against the products_per_order table within a Databricks notebook. is wrong because it does not satisfy the requirement in the question (The business intelligence team has a dashboard configured to track various summary metrics for retail stores. This includes total sales for the previous day alongside totals and...) as stated.\n- C: Configure a webhook to execute an incremental read against products_per_order each time the dashboard is refreshed. is wrong because it does not satisfy the requirement in the question (The business intelligence team has a dashboard configured to track various summary metrics for retail stores. This includes total sales for the previous day alongside totals and...) as stated.\n- D: Use the Delta Cache to persist the products_per_order table in memory to quickly update the dashboard with each query. is wrong because it does not satisfy the requirement in the question (The business intelligence team has a dashboard configured to track various summary metrics for retail stores. This includes total sales for the previous day alongside totals and...) as stated.\n- E: Define a view against the products_per_order table and define the dashboard against this view. is wrong because it does not satisfy the requirement in the question (The business intelligence team has a dashboard configured to track various summary metrics for retail stores. This includes total sales for the previous day alongside totals and...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q069.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 70,
    "question": "A data ingestion task requires a one-TB JSON dataset to be written out to Parquet with a target part-file size of 512 MB. Because Parquet is being used instead of Delta Lake, built-in file-sizing features such as Auto-Optimize & Auto-Compaction cannot be used. Which strategy will yield the best performance without shuffling data?",
    "choices": [
      {
        "id": "A",
        "text": "Set spark.sql.files.maxPartitionBytes to 512 MB, ingest the data, execute the narrow transformations, and then write to parquet."
      },
      {
        "id": "B",
        "text": "Set spark.sql.shuffle.partitions to 2,048 partitions (1TB*1024*1024/512), ingest the data, execute the narrow transformations, optimize the data by sorting it (which automatically repartitions the data), and then write to parquet."
      },
      {
        "id": "C",
        "text": "Set spark.sql.adaptive.advisoryPartitionSizeInBytes to 512 MB bytes, ingest the data, execute the narrow transformations, coalesce to 2,048 partitions (1TB*1024*1024/512), and then write to parquet."
      },
      {
        "id": "D",
        "text": "Ingest the data, execute the narrow transformations, repartition to 2,048 partitions (1TB* 1024*1024/512), and then write to parquet."
      },
      {
        "id": "E",
        "text": "Set spark.sql.shuffle.partitions to 512, ingest the data, execute the narrow transformations, and then write to parquet."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A data ingestion task requires a one-TB JSON dataset to be written out to Parquet with a target part-file size of 512 MB. Because Parquet is being used instead of Delta Lake, bu...\n- Tested mechanism/concept: Delta Lake maintenance operations (OPTIMIZE/Z-ORDER/VACUUM) and file layout.\n- Why A is correct: Set spark.sql.files.maxPartitionBytes to 512 MB, ingest the data, execute the narrow transformations, and then write to parquet. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Set spark.sql.shuffle.partitions to 2,048 partitions (1TB*1024*1024/512), ingest the data, execute the narrow transformations, optimize the data by sorting it (which automatically repartitions the data), and then write to parquet. is wrong because it does not satisfy the requirement in the question (A data ingestion task requires a one-TB JSON dataset to be written out to Parquet with a target part-file size of 512 MB. Because Parquet is being used instead of Delta Lake, bu...) as stated.\n- C: Set spark.sql.adaptive.advisoryPartitionSizeInBytes to 512 MB bytes, ingest the data, execute the narrow transformations, coalesce to 2,048 partitions (1TB*1024*1024/512), and then write to parquet. is wrong because it does not satisfy the requirement in the question (A data ingestion task requires a one-TB JSON dataset to be written out to Parquet with a target part-file size of 512 MB. Because Parquet is being used instead of Delta Lake, bu...) as stated.\n- D: Ingest the data, execute the narrow transformations, repartition to 2,048 partitions (1TB* 1024*1024/512), and then write to parquet. is wrong because it does not satisfy the requirement in the question (A data ingestion task requires a one-TB JSON dataset to be written out to Parquet with a target part-file size of 512 MB. Because Parquet is being used instead of Delta Lake, bu...) as stated.\n- E: Set spark.sql.shuffle.partitions to 512, ingest the data, execute the narrow transformations, and then write to parquet. is wrong because it does not satisfy the requirement in the question (A data ingestion task requires a one-TB JSON dataset to be written out to Parquet with a target part-file size of 512 MB. Because Parquet is being used instead of Delta Lake, bu...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q070.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 71,
    "question": "A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity and average temperature for each non- overlapping five-minute interval. Incremental state information should be maintained for 10 minutes for late- arriving data. Streaming DataFrame df has the following schema: \"device_id INT, event_time TIMESTAMP, temp FLOAT, humidity FLOAT\" Code block:   Choose the response that correctly fills in the blank within the code block to complete this task.",
    "choices": [
      {
        "id": "A",
        "text": "withWatermark(\"event_time\", \"10 minutes\")"
      },
      {
        "id": "B",
        "text": "awaitArrival(\"event_time\", \"10 minutes\")"
      },
      {
        "id": "C",
        "text": "await(\"event_time + ‘10 minutes'\")"
      },
      {
        "id": "D",
        "text": "slidingWindow(\"event_time\", \"10 minutes\")"
      },
      {
        "id": "E",
        "text": "delayWrite(\"event_time\", \"10 minutes\")"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why A is correct: withWatermark(\"event_time\", \"10 minutes\") directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: awaitArrival(\"event_time\", \"10 minutes\") is wrong because it does not satisfy the requirement in the question (A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...) as stated.\n- C: await(\"event_time + ‘10 minutes'\") is wrong because it does not satisfy the requirement in the question (A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...) as stated.\n- D: slidingWindow(\"event_time\", \"10 minutes\") is wrong because it does not satisfy the requirement in the question (A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...) as stated.\n- E: delayWrite(\"event_time\", \"10 minutes\") is wrong because it does not satisfy the requirement in the question (A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q071.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 72,
    "question": "A data team's Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced a new promotion, and they would like to add a new field to track the number of times this promotion code is used for each item. A junior data engineer suggests updating the existing query as follows. Note that proposed changes are in bold. Original query: Proposed query:  Proposed query: .start(“/item_agg”) Which step must also be completed to put the proposed query into production?",
    "choices": [
      {
        "id": "A",
        "text": "Specify a new checkpointLocation"
      },
      {
        "id": "B",
        "text": "Increase the shuffle partitions to account for additional aggregates"
      },
      {
        "id": "C",
        "text": "Run REFRESH TABLE delta.'/item_agg'"
      },
      {
        "id": "D",
        "text": "Register the data in the \"/item_agg\" directory to the Hive metastore"
      },
      {
        "id": "E",
        "text": "Remove .option(‘mergeSchema’, ‘true’) from the streaming write"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A data team's Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...\n- Tested mechanism/concept: Structured Streaming checkpoints & trigger semantics.\n- Why A is correct: Specify a new checkpointLocation directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Increase the shuffle partitions to account for additional aggregates is wrong because it does not satisfy the requirement in the question (A data team's Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...) as stated.\n- C: Run REFRESH TABLE delta.'/item_agg' is wrong because it does not satisfy the requirement in the question (A data team's Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...) as stated.\n- D: Register the data in the \"/item_agg\" directory to the Hive metastore is wrong because it does not satisfy the requirement in the question (A data team's Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...) as stated.\n- E: Remove .option(‘mergeSchema’, ‘true’) from the streaming write is wrong because it does not satisfy the requirement in the question (A data team's Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q072.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 73,
    "question": "A Structured Streaming job deployed to production has been resulting in higher than expected cloud storage costs. At present, during normal execution, each microbatch of data is processed in less than 3s; at least 12 times per minute, a microbatch is processed that contains 0 records. The streaming write was configured using the default trigger settings. The production job is currently scheduled alongside many other Databricks jobs in a workspace with instance pools provisioned to reduce start-up time for jobs with batch execution. Holding all other variables constant and assuming records need to be processed in less than 10 minutes, which adjustment will meet the requirement?",
    "choices": [
      {
        "id": "A",
        "text": "Set the trigger interval to 3 seconds; the default trigger interval is consuming too many records per batch, resulting in spill to disk that can increase volume costs."
      },
      {
        "id": "B",
        "text": "Increase the number of shuffle partitions to maximize parallelism, since the trigger interval cannot be modified without modifying the checkpoint directory."
      },
      {
        "id": "C",
        "text": "Set the trigger interval to 10 minutes; each batch calls APIs in the source storage account, so decreasing trigger frequency to maximum allowable threshold should minimize this cost."
      },
      {
        "id": "D",
        "text": "Set the trigger interval to 500 milliseconds; setting a small but non-zero trigger interval ensures that the source is not queried too frequently."
      },
      {
        "id": "E",
        "text": "Use the trigger once option and configure a Databricks job to execute the query every 10 minutes; this approach minimizes costs for both compute and storage."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A Structured Streaming job deployed to production has been resulting in higher than expected cloud storage costs. At present, during normal execution, each microbatch of data is...\n- Tested mechanism/concept: Structured Streaming checkpoints & trigger semantics.\n- Why C is correct: Set the trigger interval to 10 minutes; each batch calls APIs in the source storage account, so decreasing trigger frequency to maximum allowable threshold should minimize this cost. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Set the trigger interval to 3 seconds; the default trigger interval is consuming too many records per batch, resulting in spill to disk that can increase volume costs. is wrong because it does not satisfy the requirement in the question (A Structured Streaming job deployed to production has been resulting in higher than expected cloud storage costs. At present, during normal execution, each microbatch of data is...) as stated.\n- B: Increase the number of shuffle partitions to maximize parallelism, since the trigger interval cannot be modified without modifying the checkpoint directory. is wrong because it does not satisfy the requirement in the question (A Structured Streaming job deployed to production has been resulting in higher than expected cloud storage costs. At present, during normal execution, each microbatch of data is...) as stated.\n- D: Set the trigger interval to 500 milliseconds; setting a small but non-zero trigger interval ensures that the source is not queried too frequently. is wrong because it does not satisfy the requirement in the question (A Structured Streaming job deployed to production has been resulting in higher than expected cloud storage costs. At present, during normal execution, each microbatch of data is...) as stated.\n- E: Use the trigger once option and configure a Databricks job to execute the query every 10 minutes; this approach minimizes costs for both compute and storage. is wrong because it does not satisfy the requirement in the question (A Structured Streaming job deployed to production has been resulting in higher than expected cloud storage costs. At present, during normal execution, each microbatch of data is...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q073.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 74,
    "question": "Which statement describes the correct use of pyspark.sql.functions.broadcast?",
    "choices": [
      {
        "id": "A",
        "text": "It marks a column as having low enough cardinality to properly map distinct values to available partitions, allowing a broadcast join."
      },
      {
        "id": "B",
        "text": "It marks a column as small enough to store in memory on all executors, allowing a broadcast join."
      },
      {
        "id": "C",
        "text": "It caches a copy of the indicated table on attached storage volumes for all active clusters within a Databricks workspace."
      },
      {
        "id": "D",
        "text": "It marks a DataFrame as small enough to store in memory on all executors, allowing a broadcast join."
      },
      {
        "id": "E",
        "text": "It caches a copy of the indicated table on all nodes in the cluster for use in all future queries during the cluster lifetime."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: It marks a DataFrame as small enough to store in memory on all executors, allowing a broadcast join. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: It marks a column as having low enough cardinality to properly map distinct values to available partitions, allowing a broadcast join. is wrong because it does not satisfy the requirement in the question () as stated.\n- B: It marks a column as small enough to store in memory on all executors, allowing a broadcast join. is wrong because it does not satisfy the requirement in the question () as stated.\n- C: It caches a copy of the indicated table on attached storage volumes for all active clusters within a Databricks workspace. is wrong because it does not satisfy the requirement in the question () as stated.\n- E: It caches a copy of the indicated table on all nodes in the cluster for use in all future queries during the cluster lifetime. is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q074.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 75,
    "question": "A data engineer is configuring a pipeline that will potentially see late-arriving, duplicate records. In addition to de-duplicating records within the batch, which of the following approaches allows the data engineer to deduplicate data against previously processed records as it is inserted into a Delta table?",
    "choices": [
      {
        "id": "A",
        "text": "Set the configuration delta.deduplicate = true."
      },
      {
        "id": "B",
        "text": "VACUUM the Delta table after each batch completes."
      },
      {
        "id": "C",
        "text": "Perform an insert-only merge with a matching condition on a unique key."
      },
      {
        "id": "D",
        "text": "Perform a full outer join on a unique key and overwrite existing data."
      },
      {
        "id": "E",
        "text": "Rely on Delta Lake schema enforcement to prevent duplicate records."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A data engineer is configuring a pipeline that will potentially see late-arriving, duplicate records. In addition to de-duplicating records within the batch,\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: Perform an insert-only merge with a matching condition on a unique key. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Set the configuration delta.deduplicate = true. is wrong because it does not satisfy the requirement in the question (A data engineer is configuring a pipeline that will potentially see late-arriving, duplicate records. In addition to de-duplicating records within the batch,) as stated.\n- B: VACUUM the Delta table after each batch completes. is wrong because it does not satisfy the requirement in the question (A data engineer is configuring a pipeline that will potentially see late-arriving, duplicate records. In addition to de-duplicating records within the batch,) as stated.\n- D: Perform a full outer join on a unique key and overwrite existing data. is wrong because it does not satisfy the requirement in the question (A data engineer is configuring a pipeline that will potentially see late-arriving, duplicate records. In addition to de-duplicating records within the batch,) as stated.\n- E: Rely on Delta Lake schema enforcement to prevent duplicate records. is wrong because it does not satisfy the requirement in the question (A data engineer is configuring a pipeline that will potentially see late-arriving, duplicate records. In addition to de-duplicating records within the batch,) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q075.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 76,
    "question": "A data pipeline uses Structured Streaming to ingest data from Apache Kafka to Delta Lake. Data is being stored in a bronze table, and includes the Kafka-generated timestamp, key, and value. Three months after the pipeline is deployed, the data engineering team has noticed some latency issues during certain times of the day. A senior data engineer updates the Delta Table's schema and ingestion logic to include the current timestamp (as recorded by Apache Spark) as well as the Kafka topic and partition. The team plans to use these additional metadata fields to diagnose the transient processing delays. Which limitation will the team face while diagnosing this problem?",
    "choices": [
      {
        "id": "A",
        "text": "New fields will not be computed for historic records."
      },
      {
        "id": "B",
        "text": "Spark cannot capture the topic and partition fields from a Kafka source."
      },
      {
        "id": "C",
        "text": "New fields cannot be added to a production Delta table."
      },
      {
        "id": "D",
        "text": "Updating the table schema will invalidate the Delta transaction log metadata."
      },
      {
        "id": "E",
        "text": "Updating the table schema requires a default value provided for each field added."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A data pipeline uses Structured Streaming to ingest data from Apache Kafka to Delta Lake. Data is being stored in a bronze table, and includes the Kafka-generated timestamp, key...\n- Tested mechanism/concept: Structured Streaming checkpoints & trigger semantics.\n- Why A is correct: New fields will not be computed for historic records. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Spark cannot capture the topic and partition fields from a Kafka source. is wrong because it does not satisfy the requirement in the question (A data pipeline uses Structured Streaming to ingest data from Apache Kafka to Delta Lake. Data is being stored in a bronze table, and includes the Kafka-generated timestamp, key...) as stated.\n- C: New fields cannot be added to a production Delta table. is wrong because it does not satisfy the requirement in the question (A data pipeline uses Structured Streaming to ingest data from Apache Kafka to Delta Lake. Data is being stored in a bronze table, and includes the Kafka-generated timestamp, key...) as stated.\n- D: Updating the table schema will invalidate the Delta transaction log metadata. is wrong because it does not satisfy the requirement in the question (A data pipeline uses Structured Streaming to ingest data from Apache Kafka to Delta Lake. Data is being stored in a bronze table, and includes the Kafka-generated timestamp, key...) as stated.\n- E: Updating the table schema requires a default value provided for each field added. is wrong because it does not satisfy the requirement in the question (A data pipeline uses Structured Streaming to ingest data from Apache Kafka to Delta Lake. Data is being stored in a bronze table, and includes the Kafka-generated timestamp, key...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q076.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 77,
    "question": "In order to facilitate near real-time workloads, a data engineer is creating a helper function to leverage the schema detection and evolution functionality of Databricks Auto Loader. The desired function will automatically detect the schema of the source directly, incrementally process JSON files as they arrive in a source directory, and    automatically evolve the schema of the table when new fields are detected. The function is displayed below with a blank: Which response correctly fills in the blank to meet the specified requirements?",
    "choices": [
      {
        "id": "A",
        "text": ""
      },
      {
        "id": "B",
        "text": ""
      },
      {
        "id": "C",
        "text": ""
      },
      {
        "id": "D",
        "text": ""
      },
      {
        "id": "E",
        "text": ""
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: In order to facilitate near real-time workloads, a data engineer is creating a helper function to leverage the schema detection and evolution functionality of Databricks Auto Lo...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why E is correct:  directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A:  is wrong because it does not satisfy the requirement in the question (In order to facilitate near real-time workloads, a data engineer is creating a helper function to leverage the schema detection and evolution functionality of Databricks Auto Lo...) as stated.\n- B:  is wrong because it does not satisfy the requirement in the question (In order to facilitate near real-time workloads, a data engineer is creating a helper function to leverage the schema detection and evolution functionality of Databricks Auto Lo...) as stated.\n- C:  is wrong because it does not satisfy the requirement in the question (In order to facilitate near real-time workloads, a data engineer is creating a helper function to leverage the schema detection and evolution functionality of Databricks Auto Lo...) as stated.\n- D:  is wrong because it does not satisfy the requirement in the question (In order to facilitate near real-time workloads, a data engineer is creating a helper function to leverage the schema detection and evolution functionality of Databricks Auto Lo...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q077.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 78,
    "question": "The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source table has been de-duplicated and validated, which statement describes what will occur when this code is executed?",
    "choices": [
      {
        "id": "A",
        "text": "The silver_customer_sales table will be overwritten by aggregated values calculated from all records in the gold_customer_lifetime_sales_summary table as a batch job."
      },
      {
        "id": "B",
        "text": "A batch job will update the gold_customer_lifetime_sales_summary table, replacing only those rows that have different values than the current version of the table, using customer_id as the primary key."
      },
      {
        "id": "C",
        "text": "The gold_customer_lifetime_sales_summary table will be overwritten by aggregated values calculated from all records in the silver_customer_sales table as a batch job."
      },
      {
        "id": "D",
        "text": "An incremental job will leverage running information in the state store to update aggregate values in the gold_customer_lifetime_sales_summary table."
      },
      {
        "id": "E",
        "text": "An incremental job will detect if new rows have been written to the silver_customer_sales table; if new rows are detected, all aggregates will be recalculated and used to overwrite the gold_customer_lifetime_sales_summary table."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source table has been de-duplicated and va...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: The gold_customer_lifetime_sales_summary table will be overwritten by aggregated values calculated from all records in the silver_customer_sales table as a batch job. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The silver_customer_sales table will be overwritten by aggregated values calculated from all records in the gold_customer_lifetime_sales_summary table as a batch job. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source table has been de-duplicated and va...) as stated.\n- B: A batch job will update the gold_customer_lifetime_sales_summary table, replacing only those rows that have different values than the current version of the table, using customer_id as the primary key. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source table has been de-duplicated and va...) as stated.\n- D: An incremental job will leverage running information in the state store to update aggregate values in the gold_customer_lifetime_sales_summary table. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source table has been de-duplicated and va...) as stated.\n- E: An incremental job will detect if new rows have been written to the silver_customer_sales table; if new rows are detected, all aggregates will be recalculated and used to overwrite the gold_customer_lifetime_sales_summary table. is wrong because it does not satisfy the requirement in the question (The data engineering team maintains the following code: Assuming that this code produces logically correct results and the data in the source table has been de-duplicated and va...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q078.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 79,
    "question": "The data architect has mandated that all tables in the Lakehouse should be configured as external (also known as \"unmanaged\") Delta Lake tables. Which approach will ensure that this requirement is met?",
    "choices": [
      {
        "id": "A",
        "text": "When a database is being created, make sure that the LOCATION keyword is used."
      },
      {
        "id": "B",
        "text": "When configuring an external data warehouse for all table storage, leverage Databricks for all ELT."
      },
      {
        "id": "C",
        "text": "When data is saved to a table, make sure that a full file path is specified alongside the Delta format."
      },
      {
        "id": "D",
        "text": "When tables are created, make sure that the EXTERNAL keyword is used in the CREATE TABLE statement."
      },
      {
        "id": "E",
        "text": "When the workspace is being configured, make sure that external cloud object storage has been mounted."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: The data architect has mandated that all tables in the Lakehouse should be configured as external (also known as \"unmanaged\") Delta Lake tables.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: When data is saved to a table, make sure that a full file path is specified alongside the Delta format. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: When a database is being created, make sure that the LOCATION keyword is used. is wrong because it does not satisfy the requirement in the question (The data architect has mandated that all tables in the Lakehouse should be configured as external (also known as \"unmanaged\") Delta Lake tables.) as stated.\n- B: When configuring an external data warehouse for all table storage, leverage Databricks for all ELT. is wrong because it does not satisfy the requirement in the question (The data architect has mandated that all tables in the Lakehouse should be configured as external (also known as \"unmanaged\") Delta Lake tables.) as stated.\n- D: When tables are created, make sure that the EXTERNAL keyword is used in the CREATE TABLE statement. is wrong because it does not satisfy the requirement in the question (The data architect has mandated that all tables in the Lakehouse should be configured as external (also known as \"unmanaged\") Delta Lake tables.) as stated.\n- E: When the workspace is being configured, make sure that external cloud object storage has been mounted. is wrong because it does not satisfy the requirement in the question (The data architect has mandated that all tables in the Lakehouse should be configured as external (also known as \"unmanaged\") Delta Lake tables.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q079.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 80,
    "question": "The marketing team is looking to share data in an aggregate table with the sales organization, but the field names used by the teams do not match, and a number of marketing-specific fields have not been approved for the sales org. Which of the following solutions addresses the situation while emphasizing simplicity?",
    "choices": [
      {
        "id": "A",
        "text": "Create a view on the marketing table selecting only those fields approved for the sales team; alias the names of any fields that should be standardized to the sales naming conventions."
      },
      {
        "id": "B",
        "text": "Create a new table with the required schema and use Delta Lake's DEEP CLONE functionality to sync up changes committed to one table to the corresponding table."
      },
      {
        "id": "C",
        "text": "Use a CTAS statement to create a derivative table from the marketing table; configure a production job to propagate changes."
      },
      {
        "id": "D",
        "text": "Add a parallel table write to the current production pipeline, updating a new sales table that varies as required from the marketing table."
      },
      {
        "id": "E",
        "text": "Instruct the marketing team to download results as a CSV and email them to the sales organization."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: The marketing team is looking to share data in an aggregate table with the sales organization, but the field names used by the teams do not match, and a number of marketing-spec...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: Create a view on the marketing table selecting only those fields approved for the sales team; alias the names of any fields that should be standardized to the sales naming conventions. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Create a new table with the required schema and use Delta Lake's DEEP CLONE functionality to sync up changes committed to one table to the corresponding table. is wrong because it does not satisfy the requirement in the question (The marketing team is looking to share data in an aggregate table with the sales organization, but the field names used by the teams do not match, and a number of marketing-spec...) as stated.\n- C: Use a CTAS statement to create a derivative table from the marketing table; configure a production job to propagate changes. is wrong because it does not satisfy the requirement in the question (The marketing team is looking to share data in an aggregate table with the sales organization, but the field names used by the teams do not match, and a number of marketing-spec...) as stated.\n- D: Add a parallel table write to the current production pipeline, updating a new sales table that varies as required from the marketing table. is wrong because it does not satisfy the requirement in the question (The marketing team is looking to share data in an aggregate table with the sales organization, but the field names used by the teams do not match, and a number of marketing-spec...) as stated.\n- E: Instruct the marketing team to download results as a CSV and email them to the sales organization. is wrong because it does not satisfy the requirement in the question (The marketing team is looking to share data in an aggregate table with the sales organization, but the field names used by the teams do not match, and a number of marketing-spec...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q080.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 81,
    "question": "A CHECK constraint has been successfully added to the Delta table named activity_details using the following logic:    A batch job is attempting to insert new records to the table, including a record where latitude = 45.50 and longitude = 212.67. Which statement describes the outcome of this batch insert?",
    "choices": [
      {
        "id": "A",
        "text": "The write will fail when the violating record is reached; any records previously processed will be recorded to the target table."
      },
      {
        "id": "B",
        "text": "The write will fail completely because of the constraint violation and no records will be inserted into the target table."
      },
      {
        "id": "C",
        "text": "The write will insert all records except those that violate the table constraints; the violating records will be recorded to a quarantine table."
      },
      {
        "id": "D",
        "text": "The write will include all records in the target table; any violations will be indicated in the boolean column named valid_coordinates."
      },
      {
        "id": "E",
        "text": "The write will insert all records except those that violate the table constraints; the violating records will be reported in a warning log."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: A CHECK constraint has been successfully added to the Delta table named activity_details using the following logic: A batch job is attempting to insert new records to the table,...\n- Tested mechanism/concept: Databricks Repos (Git integration, branch/commit/pull).\n- Why B is correct: The write will fail completely because of the constraint violation and no records will be inserted into the target table. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The write will fail when the violating record is reached; any records previously processed will be recorded to the target table. is wrong because it does not satisfy the requirement in the question (A CHECK constraint has been successfully added to the Delta table named activity_details using the following logic: A batch job is attempting to insert new records to the table,...) as stated.\n- C: The write will insert all records except those that violate the table constraints; the violating records will be recorded to a quarantine table. is wrong because it does not satisfy the requirement in the question (A CHECK constraint has been successfully added to the Delta table named activity_details using the following logic: A batch job is attempting to insert new records to the table,...) as stated.\n- D: The write will include all records in the target table; any violations will be indicated in the boolean column named valid_coordinates. is wrong because it does not satisfy the requirement in the question (A CHECK constraint has been successfully added to the Delta table named activity_details using the following logic: A batch job is attempting to insert new records to the table,...) as stated.\n- E: The write will insert all records except those that violate the table constraints; the violating records will be reported in a warning log. is wrong because it does not satisfy the requirement in the question (A CHECK constraint has been successfully added to the Delta table named activity_details using the following logic: A batch job is attempting to insert new records to the table,...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q081.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 82,
    "question": "A junior data engineer has manually configured a series of jobs using the Databricks Jobs UI. Upon reviewing their work, the engineer realizes that they are listed as the \"Owner\" for each job. They attempt to transfer \"Owner\" privileges to the \"DevOps\" group, but cannot successfully accomplish this task. Which statement explains what is preventing this privilege transfer?",
    "choices": [
      {
        "id": "A",
        "text": "Databricks jobs must have exactly one owner; \"Owner\" privileges cannot be assigned to a group."
      },
      {
        "id": "B",
        "text": "The creator of a Databricks job will always have \"Owner\" privileges; this configuration cannot be changed."
      },
      {
        "id": "C",
        "text": "Other than the default \"admins\" group, only individual users can be granted privileges on jobs."
      },
      {
        "id": "D",
        "text": "A user can only transfer job ownership to a group if they are also a member of that group."
      },
      {
        "id": "E",
        "text": "Only workspace administrators can grant \"Owner\" privileges to a group."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A junior data engineer has manually configured a series of jobs using the Databricks Jobs UI. Upon reviewing their work, the engineer realizes that they are listed as the \"Owner...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: Databricks jobs must have exactly one owner; \"Owner\" privileges cannot be assigned to a group. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: The creator of a Databricks job will always have \"Owner\" privileges; this configuration cannot be changed. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n- C: Other than the default \"admins\" group, only individual users can be granted privileges on jobs. is wrong because it does not satisfy the requirement in the question (A junior data engineer has manually configured a series of jobs using the Databricks Jobs UI. Upon reviewing their work, the engineer realizes that they are listed as the \"Owner...) as stated.\n- D: A user can only transfer job ownership to a group if they are also a member of that group. is wrong because it does not satisfy the requirement in the question (A junior data engineer has manually configured a series of jobs using the Databricks Jobs UI. Upon reviewing their work, the engineer realizes that they are listed as the \"Owner...) as stated.\n- E: Only workspace administrators can grant \"Owner\" privileges to a group. is wrong because it does not satisfy the requirement in the question (A junior data engineer has manually configured a series of jobs using the Databricks Jobs UI. Upon reviewing their work, the engineer realizes that they are listed as the \"Owner...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q082.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 83,
    "question": "All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema:   key BINARY, value BINARY, topic STRING, partition LONG, offset LONG, timestamp LONG There are 5 unique topics being ingested. Only the \"registration\" topic contains Personal Identifiable Information (PII). The company wishes to restrict access to PII. The company also wishes to only retain records containing PII in this table for 14 days after initial ingestion. However, for non-PII information, it would like to retain these records indefinitely. Which of the following solutions meets the requirements?",
    "choices": [
      {
        "id": "A",
        "text": "All data should be deleted biweekly; Delta Lake's time travel functionality should be leveraged to maintain a history of non-PII information."
      },
      {
        "id": "B",
        "text": "Data should be partitioned by the registration field, allowing ACLs and delete statements to be set for the PII directory."
      },
      {
        "id": "C",
        "text": "Because the value field is stored as binary data, this information is not considered PII and no special precautions should be taken."
      },
      {
        "id": "D",
        "text": "Separate object storage containers should be specified based on the partition field, allowing isolation at the storage level."
      },
      {
        "id": "E",
        "text": "Data should be partitioned by the topic field, allowing ACLs and delete statements to leverage partition boundaries."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why E is correct: Data should be partitioned by the topic field, allowing ACLs and delete statements to leverage partition boundaries. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: All data should be deleted biweekly; Delta Lake's time travel functionality should be leveraged to maintain a history of non-PII information. is wrong because it does not satisfy the requirement in the question (All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...) as stated.\n- B: Data should be partitioned by the registration field, allowing ACLs and delete statements to be set for the PII directory. is wrong because it does not satisfy the requirement in the question (All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...) as stated.\n- C: Because the value field is stored as binary data, this information is not considered PII and no special precautions should be taken. is wrong because it does not satisfy the requirement in the question (All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...) as stated.\n- D: Separate object storage containers should be specified based on the partition field, allowing isolation at the storage level. is wrong because it does not satisfy the requirement in the question (All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q083.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 84,
    "question": "The data architect has decided that once data has been ingested from external sources into the Databricks Lakehouse, table access controls will be leveraged to manage permissions for all production tables and views. The following logic was executed to grant privileges for interactive queries on a production database to the core engineering group. GRANT USAGE ON DATABASE prod TO eng; GRANT SELECT ON DATABASE prod TO eng; Assuming these are the only privileges that have been granted to the eng group and that these users are not workspace administrators, which statement describes their privileges?",
    "choices": [
      {
        "id": "A",
        "text": "Group members have full permissions on the prod database and can also assign permissions to other users or groups."
      },
      {
        "id": "B",
        "text": "Group members are able to list all tables in the prod database but are not able to see the results of any queries on those tables."
      },
      {
        "id": "C",
        "text": "Group members are able to query and modify all tables and views in the prod database, but cannot create new tables or views."
      },
      {
        "id": "D",
        "text": "Group members are able to query all tables and views in the prod database, but cannot create or edit anything in the database."
      },
      {
        "id": "E",
        "text": "Group members are able to create, query, and modify all tables and views in the prod database, but cannot define custom functions."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: The data architect has decided that once data has been ingested from external sources into the Databricks Lakehouse, table access controls will be leveraged to manage permission...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: Group members are able to query all tables and views in the prod database, but cannot create or edit anything in the database. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Group members have full permissions on the prod database and can also assign permissions to other users or groups. is wrong because it does not satisfy the requirement in the question (The data architect has decided that once data has been ingested from external sources into the Databricks Lakehouse, table access controls will be leveraged to manage permission...) as stated.\n- B: Group members are able to list all tables in the prod database but are not able to see the results of any queries on those tables. is wrong because it does not satisfy the requirement in the question (The data architect has decided that once data has been ingested from external sources into the Databricks Lakehouse, table access controls will be leveraged to manage permission...) as stated.\n- C: Group members are able to query and modify all tables and views in the prod database, but cannot create new tables or views. is wrong because it does not satisfy the requirement in the question (The data architect has decided that once data has been ingested from external sources into the Databricks Lakehouse, table access controls will be leveraged to manage permission...) as stated.\n- E: Group members are able to create, query, and modify all tables and views in the prod database, but cannot define custom functions. is wrong because it does not satisfy the requirement in the question (The data architect has decided that once data has been ingested from external sources into the Databricks Lakehouse, table access controls will be leveraged to manage permission...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q084.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 85,
    "question": "A distributed team of data analysts share computing resources on an interactive cluster with autoscaling configured. In order to better manage costs and query throughput, the workspace administrator is hoping to evaluate whether cluster upscaling is caused by many concurrent users or resource-intensive queries.   In which location can one review the timeline for cluster resizing events?",
    "choices": [
      {
        "id": "A",
        "text": "Workspace audit logs"
      },
      {
        "id": "B",
        "text": "Driver's log file"
      },
      {
        "id": "C",
        "text": "Ganglia"
      },
      {
        "id": "D",
        "text": "Cluster Event Log"
      },
      {
        "id": "E",
        "text": "Executor's log file"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A distributed team of data analysts share computing resources on an interactive cluster with autoscaling configured. In order to better manage costs and query throughput, the wo...\n- Tested mechanism/concept: Databricks compute configuration (clusters, jobs compute, pools).\n- Why D is correct: Cluster Event Log directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Workspace audit logs is wrong because it does not satisfy the requirement in the question (A distributed team of data analysts share computing resources on an interactive cluster with autoscaling configured. In order to better manage costs and query throughput, the wo...) as stated.\n- B: Driver's log file is wrong because the question asks where in the Spark UI to diagnose this; grepping executor logs is not the Spark UI diagnostic path.\n- C: Ganglia is wrong because it does not satisfy the requirement in the question (A distributed team of data analysts share computing resources on an interactive cluster with autoscaling configured. In order to better manage costs and query throughput, the wo...) as stated.\n- E: Executor's log file is wrong because the question asks where in the Spark UI to diagnose this; grepping executor logs is not the Spark UI diagnostic path.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q085.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 86,
    "question": "When evaluating the Ganglia Metrics for a given cluster with 3 executor nodes, which indicator would signal proper utilization of the VM's resources?",
    "choices": [
      {
        "id": "A",
        "text": "The five Minute Load Average remains consistent/flat"
      },
      {
        "id": "B",
        "text": "Bytes Received never exceeds 80 million bytes per second"
      },
      {
        "id": "C",
        "text": "Network I/O never spikes"
      },
      {
        "id": "D",
        "text": "Total Disk Space remains constant"
      },
      {
        "id": "E",
        "text": "CPU Utilization is around 75%"
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: Databricks compute configuration (clusters, jobs compute, pools).\n- Why E is correct: CPU Utilization is around 75% directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The five Minute Load Average remains consistent/flat is wrong because it does not satisfy the requirement in the question () as stated.\n- B: Bytes Received never exceeds 80 million bytes per second is wrong because it does not satisfy the requirement in the question () as stated.\n- C: Network I/O never spikes is wrong because it does not satisfy the requirement in the question () as stated.\n- D: Total Disk Space remains constant is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q086.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 87,
    "question": "Which of the following technologies can be used to identify key areas of text when parsing Spark Driver log4j output?",
    "choices": [
      {
        "id": "A",
        "text": "Regex"
      },
      {
        "id": "B",
        "text": "Julia"
      },
      {
        "id": "C",
        "text": "pyspsark.ml.feature"
      },
      {
        "id": "D",
        "text": "Scala Datasets"
      },
      {
        "id": "E",
        "text": "C++"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: Regex directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Julia is wrong because it does not satisfy the requirement in the question () as stated.\n- C: pyspsark.ml.feature is wrong because it does not satisfy the requirement in the question () as stated.\n- D: Scala Datasets is wrong because it does not satisfy the requirement in the question () as stated.\n- E: C++ is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q087.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 88,
    "question": "You are testing a collection of mathematical functions, one of which calculates the area under a curve as described by another function. assert(myIntegrate(lambda x: x*x, 0, 3) [0] == 9) Which kind of test would the above line exemplify?",
    "choices": [
      {
        "id": "A",
        "text": "Unit"
      },
      {
        "id": "B",
        "text": "Manual"
      },
      {
        "id": "C",
        "text": "Functional"
      },
      {
        "id": "D",
        "text": "Integration"
      },
      {
        "id": "E",
        "text": "End-to-end"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: You are testing a collection of mathematical functions, one of\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: Unit directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Manual is wrong because it does not satisfy the requirement in the question (You are testing a collection of mathematical functions, one of) as stated.\n- C: Functional is wrong because it does not satisfy the requirement in the question (You are testing a collection of mathematical functions, one of) as stated.\n- D: Integration is wrong because it does not satisfy the requirement in the question (You are testing a collection of mathematical functions, one of) as stated.\n- E: End-to-end is wrong because it does not satisfy the requirement in the question (You are testing a collection of mathematical functions, one of) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q088.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 89,
    "question": "A Databricks job has been configured with 3 tasks, each of which is a Databricks notebook. Task A does not depend on other tasks. Tasks B and C run in parallel, with each having a serial dependency on Task A. If task A fails during a scheduled run, which statement describes the results of this run?",
    "choices": [
      {
        "id": "A",
        "text": "Because all tasks are managed as a dependency graph, no changes will be committed to the Lakehouse until all tasks have successfully been completed."
      },
      {
        "id": "B",
        "text": "Tasks B and C will attempt to run as configured; any changes made in task A will be rolled back due to task failure."
      },
      {
        "id": "C",
        "text": "Unless all tasks complete successfully, no changes will be committed to the Lakehouse; because task A failed, all commits will be rolled back automatically."
      },
      {
        "id": "D",
        "text": "Tasks B and C will be skipped; some logic expressed in task A may have been committed before task failure."
      },
      {
        "id": "E",
        "text": "Tasks B and C will be skipped; task A will not commit any changes because of stage failure."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A Databricks job has been configured with 3 tasks, each of\n- Tested mechanism/concept: Databricks Jobs scheduling/execution model (task types, parameters, retries).\n- Why D is correct: Tasks B and C will be skipped; some logic expressed in task A may have been committed before task failure. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Because all tasks are managed as a dependency graph, no changes will be committed to the Lakehouse until all tasks have successfully been completed. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with 3 tasks, each of) as stated.\n- B: Tasks B and C will attempt to run as configured; any changes made in task A will be rolled back due to task failure. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with 3 tasks, each of) as stated.\n- C: Unless all tasks complete successfully, no changes will be committed to the Lakehouse; because task A failed, all commits will be rolled back automatically. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with 3 tasks, each of) as stated.\n- E: Tasks B and C will be skipped; task A will not commit any changes because of stage failure. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with 3 tasks, each of) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q089.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 90,
    "question": "Which statement regarding Spark configuration on the Databricks platform is true?",
    "choices": [
      {
        "id": "A",
        "text": "The Databricks REST API can be used to modify the Spark configuration properties for an interactive cluster without interrupting jobs currently running on the cluster."
      },
      {
        "id": "B",
        "text": "Spark configurations set within a notebook will affect all SparkSessions attached to the same interactive cluster."
      },
      {
        "id": "C",
        "text": "Spark configuration properties can only be set for an interactive cluster by creating a global init script."
      },
      {
        "id": "D",
        "text": "Spark configuration properties set for an interactive cluster with the Clusters UI will impact all notebooks attached to that cluster."
      },
      {
        "id": "E",
        "text": "When the same Spark configuration property is set for an interactive cluster and a notebook attached to that cluster, the notebook setting will always be ignored."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: Spark configuration properties set for an interactive cluster with the Clusters UI will impact all notebooks attached to that cluster. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The Databricks REST API can be used to modify the Spark configuration properties for an interactive cluster without interrupting jobs currently running on the cluster. is wrong because it does not satisfy the requirement in the question () as stated.\n- B: Spark configurations set within a notebook will affect all SparkSessions attached to the same interactive cluster. is wrong because it does not satisfy the requirement in the question () as stated.\n- C: Spark configuration properties can only be set for an interactive cluster by creating a global init script. is wrong because it does not satisfy the requirement in the question () as stated.\n- E: When the same Spark configuration property is set for an interactive cluster and a notebook attached to that cluster, the notebook setting will always be ignored. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q090.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 91,
    "question": "A developer has successfully configured their credentials for Databricks Repos and cloned a remote Git repository. They do not have privileges to make changes to the main branch, which is the only branch currently visible in their workspace. Which approach allows this user to share their code updates without the risk of overwriting the work of their teammates?",
    "choices": [
      {
        "id": "A",
        "text": "Use Repos to checkout all changes and send the git diff log to the team."
      },
      {
        "id": "B",
        "text": "Use Repos to create a fork of the remote repository, commit all changes, and make a pull request on the source repository."
      },
      {
        "id": "C",
        "text": "Use Repos to pull changes from the remote Git repository; commit and push changes to a branch that appeared as changes were pulled."
      },
      {
        "id": "D",
        "text": "Use Repos to merge all differences and make a pull request back to the remote repository."
      },
      {
        "id": "E",
        "text": "Use Repos to create a new branch, commit all changes, and push changes to the remote Git repository."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: A developer has successfully configured their credentials for Databricks Repos and cloned a remote Git repository. They do not have privileges to make changes to the main branch,\n- Tested mechanism/concept: Databricks Repos (Git integration, branch/commit/pull).\n- Why E is correct: Use Repos to create a new branch, commit all changes, and push changes to the remote Git repository. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Use Repos to checkout all changes and send the git diff log to the team. is wrong because it does not satisfy the requirement in the question (A developer has successfully configured their credentials for Databricks Repos and cloned a remote Git repository. They do not have privileges to make changes to the main branch,) as stated.\n- B: Use Repos to create a fork of the remote repository, commit all changes, and make a pull request on the source repository. is wrong because it does not satisfy the requirement in the question (A developer has successfully configured their credentials for Databricks Repos and cloned a remote Git repository. They do not have privileges to make changes to the main branch,) as stated.\n- C: Use Repos to pull changes from the remote Git repository; commit and push changes to a branch that appeared as changes were pulled. is wrong because it does not satisfy the requirement in the question (A developer has successfully configured their credentials for Databricks Repos and cloned a remote Git repository. They do not have privileges to make changes to the main branch,) as stated.\n- D: Use Repos to merge all differences and make a pull request back to the remote repository. is wrong because it does not satisfy the requirement in the question (A developer has successfully configured their credentials for Databricks Repos and cloned a remote Git repository. They do not have privileges to make changes to the main branch,) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q091.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 92,
    "question": "In order to prevent accidental commits to production data, a senior data engineer has instituted a policy that all development work will reference clones of Delta Lake tables. After testing both DEEP and SHALLOW CLONE, development tables are created using SHALLOW CLONE. A few weeks after initial table creation, the cloned versions of several tables implemented as Type 1 Slowly Changing Dimension (SCD) stop working. The transaction logs for the source tables show that VACUUM was run the day before. Which statement describes why the cloned tables are no longer working?",
    "choices": [
      {
        "id": "A",
        "text": "Because Type 1 changes overwrite existing records, Delta Lake cannot guarantee data consistency for cloned tables."
      },
      {
        "id": "B",
        "text": "Running VACUUM automatically invalidates any shallow clones of a table; DEEP CLONE should always be used when a cloned table will be repeatedly queried."
      },
      {
        "id": "C",
        "text": "Tables created with SHALLOW CLONE are automatically deleted after their default retention threshold of 7 days."
      },
      {
        "id": "D",
        "text": "The metadata created by the CLONE operation is referencing data files that were purged as invalid by the VACUUM command."
      },
      {
        "id": "E",
        "text": "The data files compacted by VACUUM are not tracked by the cloned metadata; running REFRESH on the cloned table will pull in recent changes."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: In order to prevent accidental commits to production data, a senior data engineer has instituted a policy that all development work will reference clones of Delta Lake tables. A...\n- Tested mechanism/concept: Delta Lake maintenance operations (OPTIMIZE/Z-ORDER/VACUUM) and file layout.\n- Why B is correct: Running VACUUM automatically invalidates any shallow clones of a table; DEEP CLONE should always be used when a cloned table will be repeatedly queried. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Because Type 1 changes overwrite existing records, Delta Lake cannot guarantee data consistency for cloned tables. is wrong because it does not satisfy the requirement in the question (In order to prevent accidental commits to production data, a senior data engineer has instituted a policy that all development work will reference clones of Delta Lake tables. A...) as stated.\n- C: Tables created with SHALLOW CLONE are automatically deleted after their default retention threshold of 7 days. is wrong because it does not satisfy the requirement in the question (In order to prevent accidental commits to production data, a senior data engineer has instituted a policy that all development work will reference clones of Delta Lake tables. A...) as stated.\n- D: The metadata created by the CLONE operation is referencing data files that were purged as invalid by the VACUUM command. is wrong because it does not satisfy the requirement in the question (In order to prevent accidental commits to production data, a senior data engineer has instituted a policy that all development work will reference clones of Delta Lake tables. A...) as stated.\n- E: The data files compacted by VACUUM are not tracked by the cloned metadata; running REFRESH on the cloned table will pull in recent changes. is wrong because it does not satisfy the requirement in the question (In order to prevent accidental commits to production data, a senior data engineer has instituted a policy that all development work will reference clones of Delta Lake tables. A...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q092.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 93,
    "question": "You are performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF. Which code block attempts to perform an invalid stream-static join?",
    "choices": [
      {
        "id": "A",
        "text": "userLookup.join(streamingDF, [\"userid\"], how=\"inner\")"
      },
      {
        "id": "B",
        "text": "streamingDF.join(userLookup, [\"user_id\"], how=\"outer\")"
      },
      {
        "id": "C",
        "text": "streamingDF.join(userLookup, [\"user_id”], how=\"left\")"
      },
      {
        "id": "D",
        "text": "streamingDF.join(userLookup, [\"userid\"], how=\"inner\")"
      },
      {
        "id": "E",
        "text": "userLookup.join(streamingDF, [\"user_id\"], how=\"right\")"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: You are performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why B is correct: streamingDF.join(userLookup, [\"user_id\"], how=\"outer\") directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: userLookup.join(streamingDF, [\"userid\"], how=\"inner\") is wrong because it does not satisfy the requirement in the question (You are performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.) as stated.\n- C: streamingDF.join(userLookup, [\"user_id”], how=\"left\") is wrong because it does not satisfy the requirement in the question (You are performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.) as stated.\n- D: streamingDF.join(userLookup, [\"userid\"], how=\"inner\") is wrong because it does not satisfy the requirement in the question (You are performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.) as stated.\n- E: userLookup.join(streamingDF, [\"user_id\"], how=\"right\") is wrong because it does not satisfy the requirement in the question (You are performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q093.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 94,
    "question": "Spill occurs as a result of executing various wide transformations. However, diagnosing spill requires one to proactively look for key indicators. Where in the Spark UI are two of the primary indicators that a partition is spilling to disk?",
    "choices": [
      {
        "id": "A",
        "text": "Query’s detail screen and Job’s detail screen"
      },
      {
        "id": "B",
        "text": "Stage’s detail screen and Executor’s log files"
      },
      {
        "id": "C",
        "text": "Driver’s and Executor’s log files"
      },
      {
        "id": "D",
        "text": "Executor’s detail screen and Executor’s log files"
      },
      {
        "id": "E",
        "text": "Stage’s detail screen and Query’s detail screen"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Spill occurs as a result of executing various wide transformations. However, diagnosing spill requires one to proactively look for key indicators.\n- Tested mechanism/concept: Spark UI tabs (SQL/Jobs/Stages/Storage) for performance diagnosis.\n- Why B is correct: Stage’s detail screen and Executor’s log files directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Query’s detail screen and Job’s detail screen is wrong because it does not satisfy the requirement in the question (Spill occurs as a result of executing various wide transformations. However, diagnosing spill requires one to proactively look for key indicators.) as stated.\n- C: Driver’s and Executor’s log files is wrong because the question asks where in the Spark UI to diagnose this; grepping executor logs is not the Spark UI diagnostic path.\n- D: Executor’s detail screen and Executor’s log files is wrong because the question asks where in the Spark UI to diagnose this; grepping executor logs is not the Spark UI diagnostic path.\n- E: Stage’s detail screen and Query’s detail screen is wrong because it does not satisfy the requirement in the question (Spill occurs as a result of executing various wide transformations. However, diagnosing spill requires one to proactively look for key indicators.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q094.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 95,
    "question": "A task orchestrator has been configured to run two hourly tasks. First, an outside system writes Parquet data to a directory mounted at /mnt/raw_orders/. After this data is written, a Databricks job containing the following code is executed: Assume that the fields customer_id and order_id serve as a composite key to uniquely identify each order, and that the time field indicates when the record was queued in the source system. If the upstream system is known to occasionally enqueue duplicate entries for a single order hours apart, which statement is correct?",
    "choices": [
      {
        "id": "A",
        "text": "Duplicate records enqueued more than 2 hours apart may be retained and the orders table may contain duplicate records with the same customer_id and order_id."
      },
      {
        "id": "B",
        "text": "All records will be held in the state store for 2 hours before being deduplicated and committed to the orders table."
      },
      {
        "id": "C",
        "text": "The orders table will contain only the most recent 2 hours of records and no duplicates will be present."
      },
      {
        "id": "D",
        "text": "Duplicate records arriving more than 2 hours apart will be dropped, but duplicates that arrive in the same batch may both be written to the orders table."
      },
      {
        "id": "E",
        "text": "The orders table will not contain duplicates, but records arriving more than 2 hours late will be ignored and missing from the table."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A task orchestrator has been configured to run two hourly tasks. First, an outside system writes Parquet data to a directory mounted at /mnt/raw_orders/. After this data is writ...\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why A is correct: Duplicate records enqueued more than 2 hours apart may be retained and the orders table may contain duplicate records with the same customer_id and order_id. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: All records will be held in the state store for 2 hours before being deduplicated and committed to the orders table. is wrong because it does not satisfy the requirement in the question (A task orchestrator has been configured to run two hourly tasks. First, an outside system writes Parquet data to a directory mounted at /mnt/raw_orders/. After this data is writ...) as stated.\n- C: The orders table will contain only the most recent 2 hours of records and no duplicates will be present. is wrong because it does not satisfy the requirement in the question (A task orchestrator has been configured to run two hourly tasks. First, an outside system writes Parquet data to a directory mounted at /mnt/raw_orders/. After this data is writ...) as stated.\n- D: Duplicate records arriving more than 2 hours apart will be dropped, but duplicates that arrive in the same batch may both be written to the orders table. is wrong because it does not satisfy the requirement in the question (A task orchestrator has been configured to run two hourly tasks. First, an outside system writes Parquet data to a directory mounted at /mnt/raw_orders/. After this data is writ...) as stated.\n- E: The orders table will not contain duplicates, but records arriving more than 2 hours late will be ignored and missing from the table. is wrong because it does not satisfy the requirement in the question (A task orchestrator has been configured to run two hourly tasks. First, an outside system writes Parquet data to a directory mounted at /mnt/raw_orders/. After this data is writ...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q095.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 96,
    "question": "A junior data engineer is migrating a workload from a relational database system to the Databricks Lakehouse. The source system uses a star schema, leveraging foreign key constraints and multi-table inserts to validate records on write. Which consideration will impact the decisions made by the engineer while migrating this workload?",
    "choices": [
      {
        "id": "A",
        "text": "Databricks only allows foreign key constraints on hashed identifiers, which avoid collisions in highly-parallel writes."
      },
      {
        "id": "B",
        "text": "Databricks supports Spark SQL and JDBC; all logic can be directly migrated from the source system without refactoring."
      },
      {
        "id": "C",
        "text": "Committing to multiple tables simultaneously requires taking out multiple table locks and can lead to a state of deadlock."
      },
      {
        "id": "D",
        "text": "All Delta Lake transactions are ACID compliant against a single table, and Databricks does not enforce foreign key constraints."
      },
      {
        "id": "E",
        "text": "Foreign keys must reference a primary key field; multi-table inserts must leverage Delta Lake’s upsert functionality."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A junior data engineer is migrating a workload from a relational database system to the Databricks Lakehouse. The source system uses a star schema, leveraging foreign key constr...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: All Delta Lake transactions are ACID compliant against a single table, and Databricks does not enforce foreign key constraints. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Databricks only allows foreign key constraints on hashed identifiers, which avoid collisions in highly-parallel writes. is wrong because it does not satisfy the requirement in the question (A junior data engineer is migrating a workload from a relational database system to the Databricks Lakehouse. The source system uses a star schema, leveraging foreign key constr...) as stated.\n- B: Databricks supports Spark SQL and JDBC; all logic can be directly migrated from the source system without refactoring. is wrong because it does not satisfy the requirement in the question (A junior data engineer is migrating a workload from a relational database system to the Databricks Lakehouse. The source system uses a star schema, leveraging foreign key constr...) as stated.\n- C: Committing to multiple tables simultaneously requires taking out multiple table locks and can lead to a state of deadlock. is wrong because it does not satisfy the requirement in the question (A junior data engineer is migrating a workload from a relational database system to the Databricks Lakehouse. The source system uses a star schema, leveraging foreign key constr...) as stated.\n- E: Foreign keys must reference a primary key field; multi-table inserts must leverage Delta Lake’s upsert functionality. is wrong because it does not satisfy the requirement in the question (A junior data engineer is migrating a workload from a relational database system to the Databricks Lakehouse. The source system uses a star schema, leveraging foreign key constr...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q096.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 97,
    "question": "A data architect has heard about Delta Lake’s built-in versioning and time travel capabilities. For auditing purposes, they have a requirement to maintain a full record of all valid street addresses as they appear in the customers table. The architect is interested in implementing a Type 1 table, overwriting existing records with new values and relying on Delta Lake time travel to support long-term auditing. A data engineer on the project feels that a Type 2 table will provide better performance and scalability. Which piece of information is critical to this decision?",
    "choices": [
      {
        "id": "A",
        "text": "Data corruption can occur if a query fails in a partially completed state because Type 2 tables require setting multiple fields in a single update."
      },
      {
        "id": "B",
        "text": "Shallow clones can be combined with Type 1 tables to accelerate historic queries for long-term versioning."
      },
      {
        "id": "C",
        "text": "Delta Lake time travel cannot be used to query previous versions of these tables because Type 1 changes modify data files in place."
      },
      {
        "id": "D",
        "text": "Delta Lake time travel does not scale well in cost or latency to provide a long-term versioning solution."
      },
      {
        "id": "E",
        "text": "Delta Lake only supports Type 0 tables; once records are inserted to a Delta Lake table, they cannot be modified."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A data architect has heard about Delta Lake’s built-in versioning and time travel capabilities. For auditing purposes, they have a requirement to maintain a full record of all v...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: Delta Lake time travel does not scale well in cost or latency to provide a long-term versioning solution. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Data corruption can occur if a query fails in a partially completed state because Type 2 tables require setting multiple fields in a single update. is wrong because it does not satisfy the requirement in the question (A data architect has heard about Delta Lake’s built-in versioning and time travel capabilities. For auditing purposes, they have a requirement to maintain a full record of all v...) as stated.\n- B: Shallow clones can be combined with Type 1 tables to accelerate historic queries for long-term versioning. is wrong because it does not satisfy the requirement in the question (A data architect has heard about Delta Lake’s built-in versioning and time travel capabilities. For auditing purposes, they have a requirement to maintain a full record of all v...) as stated.\n- C: Delta Lake time travel cannot be used to query previous versions of these tables because Type 1 changes modify data files in place. is wrong because Parquet files are immutable; schema changes require writing new files/metadata rather than editing footers in place.\n- E: Delta Lake only supports Type 0 tables; once records are inserted to a Delta Lake table, they cannot be modified. is wrong because it does not satisfy the requirement in the question (A data architect has heard about Delta Lake’s built-in versioning and time travel capabilities. For auditing purposes, they have a requirement to maintain a full record of all v...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q097.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 98,
    "question": "A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups, which are used for setting up data access using ACLs. The user_ltv table has the following schema: email STRING, age INT, ltv INT The following view definition is executed:   An analyst who is not a member of the auditing group executes the following query: SELECT * FROM user_ltv_no_minors Which statement describes the results returned by this query?",
    "choices": [
      {
        "id": "A",
        "text": "All columns will be displayed normally for those records that have an age greater than 17; records not meeting this condition will be omitted."
      },
      {
        "id": "B",
        "text": "All age values less than 18 will be returned as null values, all other columns will be returned with the values in user_ltv."
      },
      {
        "id": "C",
        "text": "All values for the age column will be returned as null values, all other columns will be returned with the values in user_ltv."
      },
      {
        "id": "D",
        "text": "All records from all columns will be displayed with the values in user_ltv."
      },
      {
        "id": "E",
        "text": "All columns will be displayed normally for those records that have an age greater than 18; records not meeting this condition will be omitted."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: All columns will be displayed normally for those records that have an age greater than 17; records not meeting this condition will be omitted. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: All age values less than 18 will be returned as null values, all other columns will be returned with the values in user_ltv. is wrong because it does not satisfy the requirement in the question (A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,) as stated.\n- C: All values for the age column will be returned as null values, all other columns will be returned with the values in user_ltv. is wrong because it does not satisfy the requirement in the question (A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,) as stated.\n- D: All records from all columns will be displayed with the values in user_ltv. is wrong because it does not satisfy the requirement in the question (A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,) as stated.\n- E: All columns will be displayed normally for those records that have an age greater than 18; records not meeting this condition will be omitted. is wrong because it does not satisfy the requirement in the question (A table named user_ltv is being used to create a view that will be used by data analysts on various teams. Users in the workspace are configured into groups,) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q098.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 99,
    "question": "The data governance team is reviewing code used for deleting records for compliance with GDPR. The following logic has been implemented to propagate delete requests from the user_lookup table to the user_aggregates table.  Assuming that user_id is a unique identifying key and that all users that have requested deletion have been removed from the user_lookup table, which statement describes whether successfully executing the above logic guarantees that the records to be deleted from the user_aggregates table are no longer accessible and why?",
    "choices": [
      {
        "id": "A",
        "text": "No; the Delta Lake DELETE command only provides ACID guarantees when combined with the MERGE INTO command."
      },
      {
        "id": "B",
        "text": "No; files containing deleted records may still be accessible with time travel until a VACUUM command is used to remove invalidated data files."
      },
      {
        "id": "C",
        "text": "Yes; the change data feed uses foreign keys to ensure delete consistency throughout the Lakehouse."
      },
      {
        "id": "D",
        "text": "Yes; Delta Lake ACID guarantees provide assurance that the DELETE command succeeded fully and permanently purged these records."
      },
      {
        "id": "E",
        "text": "No; the change data feed only tracks inserts and updates, not deleted records."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The data governance team is reviewing code used for deleting records for compliance with GDPR. The following logic has been implemented to propagate delete requests from the use...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: No; files containing deleted records may still be accessible with time travel until a VACUUM command is used to remove invalidated data files. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: No; the Delta Lake DELETE command only provides ACID guarantees when combined with the MERGE INTO command. is wrong because it does not satisfy the requirement in the question (The data governance team is reviewing code used for deleting records for compliance with GDPR. The following logic has been implemented to propagate delete requests from the use...) as stated.\n- C: Yes; the change data feed uses foreign keys to ensure delete consistency throughout the Lakehouse. is wrong because it does not satisfy the requirement in the question (The data governance team is reviewing code used for deleting records for compliance with GDPR. The following logic has been implemented to propagate delete requests from the use...) as stated.\n- D: Yes; Delta Lake ACID guarantees provide assurance that the DELETE command succeeded fully and permanently purged these records. is wrong because it does not satisfy the requirement in the question (The data governance team is reviewing code used for deleting records for compliance with GDPR. The following logic has been implemented to propagate delete requests from the use...) as stated.\n- E: No; the change data feed only tracks inserts and updates, not deleted records. is wrong because it does not satisfy the requirement in the question (The data governance team is reviewing code used for deleting records for compliance with GDPR. The following logic has been implemented to propagate delete requests from the use...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q099.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 100,
    "question": "The data engineering team has been tasked with configuring connections to an external database that does not have a supported native connector with Databricks. The external database already has data security configured by group membership. These groups map directly to user groups already created in Databricks that represent various teams within the company. A new login credential has been created for each group in the external database. The Databricks Utilities Secrets module will be used to make these credentials available to Databricks users. Assuming that all the credentials are configured correctly on the external database and group membership is properly configured on Databricks, which statement describes how teams can be granted the minimum necessary access to using these credentials?",
    "choices": [
      {
        "id": "A",
        "text": "\"Manage\" permissions should be set on a secret key mapped to those credentials that will be used by a given team."
      },
      {
        "id": "B",
        "text": "\"Read\" permissions should be set on a secret key mapped to those credentials that will be used by a given team."
      },
      {
        "id": "C",
        "text": "\"Read\" permissions should be set on a secret scope containing only those credentials that will be used by a given team."
      },
      {
        "id": "D",
        "text": "\"Manage\" permissions should be set on a secret scope containing only those credentials that will be used by a given team. No additional configuration is necessary as long as all users are configured as administrators in the workspace where secrets have been added."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: The data engineering team has been tasked with configuring connections to an external database that does not have a supported native connector with Databricks. The external data...\n- Tested mechanism/concept: Databricks secrets (scopes, ACLs) and safe credential handling.\n- Why C is correct: \"Read\" permissions should be set on a secret scope containing only those credentials that will be used by a given team. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: \"Manage\" permissions should be set on a secret key mapped to those credentials that will be used by a given team. is wrong because it does not satisfy the requirement in the question (The data engineering team has been tasked with configuring connections to an external database that does not have a supported native connector with Databricks. The external data...) as stated.\n- B: \"Read\" permissions should be set on a secret key mapped to those credentials that will be used by a given team. is wrong because it does not satisfy the requirement in the question (The data engineering team has been tasked with configuring connections to an external database that does not have a supported native connector with Databricks. The external data...) as stated.\n- D: \"Manage\" permissions should be set on a secret scope containing only those credentials that will be used by a given team. No additional configuration is necessary as long as all users are configured as administrators in the workspace where secrets have been added. is wrong because it does not satisfy the requirement in the question (The data engineering team has been tasked with configuring connections to an external database that does not have a supported native connector with Databricks. The external data...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q100.webp"
    ],
    "docs": [
      {
        "title": "Databricks secrets (dbutils.secrets) and redaction",
        "query": "Databricks secrets redacted output"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 101,
    "question": "Which indicators would you look for in the Spark UI’s Storage tab to signal that a cached table is not performing optimally? Assume you are using Spark’s MEMORY_ONLY storage level.",
    "choices": [
      {
        "id": "A",
        "text": "Size on Disk is < Size in Memory"
      },
      {
        "id": "B",
        "text": "The RDD Block Name includes the “*” annotation signaling a failure to cache"
      },
      {
        "id": "C",
        "text": "Size on Disk is > 0"
      },
      {
        "id": "D",
        "text": "The number of Cached Partitions > the number of Spark Partitions"
      },
      {
        "id": "E",
        "text": "On Heap Memory Usage is within 75% of Off Heap Memory Usage"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: Spark UI tabs (SQL/Jobs/Stages/Storage) for performance diagnosis.\n- Why C is correct: Size on Disk is > 0 directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Size on Disk is < Size in Memory is wrong because it does not satisfy the requirement in the question () as stated.\n- B: The RDD Block Name includes the “*” annotation signaling a failure to cache is wrong because it does not satisfy the requirement in the question () as stated.\n- D: The number of Cached Partitions > the number of Spark Partitions is wrong because it does not satisfy the requirement in the question () as stated.\n- E: On Heap Memory Usage is within 75% of Off Heap Memory Usage is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q101.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 102,
    "question": "What is the first line of a Databricks Python notebook when viewed in a text editor?",
    "choices": [
      {
        "id": "A",
        "text": "%python"
      },
      {
        "id": "B",
        "text": "// Databricks notebook source"
      },
      {
        "id": "C",
        "text": "# Databricks notebook source"
      },
      {
        "id": "D",
        "text": "-- Databricks notebook source"
      },
      {
        "id": "E",
        "text": "# MAGIC %python"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: # Databricks notebook source directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: %python is wrong because it does not satisfy the requirement in the question () as stated.\n- B: // Databricks notebook source is wrong because it does not satisfy the requirement in the question () as stated.\n- D: -- Databricks notebook source is wrong because it does not satisfy the requirement in the question () as stated.\n- E: # MAGIC %python is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q102.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 103,
    "question": "Which statement describes a key benefit of an end-to-end test?",
    "choices": [
      {
        "id": "A",
        "text": "Makes it easier to automate your test suite"
      },
      {
        "id": "B",
        "text": "Pinpoints errors in the building blocks of your application"
      },
      {
        "id": "C",
        "text": "Provides testing coverage for all code paths and branches"
      },
      {
        "id": "D",
        "text": "Closely simulates real world usage of your application"
      },
      {
        "id": "E",
        "text": "Ensures code is optimized for a real-life workflow"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: Closely simulates real world usage of your application directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Makes it easier to automate your test suite is wrong because it does not satisfy the requirement in the question () as stated.\n- B: Pinpoints errors in the building blocks of your application is wrong because it does not satisfy the requirement in the question () as stated.\n- C: Provides testing coverage for all code paths and branches is wrong because it does not satisfy the requirement in the question () as stated.\n- E: Ensures code is optimized for a real-life workflow is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 104,
    "question": "The Databricks CLI is used to trigger a run of an existing job by passing the job_id parameter. The response that the job run request has been submitted successfully includes a field run_id. Which statement describes what the number alongside this field represents?",
    "choices": [
      {
        "id": "A",
        "text": "The job_id and number of times the job has been run are concatenated and returned."
      },
      {
        "id": "B",
        "text": "The total number of jobs that have been run in the workspace."
      },
      {
        "id": "C",
        "text": "The number of times the job definition has been run in this workspace."
      },
      {
        "id": "D",
        "text": "The job_id is returned in this field."
      },
      {
        "id": "E",
        "text": "The globally unique ID of the newly triggered run."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: The Databricks CLI is used to trigger a run of an existing job by passing the job_id parameter. The response that the job run request has been submitted successfully includes a...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why E is correct: The globally unique ID of the newly triggered run. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The job_id and number of times the job has been run are concatenated and returned. is wrong because it does not satisfy the requirement in the question (The Databricks CLI is used to trigger a run of an existing job by passing the job_id parameter. The response that the job run request has been submitted successfully includes a...) as stated.\n- B: The total number of jobs that have been run in the workspace. is wrong because it does not satisfy the requirement in the question (The Databricks CLI is used to trigger a run of an existing job by passing the job_id parameter. The response that the job run request has been submitted successfully includes a...) as stated.\n- C: The number of times the job definition has been run in this workspace. is wrong because it does not satisfy the requirement in the question (The Databricks CLI is used to trigger a run of an existing job by passing the job_id parameter. The response that the job run request has been submitted successfully includes a...) as stated.\n- D: The job_id is returned in this field. is wrong because it does not satisfy the requirement in the question (The Databricks CLI is used to trigger a run of an existing job by passing the job_id parameter. The response that the job run request has been submitted successfully includes a...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q104.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 105,
    "question": "The data science team has created and logged a production model using MLflow. The model accepts a list of column names and returns a new column of type DOUBLE. The following code correctly imports the production model, loads the customers table containing the customer_id key column into a DataFrame, and defines the feature columns needed for the model. Which code block will output a DataFrame with the schema \"customer_id LONG, predictions DOUBLE\"?",
    "choices": [
      {
        "id": "A",
        "text": "df.map(lambda x:model(x[columns])).select(\"customer_id, predictions\")"
      },
      {
        "id": "B",
        "text": "df.select(\"customer_id\", model(*columns).alias(\"predictions\"))"
      },
      {
        "id": "C",
        "text": "model.predict(df, columns)"
      },
      {
        "id": "D",
        "text": "df.select(\"customer_id\", pandas_udf(model, columns).alias(\"predictions\"))"
      },
      {
        "id": "E",
        "text": "df.apply(model, columns).select(\"customer_id, predictions\")"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The data science team has created and logged a production model using MLflow. The model accepts a list of column names and returns a new column of type DOUBLE. The following cod...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: df.select(\"customer_id\", model(*columns).alias(\"predictions\")) directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: df.map(lambda x:model(x[columns])).select(\"customer_id, predictions\") is wrong because it does not satisfy the requirement in the question (The data science team has created and logged a production model using MLflow. The model accepts a list of column names and returns a new column of type DOUBLE. The following cod...) as stated.\n- C: model.predict(df, columns) is wrong because it does not satisfy the requirement in the question (The data science team has created and logged a production model using MLflow. The model accepts a list of column names and returns a new column of type DOUBLE. The following cod...) as stated.\n- D: df.select(\"customer_id\", pandas_udf(model, columns).alias(\"predictions\")) is wrong because it does not satisfy the requirement in the question (The data science team has created and logged a production model using MLflow. The model accepts a list of column names and returns a new column of type DOUBLE. The following cod...) as stated.\n- E: df.apply(model, columns).select(\"customer_id, predictions\") is wrong because it does not satisfy the requirement in the question (The data science team has created and logged a production model using MLflow. The model accepts a list of column names and returns a new column of type DOUBLE. The following cod...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q105.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 106,
    "question": "A nightly batch job is configured to ingest all data files from a cloud object storage container where records are stored in a nested directory structure YYYY/MM/DD. The data for each date represents all records that were processed by the source system on that date, noting that some records may be delayed as they await moderator approval. Each entry represents a user review of a product and has the following schema: user_id STRING, review_id BIGINT, product_id BIGINT, review_timestamp TIMESTAMP, review_text STRING The ingestion job is configured to append all data for the previous date to a target table reviews_raw with an identical schema to the source system. The next step in the pipeline is a batch write to propagate all new records    inserted into reviews_raw to a table where data is fully deduplicated, validated, and enriched. Which solution minimizes the compute costs to propagate this batch of data?",
    "choices": [
      {
        "id": "A",
        "text": "Perform a batch read on the reviews_raw table and perform an insert-only merge using the natural composite key user_id, review_id, product_id, review_timestamp."
      },
      {
        "id": "B",
        "text": "Configure a Structured Streaming read against the reviews_raw table using the trigger once execution mode to process new records as a batch job."
      },
      {
        "id": "C",
        "text": "Use Delta Lake version history to get the difference between the latest version of reviews_raw and one version prior, then write these records to the next table."
      },
      {
        "id": "D",
        "text": "Filter all records in the reviews_raw table based on the review_timestamp; batch append those records produced in the last 48 hours."
      },
      {
        "id": "E",
        "text": "Reprocess all records in reviews_raw and overwrite the next table in the pipeline."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: A nightly batch job is configured to ingest all data files from a cloud object storage container\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: Configure a Structured Streaming read against the reviews_raw table using the trigger once execution mode to process new records as a batch job. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Perform a batch read on the reviews_raw table and perform an insert-only merge using the natural composite key user_id, review_id, product_id, review_timestamp. is wrong because it does not satisfy the requirement in the question (A nightly batch job is configured to ingest all data files from a cloud object storage container) as stated.\n- C: Use Delta Lake version history to get the difference between the latest version of reviews_raw and one version prior, then write these records to the next table. is wrong because it does not satisfy the requirement in the question (A nightly batch job is configured to ingest all data files from a cloud object storage container) as stated.\n- D: Filter all records in the reviews_raw table based on the review_timestamp; batch append those records produced in the last 48 hours. is wrong because it does not satisfy the requirement in the question (A nightly batch job is configured to ingest all data files from a cloud object storage container) as stated.\n- E: Reprocess all records in reviews_raw and overwrite the next table in the pipeline. is wrong because it does not satisfy the requirement in the question (A nightly batch job is configured to ingest all data files from a cloud object storage container) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q106.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 107,
    "question": "Which statement describes Delta Lake optimized writes?",
    "choices": [
      {
        "id": "A",
        "text": "Before a Jobs cluster terminates, OPTIMIZE is executed on all tables modified during the most recent job."
      },
      {
        "id": "B",
        "text": "An asynchronous job runs after the write completes to detect if files could be further compacted; if yes, an OPTIMIZE job is executed toward a default of 1 GB."
      },
      {
        "id": "C",
        "text": "Data is queued in a messaging bus instead of committing data directly to memory; all data is committed from the messaging bus in one batch once the job is complete."
      },
      {
        "id": "D",
        "text": "Optimized writes use logical partitions instead of directory partitions; because partition boundaries are only represented in metadata, fewer small files are written."
      },
      {
        "id": "E",
        "text": "A shuffle occurs prior to writing to try to group similar data together resulting in fewer files instead of each executor writing multiple files based on directory partitions."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: Delta Lake maintenance operations (OPTIMIZE/Z-ORDER/VACUUM) and file layout.\n- Why E is correct: A shuffle occurs prior to writing to try to group similar data together resulting in fewer files instead of each executor writing multiple files based on directory partitions. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Before a Jobs cluster terminates, OPTIMIZE is executed on all tables modified during the most recent job. is wrong because it does not satisfy the requirement in the question () as stated.\n- B: An asynchronous job runs after the write completes to detect if files could be further compacted; if yes, an OPTIMIZE job is executed toward a default of 1 GB. is wrong because it does not satisfy the requirement in the question () as stated.\n- C: Data is queued in a messaging bus instead of committing data directly to memory; all data is committed from the messaging bus in one batch once the job is complete. is wrong because it does not satisfy the requirement in the question () as stated.\n- D: Optimized writes use logical partitions instead of directory partitions; because partition boundaries are only represented in metadata, fewer small files are written. is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q107.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 108,
    "question": "Which statement describes the default execution mode for Databricks Auto Loader?",
    "choices": [
      {
        "id": "A",
        "text": "Cloud vendor-specific queue storage and notification services are configured to track newly arriving files; the target table is materialized by directly querying all valid files in the source directory."
      },
      {
        "id": "B",
        "text": "New files are identified by listing the input directory; the target table is materialized by directly querying all valid files in the source directory."
      },
      {
        "id": "C",
        "text": "Webhooks trigger a Databricks job to run anytime new data arrives in a source directory; new data are automatically merged into target tables using rules inferred from the data."
      },
      {
        "id": "D",
        "text": "New files are identified by listing the input directory; new files are incrementally and idempotently loaded into the target Delta Lake table."
      },
      {
        "id": "E",
        "text": "Cloud vendor-specific queue storage and notification services are configured to track newly arriving files; new files are incrementally and idempotently loaded into the target Delta Lake table."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why E is correct: Cloud vendor-specific queue storage and notification services are configured to track newly arriving files; new files are incrementally and idempotently loaded into the target Delta Lake table. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Cloud vendor-specific queue storage and notification services are configured to track newly arriving files; the target table is materialized by directly querying all valid files in the source directory. is wrong because it does not satisfy the requirement in the question () as stated.\n- B: New files are identified by listing the input directory; the target table is materialized by directly querying all valid files in the source directory. is wrong because it does not satisfy the requirement in the question () as stated.\n- C: Webhooks trigger a Databricks job to run anytime new data arrives in a source directory; new data are automatically merged into target tables using rules inferred from the data. is wrong because it does not satisfy the requirement in the question () as stated.\n- D: New files are identified by listing the input directory; new files are incrementally and idempotently loaded into the target Delta Lake table. is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q108.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 109,
    "question": "A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT, post_time TIMESTAMP, date DATE Based on the above schema, which column is a good candidate for partitioning the Delta Table?",
    "choices": [
      {
        "id": "A",
        "text": "post_time"
      },
      {
        "id": "B",
        "text": "latitude"
      },
      {
        "id": "C",
        "text": "post_id"
      },
      {
        "id": "D",
        "text": "user_id"
      },
      {
        "id": "E",
        "text": "date"
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...\n- Tested mechanism/concept: Databricks Repos (Git integration, branch/commit/pull).\n- Why E is correct: date directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: post_time is wrong because it does not satisfy the requirement in the question (A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...) as stated.\n- B: latitude is wrong because it does not satisfy the requirement in the question (A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...) as stated.\n- C: post_id is wrong because it does not satisfy the requirement in the question (A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...) as stated.\n- D: user_id is wrong because it does not satisfy the requirement in the question (A Delta Lake table representing metadata about content posts from users has the following schema: user_id LONG, post_text STRING, post_id STRING, longitude FLOAT, latitude FLOAT...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q109.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 110,
    "question": "A large company seeks to implement a near real-time solution involving hundreds of pipelines with parallel updates of many tables with extremely high volume and high velocity data. Which of the following solutions would you implement to achieve this requirement?",
    "choices": [
      {
        "id": "A",
        "text": "Use Databricks High Concurrency clusters, which leverage optimized cloud storage connections to maximize data throughput."
      },
      {
        "id": "B",
        "text": "Partition ingestion tables by a small time duration to allow for many data files to be written in parallel."
      },
      {
        "id": "C",
        "text": "Configure Databricks to save all data to attached SSD volumes instead of object storage, increasing file I/O significantly."
      },
      {
        "id": "D",
        "text": "Isolate Delta Lake tables in their own storage containers to avoid API limits imposed by cloud vendors."
      },
      {
        "id": "E",
        "text": "Store all tables in a single database to ensure that the Databricks Catalyst Metastore can load balance overall throughput."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A large company seeks to implement a near real-time solution involving hundreds of pipelines with parallel updates of many tables with extremely high volume and high velocity data.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why A is correct: Use Databricks High Concurrency clusters, which leverage optimized cloud storage connections to maximize data throughput. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Partition ingestion tables by a small time duration to allow for many data files to be written in parallel. is wrong because it does not satisfy the requirement in the question (A large company seeks to implement a near real-time solution involving hundreds of pipelines with parallel updates of many tables with extremely high volume and high velocity data.) as stated.\n- C: Configure Databricks to save all data to attached SSD volumes instead of object storage, increasing file I/O significantly. is wrong because it does not satisfy the requirement in the question (A large company seeks to implement a near real-time solution involving hundreds of pipelines with parallel updates of many tables with extremely high volume and high velocity data.) as stated.\n- D: Isolate Delta Lake tables in their own storage containers to avoid API limits imposed by cloud vendors. is wrong because it does not satisfy the requirement in the question (A large company seeks to implement a near real-time solution involving hundreds of pipelines with parallel updates of many tables with extremely high volume and high velocity data.) as stated.\n- E: Store all tables in a single database to ensure that the Databricks Catalyst Metastore can load balance overall throughput. is wrong because it does not satisfy the requirement in the question (A large company seeks to implement a near real-time solution involving hundreds of pipelines with parallel updates of many tables with extremely high volume and high velocity data.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q110.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 111,
    "question": "Which describes a method of installing a Python package scoped at the notebook level to all nodes in the currently active cluster?",
    "choices": [
      {
        "id": "A",
        "text": "Run source env/bin/activate in a notebook setup script"
      },
      {
        "id": "B",
        "text": "Use b in a notebook cell"
      },
      {
        "id": "C",
        "text": "Use %pip install in a notebook cell"
      },
      {
        "id": "D",
        "text": "Use %sh pip install in a notebook cell"
      },
      {
        "id": "E",
        "text": "Install libraries from PyPI using the cluster UI"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: Databricks compute configuration (clusters, jobs compute, pools).\n- Why C is correct: Use %pip install in a notebook cell directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Run source env/bin/activate in a notebook setup script is wrong because it does not satisfy the requirement in the question () as stated.\n- B: Use b in a notebook cell is wrong because it does not satisfy the requirement in the question () as stated.\n- D: Use %sh pip install in a notebook cell is wrong because it does not satisfy the requirement in the question () as stated.\n- E: Install libraries from PyPI using the cluster UI is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q111.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 112,
    "question": "Each configuration below is identical to the extent that each cluster has 400 GB total of RAM 160 total cores and only one Executor per VM.    Given an extremely long-running job for which completion must be guaranteed, which cluster configuration will be able to guarantee completion of the job in light of one or more VM failures?",
    "choices": [
      {
        "id": "A",
        "text": "• Total VMs: 8 • 50 GB per Executor • 20 Cores / Executor"
      },
      {
        "id": "B",
        "text": "• Total VMs: 16 • 25 GB per Executor • 10 Cores / Executor"
      },
      {
        "id": "C",
        "text": "• Total VMs: 1 • 400 GB per Executor • 160 Cores/Executor"
      },
      {
        "id": "D",
        "text": "• Total VMs: 4 • 100 GB per Executor • 40 Cores / Executor"
      },
      {
        "id": "E",
        "text": "• Total VMs: 2 • 200 GB per Executor • 80 Cores / Executor"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: Each configuration below is identical to the extent that each cluster has 400 GB total of RAM 160 total cores and only one Executor per VM. Given an extremely long-running job for\n- Tested mechanism/concept: Databricks compute configuration (clusters, jobs compute, pools).\n- Why B is correct: • Total VMs: 16 • 25 GB per Executor • 10 Cores / Executor directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: • Total VMs: 8 • 50 GB per Executor • 20 Cores / Executor is wrong because it does not satisfy the requirement in the question (Each configuration below is identical to the extent that each cluster has 400 GB total of RAM 160 total cores and only one Executor per VM. Given an extremely long-running job for) as stated.\n- C: • Total VMs: 1 • 400 GB per Executor • 160 Cores/Executor is wrong because it does not satisfy the requirement in the question (Each configuration below is identical to the extent that each cluster has 400 GB total of RAM 160 total cores and only one Executor per VM. Given an extremely long-running job for) as stated.\n- D: • Total VMs: 4 • 100 GB per Executor • 40 Cores / Executor is wrong because it does not satisfy the requirement in the question (Each configuration below is identical to the extent that each cluster has 400 GB total of RAM 160 total cores and only one Executor per VM. Given an extremely long-running job for) as stated.\n- E: • Total VMs: 2 • 200 GB per Executor • 80 Cores / Executor is wrong because it does not satisfy the requirement in the question (Each configuration below is identical to the extent that each cluster has 400 GB total of RAM 160 total cores and only one Executor per VM. Given an extremely long-running job for) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q112.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 113,
    "question": "A Delta Lake table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information about customers derived from a number of upstream sources. Currently, the data engineering team populates this table nightly by overwriting the table with the current valid values derived from upstream data sources. Immediately after each update succeeds, the data engineering team would like to determine the difference between the new version and the previous version of the table. Given the current implementation, which method can be used?",
    "choices": [
      {
        "id": "A",
        "text": "Execute a query to calculate the difference between the new version and the previous version using Delta Lake’s built-in versioning and lime travel functionality."
      },
      {
        "id": "B",
        "text": "Parse the Delta Lake transaction log to identify all newly written data files."
      },
      {
        "id": "C",
        "text": "Parse the Spark event logs to identify those rows that were updated, inserted, or deleted."
      },
      {
        "id": "D",
        "text": "Execute DESCRIBE HISTORY customer_churn_params to obtain the full operation metrics for the update, including a log of all records that have been added or modified."
      },
      {
        "id": "E",
        "text": "Use Delta Lake’s change data feed to identify those records that have been updated, inserted, or deleted."
      }
    ],
    "answer": "E",
    "explanation": "Why the correct answer is correct\n- Requirement: A Delta Lake table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information about customers derived...\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why E is correct: Use Delta Lake’s change data feed to identify those records that have been updated, inserted, or deleted. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Execute a query to calculate the difference between the new version and the previous version using Delta Lake’s built-in versioning and lime travel functionality. is wrong because it does not satisfy the requirement in the question (A Delta Lake table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information about customers derived...) as stated.\n- B: Parse the Delta Lake transaction log to identify all newly written data files. is wrong because it does not satisfy the requirement in the question (A Delta Lake table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information about customers derived...) as stated.\n- C: Parse the Spark event logs to identify those rows that were updated, inserted, or deleted. is wrong because it does not satisfy the requirement in the question (A Delta Lake table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information about customers derived...) as stated.\n- D: Execute DESCRIBE HISTORY customer_churn_params to obtain the full operation metrics for the update, including a log of all records that have been added or modified. is wrong because it does not satisfy the requirement in the question (A Delta Lake table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information about customers derived...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q113.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 114,
    "question": "A data team’s Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced a new promotion, and they would like to add a new field to track the number of times this promotion code is used for each item. A junior data engineer suggests updating the existing query as follows. Note that proposed changes are in bold. Original query:   Proposed query: Which step must also be completed to put the proposed query into production?",
    "choices": [
      {
        "id": "A",
        "text": "Specify a new checkpointLocation"
      },
      {
        "id": "B",
        "text": "Remove .option('mergeSchema', 'true') from the streaming write"
      },
      {
        "id": "C",
        "text": "Increase the shuffle partitions to account for additional aggregates"
      },
      {
        "id": "D",
        "text": "Run REFRESH TABLE delta.‛/item_agg‛"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A data team’s Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...\n- Tested mechanism/concept: Structured Streaming checkpoints & trigger semantics.\n- Why A is correct: Specify a new checkpointLocation directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Remove .option('mergeSchema', 'true') from the streaming write is wrong because it does not satisfy the requirement in the question (A data team’s Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...) as stated.\n- C: Increase the shuffle partitions to account for additional aggregates is wrong because it does not satisfy the requirement in the question (A data team’s Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...) as stated.\n- D: Run REFRESH TABLE delta.‛/item_agg‛ is wrong because it does not satisfy the requirement in the question (A data team’s Structured Streaming job is configured to calculate running aggregates for item sales to update a downstream marketing dashboard. The marketing team has introduced...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q114.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 115,
    "question": "When using CLI or REST API to get results from jobs with multiple tasks, which statement correctly describes the response structure?",
    "choices": [
      {
        "id": "A",
        "text": "Each run of a job will have a unique job_id; all tasks within this job will have a unique job_id"
      },
      {
        "id": "B",
        "text": "Each run of a job will have a unique job_id; all tasks within this job will have a unique task_id"
      },
      {
        "id": "C",
        "text": "Each run of a job will have a unique orchestration_id; all tasks within this job will have a unique run_id"
      },
      {
        "id": "D",
        "text": "Each run of a job will have a unique run_id; all tasks within this job will have a unique task_id"
      },
      {
        "id": "E",
        "text": "Each run of a job will have a unique run_id; all tasks within this job will also have a unique run_id"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: Each run of a job will have a unique run_id; all tasks within this job will have a unique task_id directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Each run of a job will have a unique job_id; all tasks within this job will have a unique job_id is wrong because it does not satisfy the requirement in the question () as stated.\n- B: Each run of a job will have a unique job_id; all tasks within this job will have a unique task_id is wrong because it does not satisfy the requirement in the question () as stated.\n- C: Each run of a job will have a unique orchestration_id; all tasks within this job will have a unique run_id is wrong because it does not satisfy the requirement in the question () as stated.\n- E: Each run of a job will have a unique run_id; all tasks within this job will also have a unique run_id is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q115.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 116,
    "question": "The data engineering team is configuring environments for development, testing, and production before beginning   migration on a new data pipeline. The team requires extensive testing on both the code and data resulting from code execution, and the team wants to develop and test against data as similar to production data as possible. A junior data engineer suggests that production data can be mounted to the development and testing environments, allowing pre-production code to execute against production data. Because all users have admin privileges in the development environment, the junior data engineer has offered to configure permissions and mount this data for the team. Which statement captures best practices for this situation?",
    "choices": [
      {
        "id": "A",
        "text": "All development, testing, and production code and data should exist in a single, unified workspace; creating separate environments for testing and development complicates administrative overhead."
      },
      {
        "id": "B",
        "text": "In environments where interactive code will be executed, production data should only be accessible with read permissions; creating isolated databases for each environment further reduces risks."
      },
      {
        "id": "C",
        "text": "As long as code in the development environment declares USE dev_db at the top of each notebook, there is no possibility of inadvertently committing changes back to production data sources."
      },
      {
        "id": "D",
        "text": "Because Delta Lake versions all data and supports time travel, it is not possible for user error or malicious actors to permanently delete production data; as such, it is generally safe to mount production data anywhere."
      },
      {
        "id": "E",
        "text": "Because access to production data will always be verified using passthrough credentials, it is safe to mount data to any Databricks development environment."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The data engineering team is configuring environments for development, testing, and production before beginning migration on a new data pipeline. The team requires extensive tes...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: In environments where interactive code will be executed, production data should only be accessible with read permissions; creating isolated databases for each environment further reduces risks. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: All development, testing, and production code and data should exist in a single, unified workspace; creating separate environments for testing and development complicates administrative overhead. is wrong because it does not satisfy the requirement in the question (The data engineering team is configuring environments for development, testing, and production before beginning migration on a new data pipeline. The team requires extensive tes...) as stated.\n- C: As long as code in the development environment declares USE dev_db at the top of each notebook, there is no possibility of inadvertently committing changes back to production data sources. is wrong because it does not satisfy the requirement in the question (The data engineering team is configuring environments for development, testing, and production before beginning migration on a new data pipeline. The team requires extensive tes...) as stated.\n- D: Because Delta Lake versions all data and supports time travel, it is not possible for user error or malicious actors to permanently delete production data; as such, it is generally safe to mount production data anywhere. is wrong because it does not satisfy the requirement in the question (The data engineering team is configuring environments for development, testing, and production before beginning migration on a new data pipeline. The team requires extensive tes...) as stated.\n- E: Because access to production data will always be verified using passthrough credentials, it is safe to mount data to any Databricks development environment. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q116.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 117,
    "question": "A data engineer, User A, has promoted a pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an external orchestration tool to trigger job runs through the REST API. Both users authorized the REST API calls using their personal access tokens. A workspace admin, User C, inherits responsibility for managing this pipeline. User C uses the Databricks Jobs UI to take \"Owner\" privileges of each job. Jobs continue to be triggered using the credentials and tooling configured by User B. An application has been configured to collect and parse run information returned by the REST API. Which statement describes the value returned in the creator_user_name field?",
    "choices": [
      {
        "id": "A",
        "text": "Once User C takes \"Owner\" privileges, their email address will appear in this field; prior to this, User A’s email address will appear in this field."
      },
      {
        "id": "B",
        "text": "User B’s email address will always appear in this field, as their credentials are always used to trigger the run."
      },
      {
        "id": "C",
        "text": "User A’s email address will always appear in this field, as they still own the underlying notebooks."
      },
      {
        "id": "D",
        "text": "Once User C takes \"Owner\" privileges, their email address will appear in this field; prior to this, User B’s email address will appear in this field."
      },
      {
        "id": "E",
        "text": "User C will only ever appear in this field if they manually trigger the job, otherwise it will indicate User B."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A data engineer, User A, has promoted a pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an extern...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: User A’s email address will always appear in this field, as they still own the underlying notebooks. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Once User C takes \"Owner\" privileges, their email address will appear in this field; prior to this, User A’s email address will appear in this field. is wrong because it does not satisfy the requirement in the question (A data engineer, User A, has promoted a pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an extern...) as stated.\n- B: User B’s email address will always appear in this field, as their credentials are always used to trigger the run. is wrong because it makes an absolute guarantee the platform does not provide, which the question’s scenario cannot rely on.\n- D: Once User C takes \"Owner\" privileges, their email address will appear in this field; prior to this, User B’s email address will appear in this field. is wrong because it does not satisfy the requirement in the question (A data engineer, User A, has promoted a pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an extern...) as stated.\n- E: User C will only ever appear in this field if they manually trigger the job, otherwise it will indicate User B. is wrong because it does not satisfy the requirement in the question (A data engineer, User A, has promoted a pipeline to production by using the REST API to programmatically create several jobs. A DevOps engineer, User B, has configured an extern...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q117.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 124,
    "question": "The security team is exploring whether or not the Databricks secrets module can be leveraged for connecting to an external database. After testing the code with all Python variables being defined with strings, they upload the password to the secrets module and configure the correct permissions for the currently active user. They then modify their code to the following (leaving all other variables unchanged).   Which statement describes what will happen when the above code is executed?",
    "choices": [
      {
        "id": "A",
        "text": "The connection to the external table will succeed; the string \"REDACTED\" will be printed."
      },
      {
        "id": "B",
        "text": "An interactive input box will appear in the notebook; if the right password is provided, the connection will succeed and the encoded password will be saved to DBFS."
      },
      {
        "id": "C",
        "text": "An interactive input box will appear in the notebook; if the right password is provided, the connection will succeed and the password will be printed in plain text."
      },
      {
        "id": "D",
        "text": "The connection to the external table will succeed; the string value of password will be printed in plain text."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: The security team is exploring whether or not the Databricks secrets module can be leveraged for connecting to an external database. After testing the code with all Python varia...\n- Tested mechanism/concept: Databricks secrets (scopes, ACLs) and safe credential handling.\n- Why A is correct: The connection to the external table will succeed; the string \"REDACTED\" will be printed. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: An interactive input box will appear in the notebook; if the right password is provided, the connection will succeed and the encoded password will be saved to DBFS. is wrong because it does not satisfy the requirement in the question (The security team is exploring whether or not the Databricks secrets module can be leveraged for connecting to an external database. After testing the code with all Python varia...) as stated.\n- C: An interactive input box will appear in the notebook; if the right password is provided, the connection will succeed and the password will be printed in plain text. is wrong because it does not satisfy the requirement in the question (The security team is exploring whether or not the Databricks secrets module can be leveraged for connecting to an external database. After testing the code with all Python varia...) as stated.\n- D: The connection to the external table will succeed; the string value of password will be printed in plain text. is wrong because it does not satisfy the requirement in the question (The security team is exploring whether or not the Databricks secrets module can be leveraged for connecting to an external database. After testing the code with all Python varia...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q124.webp"
    ],
    "docs": [
      {
        "title": "Databricks secrets (dbutils.secrets) and redaction",
        "query": "Databricks secrets redacted output"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 126,
    "question": "A junior member of the data engineering team is exploring the language interoperability of Databricks notebooks. The intended outcome of the below code is to register a view of all sales that occurred in countries on the continent of Africa that appear in the geo_lookup table. Before executing the code, running SHOW TABLES on the current database indicates the database contains only two tables: geo_lookup and sales. What will be the outcome of executing these command cells m order m an interactive notebook?",
    "choices": [
      {
        "id": "A",
        "text": "Both commands will succeed. Executing SHOW TABLES will show that countries_af and sales_af have been registered as views."
      },
      {
        "id": "B",
        "text": "Cmd 1 will succeed. Cmd 2 will search all accessible databases for a table or view named countries_af: if this entity exists, Cmd 2 will succeed."
      },
      {
        "id": "C",
        "text": "Cmd 1 will succeed and Cmd 2 will fail. countries_af will be a Python variable representing a PySpark DataFrame."
      },
      {
        "id": "D",
        "text": "Cmd 1 will succeed and Cmd 2 will fail. countries_af will be a Python variable containing a list of strings."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A junior member of the data engineering team is exploring the language interoperability of Databricks notebooks. The intended outcome of the below code is to register a view of...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: Cmd 1 will succeed and Cmd 2 will fail. countries_af will be a Python variable containing a list of strings. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Both commands will succeed. Executing SHOW TABLES will show that countries_af and sales_af have been registered as views. is wrong because it does not satisfy the requirement in the question (A junior member of the data engineering team is exploring the language interoperability of Databricks notebooks. The intended outcome of the below code is to register a view of...) as stated.\n- B: Cmd 1 will succeed. Cmd 2 will search all accessible databases for a table or view named countries_af: if this entity exists, Cmd 2 will succeed. is wrong because it does not satisfy the requirement in the question (A junior member of the data engineering team is exploring the language interoperability of Databricks notebooks. The intended outcome of the below code is to register a view of...) as stated.\n- C: Cmd 1 will succeed and Cmd 2 will fail. countries_af will be a Python variable representing a PySpark DataFrame. is wrong because it does not satisfy the requirement in the question (A junior member of the data engineering team is exploring the language interoperability of Databricks notebooks. The intended outcome of the below code is to register a view of...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q126.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 127,
    "question": "The data science team has requested assistance in accelerating queries on free-form text from user reviews. The data is currently stored in Parquet with the below schema: item_id INT, user_id INT, review_id INT, rating FLOAT, review STRING The review column contains the full text of the review left by the user. Specifically, the data science team is looking to identify if any of 30 key words exist in this field. A junior data engineer suggests converting this data to Delta Lake will improve query performance. Which response to the junior data engineer’s suggestion is correct?",
    "choices": [
      {
        "id": "A",
        "text": "Delta Lake statistics are not optimized for free text fields with high cardinality."
      },
      {
        "id": "B",
        "text": "Delta Lake statistics are only collected on the first 4 columns in a table."
      },
      {
        "id": "C",
        "text": "ZORDER ON review will need to be run to see performance gains."
      },
      {
        "id": "D",
        "text": "The Delta log creates a term matrix for free text fields to support selective filtering."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: The data science team has requested assistance in accelerating queries on free-form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...\n- Tested mechanism/concept: Parquet/Delta schema enforcement & evolution.\n- Why A is correct: Delta Lake statistics are not optimized for free text fields with high cardinality. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Delta Lake statistics are only collected on the first 4 columns in a table. is wrong because it does not satisfy the requirement in the question (The data science team has requested assistance in accelerating queries on free-form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...) as stated.\n- C: ZORDER ON review will need to be run to see performance gains. is wrong because it does not satisfy the requirement in the question (The data science team has requested assistance in accelerating queries on free-form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...) as stated.\n- D: The Delta log creates a term matrix for free text fields to support selective filtering. is wrong because it does not satisfy the requirement in the question (The data science team has requested assistance in accelerating queries on free-form text from user reviews. The data is currently stored in Parquet with the below schema: item_i...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q127.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 130,
    "question": "The following table consists of items found in user carts within an e-commerce website.    The following MERGE statement is used to update this table using an updates view, with schema evolution enabled on this table. How would the following update be handled?",
    "choices": [
      {
        "id": "A",
        "text": "The update throws an error because changes to existing columns in the target schema are not supported."
      },
      {
        "id": "B",
        "text": "The new nested Field is added to the target schema, and dynamically read as NULL for existing unmatched records."
      },
      {
        "id": "C",
        "text": "The update is moved to a separate \"rescued\" column because it is missing a column expected in the target schema."
      },
      {
        "id": "D",
        "text": "The new nested field is added to the target schema, and files underlying existing records are updated to include NULL values for the new field."
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The following table consists of items found in user carts within an e-commerce website. The following MERGE statement is used to update this table using an updates view, with sc...\n- Tested mechanism/concept: Delta Lake MERGE semantics for upserts.\n- Why B is correct: The new nested Field is added to the target schema, and dynamically read as NULL for existing unmatched records. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: The update throws an error because changes to existing columns in the target schema are not supported. is wrong because it does not satisfy the requirement in the question (The following table consists of items found in user carts within an e-commerce website. The following MERGE statement is used to update this table using an updates view, with sc...) as stated.\n- C: The update is moved to a separate \"rescued\" column because it is missing a column expected in the target schema. is wrong because it does not satisfy the requirement in the question (The following table consists of items found in user carts within an e-commerce website. The following MERGE statement is used to update this table using an updates view, with sc...) as stated.\n- D: The new nested field is added to the target schema, and files underlying existing records are updated to include NULL values for the new field. is wrong because it does not satisfy the requirement in the question (The following table consists of items found in user carts within an e-commerce website. The following MERGE statement is used to update this table using an updates view, with sc...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q130.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 132,
    "question": "An hourly batch job is configured to ingest data files from a cloud object storage container where each batch represent all records produced by the source system in a given hour. The batch job to process these records into the Lakehouse is sufficiently delayed to ensure no late-arriving data is missed. The user_id field represents a unique key for the data, which has the following schema: user_id BIGINT, username STRING, user_utc STRING, user_region STRING, last_login BIGINT, auto_pay BOOLEAN, last_updated BIGINT New records are all ingested into a table named account_history which maintains a full record of all data in the same schema as the source. The next table in the system is named account_current and is implemented as a Type 1 table representing the most recent value for each unique user_id. Which implementation can be used to efficiently update the described account_current table as part of each hourly batch job assuming there are millions of user accounts and tens of thousands of records processed hourly?",
    "choices": [
      {
        "id": "A",
        "text": "Filter records in account_history using the last_updated field and the most recent hour processed, making sure to deduplicate on username; write a merge statement to update or insert the most recent value for each username."
      },
      {
        "id": "B",
        "text": "Use Auto Loader to subscribe to new files in the account_history directory; configure a Structured Streaming trigger available job to batch update newly detected files into the account_current table."
      },
      {
        "id": "C",
        "text": "Overwrite the account_current table with each batch using the results of a query against the account_history table grouping by user_id and filtering for the max value of last_updated."
      },
      {
        "id": "D",
        "text": "Filter records in account_history using the last_updated field and the most recent hour processed, as well as the max last_login by user_id write a merge statement to update or insert the most recent value for each user_id."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: An hourly batch job is configured to ingest data files from a cloud object storage container\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: Filter records in account_history using the last_updated field and the most recent hour processed, as well as the max last_login by user_id write a merge statement to update or insert the most recent value for each user_id. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Filter records in account_history using the last_updated field and the most recent hour processed, making sure to deduplicate on username; write a merge statement to update or insert the most recent value for each username. is wrong because it does not satisfy the requirement in the question (An hourly batch job is configured to ingest data files from a cloud object storage container) as stated.\n- B: Use Auto Loader to subscribe to new files in the account_history directory; configure a Structured Streaming trigger available job to batch update newly detected files into the account_current table. is wrong because it does not satisfy the requirement in the question (An hourly batch job is configured to ingest data files from a cloud object storage container) as stated.\n- C: Overwrite the account_current table with each batch using the results of a query against the account_history table grouping by user_id and filtering for the max value of last_updated. is wrong because it does not satisfy the requirement in the question (An hourly batch job is configured to ingest data files from a cloud object storage container) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q132.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 134,
    "question": "A Delta lake table with CDF enabled table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information about customers derived from a number of upstream sources. Currently, the data engineering team populates this table nightly by overwriting the table with the current valid values derived from upstream data sources. The churn prediction model used by the ML team is fairly stable in production. The team is only interested in making predictions on records that have changed in the past 24 hours. Which approach would simplify the identification of these changed records?",
    "choices": [
      {
        "id": "A",
        "text": "Apply the churn model to all rows in the customer_churn_params table, but implement logic to perform an upsert into the predictions table that ignores rows where predictions have not changed."
      },
      {
        "id": "B",
        "text": "Convert the batch job to a Structured Streaming job using the complete output mode; configure a Structured Streaming job to read from the customer_churn_params table and incrementally predict against the churn model."
      },
      {
        "id": "C",
        "text": "Replace the current overwrite logic with a merge statement to modify only those records that have changed; write logic to make predictions on the changed records identified by the change data feed."
      },
      {
        "id": "D",
        "text": "Modify the overwrite logic to include a field populated by calling spark.sql.functions.current_timestamp() as data are being written; use this field to identify records written on a particular date."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A Delta lake table with CDF enabled table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information a...\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why C is correct: Replace the current overwrite logic with a merge statement to modify only those records that have changed; write logic to make predictions on the changed records identified by the change data feed. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Apply the churn model to all rows in the customer_churn_params table, but implement logic to perform an upsert into the predictions table that ignores rows where predictions have not changed. is wrong because it does not satisfy the requirement in the question (A Delta lake table with CDF enabled table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information a...) as stated.\n- B: Convert the batch job to a Structured Streaming job using the complete output mode; configure a Structured Streaming job to read from the customer_churn_params table and incrementally predict against the churn model. is wrong because it does not satisfy the requirement in the question (A Delta lake table with CDF enabled table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information a...) as stated.\n- D: Modify the overwrite logic to include a field populated by calling spark.sql.functions.current_timestamp() as data are being written; use this field to identify records written on a particular date. is wrong because it does not satisfy the requirement in the question (A Delta lake table with CDF enabled table in the Lakehouse named customer_churn_params is used in churn prediction by the machine learning team. The table contains information a...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q134.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 135,
    "question": "A view is registered with the following code: Both users and orders are Delta Lake tables. Which statement describes the results of querying recent_orders?",
    "choices": [
      {
        "id": "A",
        "text": "All logic will execute when the view is defined and store the result of joining tables to the DBFS; this stored data will be returned when the view is queried."
      },
      {
        "id": "B",
        "text": "Results will be computed and cached when the view is defined; these cached results will incrementally update as new records are inserted into source tables."
      },
      {
        "id": "C",
        "text": "All logic will execute at query time and return the result of joining the valid versions of the source tables at   the time the query finishes."
      },
      {
        "id": "D",
        "text": "All logic will execute at query time and return the result of joining the valid versions of the source tables at the time the query began."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A view is registered with the following code: Both users and orders are Delta Lake tables.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: All logic will execute at query time and return the result of joining the valid versions of the source tables at the time the query began. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: All logic will execute when the view is defined and store the result of joining tables to the DBFS; this stored data will be returned when the view is queried. is wrong because it does not satisfy the requirement in the question (A view is registered with the following code: Both users and orders are Delta Lake tables.) as stated.\n- B: Results will be computed and cached when the view is defined; these cached results will incrementally update as new records are inserted into source tables. is wrong because it does not satisfy the requirement in the question (A view is registered with the following code: Both users and orders are Delta Lake tables.) as stated.\n- C: All logic will execute at query time and return the result of joining the valid versions of the source tables at   the time the query finishes. is wrong because it does not satisfy the requirement in the question (A view is registered with the following code: Both users and orders are Delta Lake tables.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q135.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 138,
    "question": "A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity and average temperature for each non- overlapping five-minute interval. Events are recorded once per minute per device. Streaming DataFrame df has the following schema: \"device_id INT, event_time TIMESTAMP, temp FLOAT, humidity FLOAT\" Code block:    Which line of code correctly fills in the blank within the code block to complete this task?",
    "choices": [
      {
        "id": "A",
        "text": "to_interval(\"event_time\", \"5 minutes\").alias(\"time\")"
      },
      {
        "id": "B",
        "text": "window(\"event_time\", \"5 minutes\").alias(\"time\")"
      },
      {
        "id": "C",
        "text": "\"event_time\""
      },
      {
        "id": "D",
        "text": "lag(\"event_time\", \"10 minutes\").alias(\"time\")"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why B is correct: window(\"event_time\", \"5 minutes\").alias(\"time\") directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: to_interval(\"event_time\", \"5 minutes\").alias(\"time\") is wrong because it does not satisfy the requirement in the question (A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...) as stated.\n- C: \"event_time\" is wrong because it does not satisfy the requirement in the question (A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...) as stated.\n- D: lag(\"event_time\", \"10 minutes\").alias(\"time\") is wrong because it does not satisfy the requirement in the question (A junior data engineer has been asked to develop a streaming data pipeline with a grouped aggregation using DataFrame df. The pipeline needs to calculate the average humidity an...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q138.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 148,
    "question": "A DLT pipeline includes the following streaming tables: •raw_iot ingests raw device measurement data from a heart rate tracking device. •bpm_stats incrementally computes user statistics based on BPM measurements from raw_iot. How can the data engineer configure this pipeline to be able to retain manually deleted or updated records in the raw_iot table, while recomputing the downstream table bpm_stats table when a pipeline update is run?",
    "choices": [
      {
        "id": "A",
        "text": "Set the pipelines.reset.allowed property to false on raw_iot"
      },
      {
        "id": "B",
        "text": "Set the skipChangeCommits flag to true on raw_iot"
      },
      {
        "id": "C",
        "text": "Set the pipelines.reset.allowed property to false on bpm_stats"
      },
      {
        "id": "D",
        "text": "Set the skipChangeCommits flag to true on bpm_stats"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: A DLT pipeline includes the following streaming tables: •raw_iot ingests raw device measurement data from a heart rate tracking device. •bpm_stats incrementally computes user st...\n- Tested mechanism/concept: Delta Live Tables pipeline semantics (tables vs views, expectations, flow).\n- Why B is correct: Set the skipChangeCommits flag to true on raw_iot directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Set the pipelines.reset.allowed property to false on raw_iot is wrong because it does not satisfy the requirement in the question (A DLT pipeline includes the following streaming tables: •raw_iot ingests raw device measurement data from a heart rate tracking device. •bpm_stats incrementally computes user st...) as stated.\n- C: Set the pipelines.reset.allowed property to false on bpm_stats is wrong because it does not satisfy the requirement in the question (A DLT pipeline includes the following streaming tables: •raw_iot ingests raw device measurement data from a heart rate tracking device. •bpm_stats incrementally computes user st...) as stated.\n- D: Set the skipChangeCommits flag to true on bpm_stats is wrong because it does not satisfy the requirement in the question (A DLT pipeline includes the following streaming tables: •raw_iot ingests raw device measurement data from a heart rate tracking device. •bpm_stats incrementally computes user st...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q148.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 161,
    "question": "A data engineer wants to join a stream of advertisement impressions (when an ad was shown) with another stream of user clicks on advertisements to correlate when impressions led to monetizable clicks. In the code below, Impressions is a streaming DataFrame with a watermark (\"event_time\", \"10 minutes\") The data engineer notices the query slowing down significantly. Which solution would improve the performance?",
    "choices": [
      {
        "id": "A",
        "text": "Joining on event time constraint: clickTime >= impressionTime AND clickTime <= impressionTime interval 1 hour"
      },
      {
        "id": "B",
        "text": "Joining on event time constraint: clickTime + 3 hours < impressionTime - 2 hours"
      },
      {
        "id": "C",
        "text": "Joining on event time constraint: clickTime == impressionTime using a leftOuter join"
      },
      {
        "id": "D",
        "text": "Joining on event time constraint: clickTime >= impressionTime - interval 3 hours and removing watermarks"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A data engineer wants to join a stream of advertisement impressions (\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why A is correct: Joining on event time constraint: clickTime >= impressionTime AND clickTime <= impressionTime interval 1 hour directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Joining on event time constraint: clickTime + 3 hours < impressionTime - 2 hours is wrong because it does not satisfy the requirement in the question (A data engineer wants to join a stream of advertisement impressions () as stated.\n- C: Joining on event time constraint: clickTime == impressionTime using a leftOuter join is wrong because it does not satisfy the requirement in the question (A data engineer wants to join a stream of advertisement impressions () as stated.\n- D: Joining on event time constraint: clickTime >= impressionTime - interval 3 hours and removing watermarks is wrong because it does not satisfy the requirement in the question (A data engineer wants to join a stream of advertisement impressions () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q161.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 164,
    "question": "All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, offset LONG, timestamp LONG There are 5 unique topics being ingested. Only the \"registration\" topic contains Personal Identifiable Information (PII). The company wishes to restrict access to PII. The company also wishes to only retain records containing PII in this table for 14 days after initial ingestion. However, for non-PII information, it would like to retain these records indefinitely. Which solution meets the requirements?",
    "choices": [
      {
        "id": "A",
        "text": "All data should be deleted biweekly; Delta Lake's time travel functionality should be leveraged to maintain a history of non-PII information."
      },
      {
        "id": "B",
        "text": "Data should be partitioned by the registration field, allowing ACLs and delete statements to be set for the PII directory."
      },
      {
        "id": "C",
        "text": "Data should be partitioned by the topic field, allowing ACLs and delete statements to leverage partition boundaries."
      },
      {
        "id": "D",
        "text": "Separate object storage containers should be specified based on the partition field, allowing isolation at the storage level."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: Data should be partitioned by the topic field, allowing ACLs and delete statements to leverage partition boundaries. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: All data should be deleted biweekly; Delta Lake's time travel functionality should be leveraged to maintain a history of non-PII information. is wrong because it does not satisfy the requirement in the question (All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...) as stated.\n- B: Data should be partitioned by the registration field, allowing ACLs and delete statements to be set for the PII directory. is wrong because it does not satisfy the requirement in the question (All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...) as stated.\n- D: Separate object storage containers should be specified based on the partition field, allowing isolation at the storage level. is wrong because it does not satisfy the requirement in the question (All records from an Apache Kafka producer are being ingested into a single Delta Lake table with the following schema: key BINARY, value BINARY, topic STRING, partition LONG, of...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q164.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 168,
    "question": "What is the retention of job run history?",
    "choices": [
      {
        "id": "A",
        "text": "It is retained until you export or delete job run logs"
      },
      {
        "id": "B",
        "text": "It is retained for 30 days, during which time you can deliver job run logs to DBFS or S3"
      },
      {
        "id": "C",
        "text": "It is retained for 60 days, during which you can export notebook run results to HTML"
      },
      {
        "id": "D",
        "text": "It is retained for 60 days, after which logs are archived"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: It is retained for 60 days, during which you can export notebook run results to HTML directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: It is retained until you export or delete job run logs is wrong because it does not satisfy the requirement in the question () as stated.\n- B: It is retained for 30 days, during which time you can deliver job run logs to DBFS or S3 is wrong because it does not satisfy the requirement in the question () as stated.\n- D: It is retained for 60 days, after which logs are archived is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q168.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 172,
    "question": "The data engineer is using Spark's MEMORY_ONLY storage level.     Which indicators should the data engineer look for in the Spark UI's Storage tab to signal that a cached table is not performing optimally?",
    "choices": [
      {
        "id": "A",
        "text": "On Heap Memory Usage is within 75% of Off Heap Memory Usage"
      },
      {
        "id": "B",
        "text": "The RDD Block Name includes the “*” annotation signaling a failure to cache"
      },
      {
        "id": "C",
        "text": "Size on Disk is > 0"
      },
      {
        "id": "D",
        "text": "The number of Cached Partitions > the number of Spark Partitions"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: The data engineer is using Spark's MEMORY_ONLY storage level.\n- Tested mechanism/concept: Spark UI tabs (SQL/Jobs/Stages/Storage) for performance diagnosis.\n- Why B is correct: The RDD Block Name includes the “*” annotation signaling a failure to cache directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: On Heap Memory Usage is within 75% of Off Heap Memory Usage is wrong because it does not satisfy the requirement in the question (The data engineer is using Spark's MEMORY_ONLY storage level.) as stated.\n- C: Size on Disk is > 0 is wrong because it does not satisfy the requirement in the question (The data engineer is using Spark's MEMORY_ONLY storage level.) as stated.\n- D: The number of Cached Partitions > the number of Spark Partitions is wrong because it does not satisfy the requirement in the question (The data engineer is using Spark's MEMORY_ONLY storage level.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q172.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 174,
    "question": "What is a method of installing a Python package scoped at the notebook level to all nodes in the currently active cluster?",
    "choices": [
      {
        "id": "A",
        "text": "Run source env/bin/activate in a notebook setup script"
      },
      {
        "id": "B",
        "text": "Install libraries from PyPI using the cluster UI"
      },
      {
        "id": "C",
        "text": "Use %pip install in a notebook cell"
      },
      {
        "id": "D",
        "text": "Use %sh pip install in a notebook cell"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: Databricks compute configuration (clusters, jobs compute, pools).\n- Why C is correct: Use %pip install in a notebook cell directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Run source env/bin/activate in a notebook setup script is wrong because it does not satisfy the requirement in the question () as stated.\n- B: Install libraries from PyPI using the cluster UI is wrong because it does not satisfy the requirement in the question () as stated.\n- D: Use %sh pip install in a notebook cell is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q174.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 176,
    "question": "Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code. Which benefit offsets this additional effort?",
    "choices": [
      {
        "id": "A",
        "text": "Improves the quality of your data"
      },
      {
        "id": "B",
        "text": "Validates a complete use case of your application"
      },
      {
        "id": "C",
        "text": "Troubleshooting is easier since all steps are isolated and tested individually"
      },
      {
        "id": "D",
        "text": "Ensures that all steps interact correctly to achieve the desired end result"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: Troubleshooting is easier since all steps are isolated and tested individually directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Improves the quality of your data is wrong because it does not satisfy the requirement in the question (Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.) as stated.\n- B: Validates a complete use case of your application is wrong because it does not satisfy the requirement in the question (Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.) as stated.\n- D: Ensures that all steps interact correctly to achieve the desired end result is wrong because it does not satisfy the requirement in the question (Incorporating unit tests into a PySpark application requires upfront attention to the design of your jobs, or a potentially significant refactoring of existing code.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q176.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 177,
    "question": "What describes integration testing?",
    "choices": [
      {
        "id": "A",
        "text": "It validates an application use case."
      },
      {
        "id": "B",
        "text": "It validates behavior of individual elements of an application,"
      },
      {
        "id": "C",
        "text": "It requires an automated testing framework."
      },
      {
        "id": "D",
        "text": "It validates interactions between subsystems of your application."
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: Choose the option that best satisfies the scenario described in the question.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why D is correct: It validates interactions between subsystems of your application. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: It validates an application use case. is wrong because it does not satisfy the requirement in the question () as stated.\n- B: It validates behavior of individual elements of an application, is wrong because it does not satisfy the requirement in the question () as stated.\n- C: It requires an automated testing framework. is wrong because it does not satisfy the requirement in the question () as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q177.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 179,
    "question": "A Databricks job has been configured with three tasks, each of which is a Databricks notebook. Task A does not depend on other tasks. Tasks B and C run in parallel, with each having a serial dependency on task A. What will be the resulting state if tasks A and B complete successfully but task C fails during a scheduled run?",
    "choices": [
      {
        "id": "A",
        "text": "All logic expressed in the notebook associated with tasks A and B will have been successfully completed; some operations in task C may have completed successfully."
      },
      {
        "id": "B",
        "text": "Unless all tasks complete successfully, no changes will be committed to the Lakehouse; because task C failed, all commits will be rolled back automatically."
      },
      {
        "id": "C",
        "text": "Because all tasks are managed as a dependency graph, no changes will be committed to the Lakehouse until all tasks have successfully been completed."
      },
      {
        "id": "D",
        "text": "All logic expressed in the notebook associated with tasks A and B will have been successfully completed; any changes made in task C will be rolled back due to task failure."
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A Databricks job has been configured with three tasks, each of\n- Tested mechanism/concept: Databricks Jobs scheduling/execution model (task types, parameters, retries).\n- Why A is correct: All logic expressed in the notebook associated with tasks A and B will have been successfully completed; some operations in task C may have completed successfully. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Unless all tasks complete successfully, no changes will be committed to the Lakehouse; because task C failed, all commits will be rolled back automatically. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with three tasks, each of) as stated.\n- C: Because all tasks are managed as a dependency graph, no changes will be committed to the Lakehouse until all tasks have successfully been completed. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with three tasks, each of) as stated.\n- D: All logic expressed in the notebook associated with tasks A and B will have been successfully completed; any changes made in task C will be rolled back due to task failure. is wrong because it does not satisfy the requirement in the question (A Databricks job has been configured with three tasks, each of) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q179.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 187,
    "question": "A data engineer is performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF. Which code block attempts to perform an invalid stream-static join?",
    "choices": [
      {
        "id": "A",
        "text": "userLookup.join(streamingDF, [\"user_id\"], how=\"right\")"
      },
      {
        "id": "B",
        "text": "streamingDF.join(userLookup, [\"user_id\"], how=\"inner\")"
      },
      {
        "id": "C",
        "text": "userLookup.join(streamingDF, [\"user_id\"), how=\"inner\")"
      },
      {
        "id": "D",
        "text": "userLookup.join(streamingDF, [\"user_id\"], how=\"left\")"
      }
    ],
    "answer": "D",
    "explanation": "Why the correct answer is correct\n- Requirement: A data engineer is performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.\n- Tested mechanism/concept: Spark Structured Streaming / Auto Loader pipeline behavior.\n- Why D is correct: userLookup.join(streamingDF, [\"user_id\"], how=\"left\") directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: userLookup.join(streamingDF, [\"user_id\"], how=\"right\") is wrong because it does not satisfy the requirement in the question (A data engineer is performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.) as stated.\n- B: streamingDF.join(userLookup, [\"user_id\"], how=\"inner\") is wrong because it does not satisfy the requirement in the question (A data engineer is performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.) as stated.\n- C: userLookup.join(streamingDF, [\"user_id\"), how=\"inner\") is wrong because it does not satisfy the requirement in the question (A data engineer is performing a join operation to combine values from a static userLookup table with a streaming DataFrame streamingDF.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q187.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 191,
    "question": "A team of data engineers are adding tables to a DLT pipeline that contain repetitive expectations for many of the same data quality checks. One member of the team suggests reusing these data quality rules across all tables defined for this pipeline. What approach would allow them to do this?",
    "choices": [
      {
        "id": "A",
        "text": "Add data quality constraints to tables in this pipeline using an external job with access to pipeline configuration files."
      },
      {
        "id": "B",
        "text": "Use global Python variables to make expectations visible across DLT notebooks included in the same pipeline."
      },
      {
        "id": "C",
        "text": "Maintain data quality rules in a separate Databricks notebook that each DLT notebook or file can import as a library."
      },
      {
        "id": "D",
        "text": "Maintain data quality rules in a Delta table outside of this pipeline's target schema, providing the schema name as a pipeline parameter."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A team of data engineers are adding tables to a DLT pipeline that contain repetitive expectations for many of the same data quality checks. One member of the team suggests reusi...\n- Tested mechanism/concept: Delta Live Tables pipeline semantics (tables vs views, expectations, flow).\n- Why C is correct: Maintain data quality rules in a separate Databricks notebook that each DLT notebook or file can import as a library. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Add data quality constraints to tables in this pipeline using an external job with access to pipeline configuration files. is wrong because it does not satisfy the requirement in the question (A team of data engineers are adding tables to a DLT pipeline that contain repetitive expectations for many of the same data quality checks. One member of the team suggests reusi...) as stated.\n- B: Use global Python variables to make expectations visible across DLT notebooks included in the same pipeline. is wrong because it does not satisfy the requirement in the question (A team of data engineers are adding tables to a DLT pipeline that contain repetitive expectations for many of the same data quality checks. One member of the team suggests reusi...) as stated.\n- D: Maintain data quality rules in a Delta table outside of this pipeline's target schema, providing the schema name as a pipeline parameter. is wrong because it does not satisfy the requirement in the question (A team of data engineers are adding tables to a DLT pipeline that contain repetitive expectations for many of the same data quality checks. One member of the team suggests reusi...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q191.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 192,
    "question": "A user wants to use DLT expectations to validate that a derived table report contains all records from the source, included in the table validation_copy. The user attempts and fails to accomplish this by adding an expectation to the report table definition. Which approach would allow using DLT expectations to validate all expected records are present in this table?",
    "choices": [
      {
        "id": "A",
        "text": "Define a temporary table that performs a left outer join on validation_copy and report, and define an expectation that no report key values are null"
      },
      {
        "id": "B",
        "text": "Define a SQL UDF that performs a left outer join on two tables, and check if this returns null values for report key values in a DLT expectation for the report table"
      },
      {
        "id": "C",
        "text": "Define a view that performs a left outer join on validation_copy and report, and reference this view in DLT expectations for the report table"
      },
      {
        "id": "D",
        "text": "Define a function that performs a left outer join on validation_copy and report, and check against the result in a DLT expectation for the report table"
      }
    ],
    "answer": "A",
    "explanation": "Why the correct answer is correct\n- Requirement: A user wants to use DLT expectations to validate that a derived table report contains all records from the source, included in the table validation_copy. The user attempts and f...\n- Tested mechanism/concept: Delta Live Tables pipeline semantics (tables vs views, expectations, flow).\n- Why A is correct: Define a temporary table that performs a left outer join on validation_copy and report, and define an expectation that no report key values are null directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- B: Define a SQL UDF that performs a left outer join on two tables, and check if this returns null values for report key values in a DLT expectation for the report table is wrong because it does not satisfy the requirement in the question (A user wants to use DLT expectations to validate that a derived table report contains all records from the source, included in the table validation_copy. The user attempts and f...) as stated.\n- C: Define a view that performs a left outer join on validation_copy and report, and reference this view in DLT expectations for the report table is wrong because it does not satisfy the requirement in the question (A user wants to use DLT expectations to validate that a derived table report contains all records from the source, included in the table validation_copy. The user attempts and f...) as stated.\n- D: Define a function that performs a left outer join on validation_copy and report, and check against the result in a DLT expectation for the report table is wrong because it does not satisfy the requirement in the question (A user wants to use DLT expectations to validate that a derived table report contains all records from the source, included in the table validation_copy. The user attempts and f...) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q192.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  },
  {
    "id": 195,
    "question": "A data engineer needs to capture pipeline settings from an existing setting in the workspace, and use them to create and version a JSON file to create a new pipeline. Which command should the data engineer enter in a web terminal configured with the Databricks CLI?",
    "choices": [
      {
        "id": "A",
        "text": "Use list pipelines to get the specs for all pipelines; get the pipeline spec from the returned results; parse and use this to create a pipeline"
      },
      {
        "id": "B",
        "text": "Stop the existing pipeline; use the returned settings in a reset command"
      },
      {
        "id": "C",
        "text": "Use the get command to capture the settings for the existing pipeline; remove the pipeline_id and rename the pipeline; use this in a create command"
      },
      {
        "id": "D",
        "text": "Use the clone command to create a copy of an existing pipeline; use the get JSON command to get the pipeline definition; save this to git"
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A data engineer needs to capture pipeline settings from an existing setting in the workspace, and use them to create and version a JSON file to create a new pipeline.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why C is correct: Use the get command to capture the settings for the existing pipeline; remove the pipeline_id and rename the pipeline; use this in a create command directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Use list pipelines to get the specs for all pipelines; get the pipeline spec from the returned results; parse and use this to create a pipeline is wrong because it does not satisfy the requirement in the question (A data engineer needs to capture pipeline settings from an existing setting in the workspace, and use them to create and version a JSON file to create a new pipeline.) as stated.\n- B: Stop the existing pipeline; use the returned settings in a reset command is wrong because it does not satisfy the requirement in the question (A data engineer needs to capture pipeline settings from an existing setting in the workspace, and use them to create and version a JSON file to create a new pipeline.) as stated.\n- D: Use the clone command to create a copy of an existing pipeline; use the get JSON command to get the pipeline definition; save this to git is wrong because it does not satisfy the requirement in the question (A data engineer needs to capture pipeline settings from an existing setting in the workspace, and use them to create and version a JSON file to create a new pipeline.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q195.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 197,
    "question": "A Data Engineer wants to run unit tests using common Python testing frameworks on Python functions defined across several Databricks notebooks currently used in production.     How can the data engineer run unit tests against functions that work with data in production?",
    "choices": [
      {
        "id": "A",
        "text": "Define and import unit test functions from a separate Databricks notebook"
      },
      {
        "id": "B",
        "text": "Define and unit test functions using Files in Repos"
      },
      {
        "id": "C",
        "text": "Run unit tests against non-production data that closely mirrors production"
      },
      {
        "id": "D",
        "text": "Define unit tests and functions within the same notebook"
      }
    ],
    "answer": "B",
    "explanation": "Why the correct answer is correct\n- Requirement: A Data Engineer wants to run unit tests using common Python testing frameworks on Python functions defined across several Databricks notebooks currently used in production.\n- Tested mechanism/concept: The Databricks/Spark concept tested by the scenario.\n- Why B is correct: Define and unit test functions using Files in Repos directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Define and import unit test functions from a separate Databricks notebook is wrong because it does not satisfy the requirement in the question (A Data Engineer wants to run unit tests using common Python testing frameworks on Python functions defined across several Databricks notebooks currently used in production.) as stated.\n- C: Run unit tests against non-production data that closely mirrors production is wrong because it does not satisfy the requirement in the question (A Data Engineer wants to run unit tests using common Python testing frameworks on Python functions defined across several Databricks notebooks currently used in production.) as stated.\n- D: Define unit tests and functions within the same notebook is wrong because it does not satisfy the requirement in the question (A Data Engineer wants to run unit tests using common Python testing frameworks on Python functions defined across several Databricks notebooks currently used in production.) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q197.webp"
    ],
    "docs": [
      {
        "title": "Databricks Repos (Git integration)",
        "query": "Databricks Repos pull fetch branch"
      },
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      }
    ]
  },
  {
    "id": 198,
    "question": "A data engineer wants to refactor the following DLT code, which includes multiple table definitions with very similar code. In an attempt to programmatically create these tables using a parameterized table definition, the data engineer writes the following code. The pipeline runs an update with this refactored code, but generates a different DAG showing incorrect configuration values for these tables. How can the data engineer fix this?",
    "choices": [
      {
        "id": "A",
        "text": "Wrap the for loop inside another table definition, using generalized names and properties to replace with those from the inner table definition."
      },
      {
        "id": "B",
        "text": "Convert the list of configuration values to a dictionary of table settings, using table names as keys."
      },
      {
        "id": "C",
        "text": "Move the table definition into a separate function, and make calls to this function using different input parameters inside the for loop."
      },
      {
        "id": "D",
        "text": "Load the configuration values for these tables from a separate file, located at a path provided by a pipeline parameter."
      }
    ],
    "answer": "C",
    "explanation": "Why the correct answer is correct\n- Requirement: A data engineer wants to refactor the following DLT code,\n- Tested mechanism/concept: Delta Live Tables pipeline semantics (tables vs views, expectations, flow).\n- Why C is correct: Move the table definition into a separate function, and make calls to this function using different input parameters inside the for loop. directly aligns with the requirement and uses the correct Databricks/Spark mechanism implied by the question.\n\nWhy the other options are incorrect\n- A: Wrap the for loop inside another table definition, using generalized names and properties to replace with those from the inner table definition. is wrong because it does not satisfy the requirement in the question (A data engineer wants to refactor the following DLT code,) as stated.\n- B: Convert the list of configuration values to a dictionary of table settings, using table names as keys. is wrong because it does not satisfy the requirement in the question (A data engineer wants to refactor the following DLT code,) as stated.\n- D: Load the configuration values for these tables from a separate file, located at a path provided by a pipeline parameter. is wrong because it does not satisfy the requirement in the question (A data engineer wants to refactor the following DLT code,) as stated.\n\nKey takeaway\n- Choose the option that matches the specific Databricks/Spark mechanism the question is testing, and eliminate answers that are unrelated, over-privileged, or factually inconsistent with how the platform works.",
    "images": [
      "/questions/q198.webp"
    ],
    "docs": [
      {
        "title": "Structured Streaming on Databricks (checkpoints, triggers)",
        "query": "Databricks structured streaming checkpoint trigger interval"
      },
      {
        "title": "Spark Structured Streaming programming model",
        "query": "Spark structured streaming unbounded table micro-batch"
      },
      {
        "title": "Delta Lake on Databricks (time travel, VACUUM, OPTIMIZE)",
        "query": "Delta Lake VACUUM retention time travel"
      },
      {
        "title": "Delta Lake MERGE INTO",
        "query": "Delta Lake MERGE INTO syntax semantics"
      }
    ]
  }
]